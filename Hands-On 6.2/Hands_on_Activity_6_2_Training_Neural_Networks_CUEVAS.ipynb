{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 6.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 019\n",
        "Code Title: | Emerging Technologies in CpE 2\n",
        "2nd Semester | AY 2023-2024\n",
        "<hr> | <hr>\n",
        "<u>**ACTIVITY**</u> | <u>**Activity 1.2**</u>\n",
        "**Name** | Cuevas, Christian Jay L.\n",
        "**Section** | CPE32S3\n",
        "**Date Performed**: | 4/2/2024\n",
        "**Date Submitted**: | 4/2/2024\n",
        "**Instructor**: | Engr. Roman M. Richard  \n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "Ld1G7lXG-_hb"
      },
      "id": "Ld1G7lXG-_hb"
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "\n",
        "filepath = \"https://raw.githubusercontent.com/ChristianJayCuevas/CPE-019---Emerging-Technologies-2/main/Hands-On%206.2/pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "undefined-inventory",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "undefined-inventory",
        "outputId": "29f0a7fd-14e6-4976-ae72-18961f92708c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "624               2                     108              64               0   \n",
              "358              12                      88              74              40   \n",
              "228               4                     197              70              39   \n",
              "114               7                     160              54              32   \n",
              "604               4                     183               0               0   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "624        0  30.8              0.158   21             0  \n",
              "358       54  35.3              0.378   48             0  \n",
              "228      744  36.7              2.329   31             0  \n",
              "114      175  30.5              0.588   39             1  \n",
              "604        0  28.4              0.212   36             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a578f4e5-f298-4c80-89f8-4c6b351b222b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.8</td>\n",
              "      <td>0.158</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>12</td>\n",
              "      <td>88</td>\n",
              "      <td>74</td>\n",
              "      <td>40</td>\n",
              "      <td>54</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.378</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>4</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>39</td>\n",
              "      <td>744</td>\n",
              "      <td>36.7</td>\n",
              "      <td>2.329</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>7</td>\n",
              "      <td>160</td>\n",
              "      <td>54</td>\n",
              "      <td>32</td>\n",
              "      <td>175</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.588</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>4</td>\n",
              "      <td>183</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.4</td>\n",
              "      <td>0.212</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a578f4e5-f298-4c80-89f8-4c6b351b222b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a578f4e5-f298-4c80-89f8-4c6b351b222b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a578f4e5-f298-4c80-89f8-4c6b351b222b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b688a597-3a78-4725-a3bc-5fc2d4829729\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b688a597-3a78-4725-a3bc-5fc2d4829729')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b688a597-3a78-4725-a3bc-5fc2d4829729 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"diabetes_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"times_pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 2,\n        \"max\": 12,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          12,\n          7,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glucose_tolerance_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47,\n        \"min\": 88,\n        \"max\": 197,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          88,\n          183,\n          197\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 0,\n        \"max\": 74,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          74,\n          0,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin_thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 40,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          40,\n          32,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 315,\n        \"min\": 0,\n        \"max\": 744,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          54,\n          175,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5018566504070385,\n        \"min\": 28.4,\n        \"max\": 36.7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          35.3,\n          28.4,\n          36.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pedigree_function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9077901739939688,\n        \"min\": 0.158,\n        \"max\": 2.329,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.378,\n          0.212,\n          2.329\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 21,\n        \"max\": 48,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          48,\n          36,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "systematic-motorcycle",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "systematic-motorcycle",
        "outputId": "58ff4e5d-2a08-42d5-95f4-922d49b7097b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acceptable-equity",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acceptable-equity",
        "outputId": "35c3d06c-7ff6-4f9a-aed7-d6528b4f54cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "**Observation**:\n",
        "- This dataset has 8 features and 1 target variable. We have not done any correlational analysis and feature engineering, but we have normalized our dataset using StandardScaler. StandardScaler is very useful when scaling values with different range, it standardizes the weight of each variable. We have also split the dataset into training and testing, in a 75 - 25 split, the 75 is the training while the 25 is the testing dataset.\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "3XUTTjtggRH7"
      },
      "id": "3XUTTjtggRH7"
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-kingdom",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "correct-kingdom",
        "outputId": "5b7088ff-20fa-49b4-f6e1-1fa438a96ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "happy-prompt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "happy-prompt",
        "outputId": "6f280d42-6dc5-4bbb-fb11-eea79b6d4d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 14ms/step - loss: 0.7776 - accuracy: 0.3906 - val_loss: 0.7355 - val_accuracy: 0.4271\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7239 - accuracy: 0.4410 - val_loss: 0.6931 - val_accuracy: 0.4948\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6829 - accuracy: 0.5260 - val_loss: 0.6608 - val_accuracy: 0.6146\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6513 - accuracy: 0.6181 - val_loss: 0.6360 - val_accuracy: 0.6823\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6266 - accuracy: 0.7066 - val_loss: 0.6168 - val_accuracy: 0.6979\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.7188 - val_loss: 0.6017 - val_accuracy: 0.7135\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5912 - accuracy: 0.7222 - val_loss: 0.5894 - val_accuracy: 0.7344\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5781 - accuracy: 0.7326 - val_loss: 0.5795 - val_accuracy: 0.7448\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5672 - accuracy: 0.7413 - val_loss: 0.5712 - val_accuracy: 0.7500\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5580 - accuracy: 0.7448 - val_loss: 0.5641 - val_accuracy: 0.7500\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5500 - accuracy: 0.7448 - val_loss: 0.5581 - val_accuracy: 0.7448\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7465 - val_loss: 0.5529 - val_accuracy: 0.7448\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7500 - val_loss: 0.5484 - val_accuracy: 0.7500\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7517 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.7500 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.7517 - val_loss: 0.5377 - val_accuracy: 0.7552\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.7500 - val_loss: 0.5348 - val_accuracy: 0.7552\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.7552 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5115 - accuracy: 0.7552 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5083 - accuracy: 0.7552 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7569 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.7569 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5003 - accuracy: 0.7569 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7552 - val_loss: 0.5211 - val_accuracy: 0.7448\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4939 - accuracy: 0.7552 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7535 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7535 - val_loss: 0.5160 - val_accuracy: 0.7396\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7535 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7552 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7552 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7569 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7604 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7622 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7622 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7622 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7622 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7639 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7622 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7639 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7639 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7656 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7639 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7639 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7639 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7656 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7656 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7674 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7674 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7674 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7656 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7691 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7708 - val_loss: 0.5008 - val_accuracy: 0.7448\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.5005 - val_accuracy: 0.7448\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7448\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7708 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7726 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7708 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7726 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7726 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7743 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7448\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7448\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7448\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7743 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7743 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7760 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7760 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7778 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7778 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7778 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7778 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7795 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7812 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7778 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7795 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7865 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7552\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7552\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7830 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7830 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7778 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7778 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7760 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7760 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7778 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7795 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7795 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7760 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7778 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7795 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7795 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7795 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7795 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7795 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7812 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7899 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7760\n"
          ]
        }
      ],
      "source": [
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unsigned-nevada",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unsigned-nevada",
        "outputId": "237633f0-7e3b-4c14-82ae-20375d30a530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 = np.argmax(model.predict(X_test_norm), axis=-1)\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tough-catering",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tough-catering",
        "outputId": "5b99f7c0-1992-46b9-b98f-83d2032d3436"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "combined-zimbabwe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "combined-zimbabwe",
        "outputId": "c16c407b-8d9a-46aa-d9f8-ce7559159fd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.43125084],\n",
              "       [0.7969196 ],\n",
              "       [0.24934165],\n",
              "       [0.23118867],\n",
              "       [0.1871227 ],\n",
              "       [0.51122844],\n",
              "       [0.0200354 ],\n",
              "       [0.37328646],\n",
              "       [0.89137256],\n",
              "       [0.128482  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "**Observation**:\n",
        "- In this first model, we only have 1 hidden layer with 12 nodes and we are using all the features as the input since our input shape is (8,). Our activation for our hidden layer is \"relu\" which stands for Rectified Linear Unit. The activation function for the output layer is \"sigmoid\" function. The next thing we did is to compile our model, we used SGD or Stochastic Gradient Descent with a learning rate of 0.003, our loss function is binary_crossentropy, and we are using the accuracy as metric. We then trained our model and we stored it in run_hist_1. In our model training, we used a validation dataset which is the testing dataset that we have splitted earlier (X_test_norm and y_test), our epoch is 200.\n",
        "\n",
        "- Our final training accuracy is 0.7899 and the final training loss is 0.4311. In the validation accuracy, we have 0.7760 and the validation loss is 0.4978. Just by looking at the results, we can tell that this model is not overfitted since the value for the accuracy and loss of the training and the validation are pretty close to each other.\n",
        "\n",
        "- Overall, these parameters for the model are quite optimized, the accuracy and loss are just stagnant which may mean a lot of things, like the need for feature selection and feature engineering.\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "BuGS15N3nCnu"
      },
      "id": "BuGS15N3nCnu"
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eleven-nebraska",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "eleven-nebraska",
        "outputId": "5991e115-6ef4-44df-d64a-613fdd45ef01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.641\n",
            "roc-auc is 0.819\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "**Observation**:\n",
        "- We can observe above that our ROC curve has not reached the top left corner, which means that our model is not performing very well. This can also be seen in the accuracy of 0.641 and the ROC curve value has reached 0.819. We can also observe that our ROC curve looks like a stair and not a smooth curve, this means that our model is highly distinct and clustered.\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "pF-s81hYlp80"
      },
      "id": "pF-s81hYlp80"
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-physics",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hidden-physics",
        "outputId": "6a128ad8-6095-430d-a5ff-38140d7fba1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banned-spider",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "banned-spider",
        "outputId": "04a99184-a4a4-4efb-cf31-eaea9d0cdc9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79ad3f75f3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "**Answer**:\n",
        "- We can see in the graph above that our train loss and validation loss are decreasing in the same pace but as they reached the 20th-25th iteration, the validation loss became stagnant until it reached the 200. The training loss still continued to decrease though, this represents that the model is overfitted because the training loss decreased but the validation loss stopped decreasing early.\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "PX8Bu2HUktWR"
      },
      "id": "PX8Bu2HUktWR"
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "## Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model with 2 hidden layers, with 6 nodes each"
      ],
      "metadata": {
        "id": "xD90h73P--jP"
      },
      "id": "xD90h73P--jP"
    },
    {
      "cell_type": "code",
      "source": [
        "model1  = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "h3cYiD6xqtlx"
      },
      "id": "h3cYiD6xqtlx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-jXZs__q-8M",
        "outputId": "c3321a28-99c6-492d-d36d-3170dae14ed2"
      },
      "id": "6-jXZs__q-8M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 12ms/step - loss: 0.7940 - accuracy: 0.3056 - val_loss: 0.7713 - val_accuracy: 0.3490\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7670 - accuracy: 0.3698 - val_loss: 0.7504 - val_accuracy: 0.3958\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7468 - accuracy: 0.4080 - val_loss: 0.7344 - val_accuracy: 0.4375\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7306 - accuracy: 0.4583 - val_loss: 0.7214 - val_accuracy: 0.4896\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7177 - accuracy: 0.5087 - val_loss: 0.7110 - val_accuracy: 0.5521\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7068 - accuracy: 0.5677 - val_loss: 0.7024 - val_accuracy: 0.5781\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.5885 - val_loss: 0.6949 - val_accuracy: 0.5781\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.6042 - val_loss: 0.6885 - val_accuracy: 0.6042\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.6163 - val_loss: 0.6829 - val_accuracy: 0.6250\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.6215 - val_loss: 0.6781 - val_accuracy: 0.6354\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.6250 - val_loss: 0.6737 - val_accuracy: 0.6302\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.6250 - val_loss: 0.6698 - val_accuracy: 0.6302\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.6354 - val_loss: 0.6661 - val_accuracy: 0.6302\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6389 - val_loss: 0.6627 - val_accuracy: 0.6354\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.6424 - val_loss: 0.6594 - val_accuracy: 0.6406\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6406 - val_loss: 0.6563 - val_accuracy: 0.6406\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.6476 - val_loss: 0.6533 - val_accuracy: 0.6354\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6510 - val_loss: 0.6503 - val_accuracy: 0.6354\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.6510 - val_loss: 0.6474 - val_accuracy: 0.6354\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.6528 - val_loss: 0.6445 - val_accuracy: 0.6302\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6562 - val_loss: 0.6416 - val_accuracy: 0.6302\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6562 - val_loss: 0.6388 - val_accuracy: 0.6302\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.6580 - val_loss: 0.6361 - val_accuracy: 0.6302\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6580 - val_loss: 0.6334 - val_accuracy: 0.6354\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.6580 - val_loss: 0.6308 - val_accuracy: 0.6406\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6102 - accuracy: 0.6580 - val_loss: 0.6281 - val_accuracy: 0.6406\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.6580 - val_loss: 0.6255 - val_accuracy: 0.6406\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.6562 - val_loss: 0.6228 - val_accuracy: 0.6406\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.6562 - val_loss: 0.6201 - val_accuracy: 0.6406\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.6545 - val_loss: 0.6174 - val_accuracy: 0.6406\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.6562 - val_loss: 0.6148 - val_accuracy: 0.6406\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.6580 - val_loss: 0.6121 - val_accuracy: 0.6406\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.6580 - val_loss: 0.6096 - val_accuracy: 0.6406\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.6615 - val_loss: 0.6070 - val_accuracy: 0.6406\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6615 - val_loss: 0.6043 - val_accuracy: 0.6406\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.6615 - val_loss: 0.6018 - val_accuracy: 0.6406\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.6615 - val_loss: 0.5994 - val_accuracy: 0.6406\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.6632 - val_loss: 0.5972 - val_accuracy: 0.6406\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.6667 - val_loss: 0.5951 - val_accuracy: 0.6406\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.6684 - val_loss: 0.5929 - val_accuracy: 0.6406\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.6684 - val_loss: 0.5908 - val_accuracy: 0.6458\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.6684 - val_loss: 0.5887 - val_accuracy: 0.6458\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.6701 - val_loss: 0.5867 - val_accuracy: 0.6458\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.6719 - val_loss: 0.5848 - val_accuracy: 0.6562\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.6701 - val_loss: 0.5830 - val_accuracy: 0.6562\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.6736 - val_loss: 0.5812 - val_accuracy: 0.6615\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.6736 - val_loss: 0.5796 - val_accuracy: 0.6615\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.6753 - val_loss: 0.5781 - val_accuracy: 0.6667\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.6788 - val_loss: 0.5766 - val_accuracy: 0.6667\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.6788 - val_loss: 0.5752 - val_accuracy: 0.6615\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.6788 - val_loss: 0.5739 - val_accuracy: 0.6615\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.6788 - val_loss: 0.5725 - val_accuracy: 0.6667\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.6806 - val_loss: 0.5713 - val_accuracy: 0.6667\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.6806 - val_loss: 0.5702 - val_accuracy: 0.6615\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.6823 - val_loss: 0.5692 - val_accuracy: 0.6615\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.6840 - val_loss: 0.5681 - val_accuracy: 0.6615\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.6840 - val_loss: 0.5671 - val_accuracy: 0.6667\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.6875 - val_loss: 0.5662 - val_accuracy: 0.6823\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.6840 - val_loss: 0.5653 - val_accuracy: 0.6875\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.6892 - val_loss: 0.5644 - val_accuracy: 0.6979\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.6892 - val_loss: 0.5636 - val_accuracy: 0.7031\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.6927 - val_loss: 0.5628 - val_accuracy: 0.7083\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.6944 - val_loss: 0.5620 - val_accuracy: 0.7083\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.6962 - val_loss: 0.5612 - val_accuracy: 0.7083\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.6927 - val_loss: 0.5604 - val_accuracy: 0.7083\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.6979 - val_loss: 0.5596 - val_accuracy: 0.7083\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.6962 - val_loss: 0.5589 - val_accuracy: 0.7031\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.6962 - val_loss: 0.5582 - val_accuracy: 0.7083\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.6979 - val_loss: 0.5576 - val_accuracy: 0.7031\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7014 - val_loss: 0.5569 - val_accuracy: 0.7031\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7031 - val_loss: 0.5564 - val_accuracy: 0.7083\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7031 - val_loss: 0.5559 - val_accuracy: 0.7083\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7101 - val_loss: 0.5554 - val_accuracy: 0.7031\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7101 - val_loss: 0.5549 - val_accuracy: 0.7031\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7118 - val_loss: 0.5545 - val_accuracy: 0.7083\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7135 - val_loss: 0.5541 - val_accuracy: 0.7083\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7153 - val_loss: 0.5538 - val_accuracy: 0.7083\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7188 - val_loss: 0.5535 - val_accuracy: 0.7083\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7222 - val_loss: 0.5532 - val_accuracy: 0.7083\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7240 - val_loss: 0.5529 - val_accuracy: 0.7135\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7257 - val_loss: 0.5526 - val_accuracy: 0.7135\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7240 - val_loss: 0.5524 - val_accuracy: 0.7083\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7240 - val_loss: 0.5522 - val_accuracy: 0.7031\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7240 - val_loss: 0.5519 - val_accuracy: 0.7031\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7309 - val_loss: 0.5516 - val_accuracy: 0.7083\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7257 - val_loss: 0.5513 - val_accuracy: 0.7083\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7257 - val_loss: 0.5510 - val_accuracy: 0.7031\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7240 - val_loss: 0.5507 - val_accuracy: 0.7083\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7274 - val_loss: 0.5504 - val_accuracy: 0.6979\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7326 - val_loss: 0.5502 - val_accuracy: 0.7031\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7361 - val_loss: 0.5499 - val_accuracy: 0.7031\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7413 - val_loss: 0.5496 - val_accuracy: 0.7083\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7413 - val_loss: 0.5494 - val_accuracy: 0.7188\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7396 - val_loss: 0.5491 - val_accuracy: 0.7135\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7396 - val_loss: 0.5489 - val_accuracy: 0.7188\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7326 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7257 - val_loss: 0.5486 - val_accuracy: 0.7188\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4819 - accuracy: 0.7292 - val_loss: 0.5484 - val_accuracy: 0.7188\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7274 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4808 - accuracy: 0.7309 - val_loss: 0.5482 - val_accuracy: 0.7083\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7326 - val_loss: 0.5480 - val_accuracy: 0.6979\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7361 - val_loss: 0.5479 - val_accuracy: 0.6875\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.7326 - val_loss: 0.5478 - val_accuracy: 0.6979\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4784 - accuracy: 0.7344 - val_loss: 0.5477 - val_accuracy: 0.6979\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7396 - val_loss: 0.5476 - val_accuracy: 0.7031\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7396 - val_loss: 0.5475 - val_accuracy: 0.6979\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7378 - val_loss: 0.5475 - val_accuracy: 0.6875\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7396 - val_loss: 0.5474 - val_accuracy: 0.6875\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7344 - val_loss: 0.5473 - val_accuracy: 0.6927\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.7361 - val_loss: 0.5473 - val_accuracy: 0.6823\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7378 - val_loss: 0.5474 - val_accuracy: 0.6719\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7396 - val_loss: 0.5473 - val_accuracy: 0.6719\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7361 - val_loss: 0.5473 - val_accuracy: 0.6719\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7344 - val_loss: 0.5473 - val_accuracy: 0.6667\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7344 - val_loss: 0.5472 - val_accuracy: 0.6667\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7292 - val_loss: 0.5473 - val_accuracy: 0.6667\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7292 - val_loss: 0.5473 - val_accuracy: 0.6615\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7361 - val_loss: 0.5472 - val_accuracy: 0.6667\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7396 - val_loss: 0.5472 - val_accuracy: 0.6667\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7378 - val_loss: 0.5472 - val_accuracy: 0.6719\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7448 - val_loss: 0.5471 - val_accuracy: 0.6719\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7483 - val_loss: 0.5471 - val_accuracy: 0.6719\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7483 - val_loss: 0.5471 - val_accuracy: 0.6771\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7483 - val_loss: 0.5471 - val_accuracy: 0.6719\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7500 - val_loss: 0.5471 - val_accuracy: 0.6719\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7517 - val_loss: 0.5471 - val_accuracy: 0.6719\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7535 - val_loss: 0.5471 - val_accuracy: 0.6719\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7517 - val_loss: 0.5472 - val_accuracy: 0.6719\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7517 - val_loss: 0.5472 - val_accuracy: 0.6667\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7500 - val_loss: 0.5472 - val_accuracy: 0.6667\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7517 - val_loss: 0.5472 - val_accuracy: 0.6719\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7569 - val_loss: 0.5472 - val_accuracy: 0.6719\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7552 - val_loss: 0.5473 - val_accuracy: 0.6667\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7587 - val_loss: 0.5473 - val_accuracy: 0.6667\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7552 - val_loss: 0.5474 - val_accuracy: 0.6615\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7552 - val_loss: 0.5474 - val_accuracy: 0.6562\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7535 - val_loss: 0.5475 - val_accuracy: 0.6562\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7569 - val_loss: 0.5475 - val_accuracy: 0.6667\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7552 - val_loss: 0.5475 - val_accuracy: 0.6667\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7552 - val_loss: 0.5476 - val_accuracy: 0.6667\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7500 - val_loss: 0.5476 - val_accuracy: 0.6667\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7552 - val_loss: 0.5477 - val_accuracy: 0.6667\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7535 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7500 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7500 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7517 - val_loss: 0.5477 - val_accuracy: 0.6771\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7465 - val_loss: 0.5476 - val_accuracy: 0.6771\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7483 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7483 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7517 - val_loss: 0.5476 - val_accuracy: 0.6719\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7517 - val_loss: 0.5476 - val_accuracy: 0.6719\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7517 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7500 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7517 - val_loss: 0.5475 - val_accuracy: 0.6719\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7448 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7517 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7483 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7500 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7483 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7483 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7517 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7517 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7517 - val_loss: 0.5477 - val_accuracy: 0.6719\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7535 - val_loss: 0.5476 - val_accuracy: 0.6719\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7500 - val_loss: 0.5476 - val_accuracy: 0.6719\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7569 - val_loss: 0.5476 - val_accuracy: 0.6719\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7517 - val_loss: 0.5476 - val_accuracy: 0.6719\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7552 - val_loss: 0.5476 - val_accuracy: 0.6719\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7552 - val_loss: 0.5475 - val_accuracy: 0.6719\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7569 - val_loss: 0.5476 - val_accuracy: 0.6719\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7535 - val_loss: 0.5476 - val_accuracy: 0.6719\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7587 - val_loss: 0.5475 - val_accuracy: 0.6719\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7552 - val_loss: 0.5474 - val_accuracy: 0.6719\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7569 - val_loss: 0.5473 - val_accuracy: 0.6719\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7552 - val_loss: 0.5474 - val_accuracy: 0.6719\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7535 - val_loss: 0.5474 - val_accuracy: 0.6719\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7535 - val_loss: 0.5473 - val_accuracy: 0.6719\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7552 - val_loss: 0.5472 - val_accuracy: 0.6719\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7604 - val_loss: 0.5471 - val_accuracy: 0.6719\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7569 - val_loss: 0.5470 - val_accuracy: 0.6719\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7569 - val_loss: 0.5469 - val_accuracy: 0.6719\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7552 - val_loss: 0.5469 - val_accuracy: 0.6719\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7535 - val_loss: 0.5469 - val_accuracy: 0.6719\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7587 - val_loss: 0.5468 - val_accuracy: 0.6719\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7587 - val_loss: 0.5467 - val_accuracy: 0.6719\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7587 - val_loss: 0.5466 - val_accuracy: 0.6719\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7587 - val_loss: 0.5465 - val_accuracy: 0.6719\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7569 - val_loss: 0.5464 - val_accuracy: 0.6719\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7552 - val_loss: 0.5464 - val_accuracy: 0.6719\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7569 - val_loss: 0.5463 - val_accuracy: 0.6719\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7569 - val_loss: 0.5462 - val_accuracy: 0.6719\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7552 - val_loss: 0.5461 - val_accuracy: 0.6719\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7569 - val_loss: 0.5460 - val_accuracy: 0.6719\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7535 - val_loss: 0.5460 - val_accuracy: 0.6719\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7569 - val_loss: 0.5459 - val_accuracy: 0.6719\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7569 - val_loss: 0.5459 - val_accuracy: 0.6771\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7569 - val_loss: 0.5458 - val_accuracy: 0.6771\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7569 - val_loss: 0.5457 - val_accuracy: 0.6771\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7552 - val_loss: 0.5455 - val_accuracy: 0.6771\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7569 - val_loss: 0.5453 - val_accuracy: 0.6771\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7569 - val_loss: 0.5452 - val_accuracy: 0.6823\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7552 - val_loss: 0.5449 - val_accuracy: 0.6823\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7569 - val_loss: 0.5449 - val_accuracy: 0.6823\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7552 - val_loss: 0.5447 - val_accuracy: 0.6823\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7569 - val_loss: 0.5445 - val_accuracy: 0.6823\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7552 - val_loss: 0.5444 - val_accuracy: 0.6875\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7569 - val_loss: 0.5442 - val_accuracy: 0.6875\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7552 - val_loss: 0.5441 - val_accuracy: 0.6875\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7552 - val_loss: 0.5441 - val_accuracy: 0.6875\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7587 - val_loss: 0.5438 - val_accuracy: 0.6927\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7569 - val_loss: 0.5436 - val_accuracy: 0.6927\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7569 - val_loss: 0.5434 - val_accuracy: 0.6927\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7569 - val_loss: 0.5434 - val_accuracy: 0.6927\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7587 - val_loss: 0.5432 - val_accuracy: 0.6927\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7569 - val_loss: 0.5431 - val_accuracy: 0.6927\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7569 - val_loss: 0.5430 - val_accuracy: 0.6927\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7569 - val_loss: 0.5430 - val_accuracy: 0.6875\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7587 - val_loss: 0.5429 - val_accuracy: 0.6875\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7587 - val_loss: 0.5429 - val_accuracy: 0.6927\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7569 - val_loss: 0.5429 - val_accuracy: 0.6927\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7604 - val_loss: 0.5428 - val_accuracy: 0.6927\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7604 - val_loss: 0.5427 - val_accuracy: 0.6927\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7622 - val_loss: 0.5427 - val_accuracy: 0.6979\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7622 - val_loss: 0.5425 - val_accuracy: 0.6979\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7622 - val_loss: 0.5424 - val_accuracy: 0.6979\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7604 - val_loss: 0.5423 - val_accuracy: 0.6979\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7622 - val_loss: 0.5422 - val_accuracy: 0.6979\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7587 - val_loss: 0.5420 - val_accuracy: 0.6979\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7604 - val_loss: 0.5419 - val_accuracy: 0.6979\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7604 - val_loss: 0.5418 - val_accuracy: 0.7031\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7604 - val_loss: 0.5417 - val_accuracy: 0.6979\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7587 - val_loss: 0.5417 - val_accuracy: 0.6979\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7587 - val_loss: 0.5416 - val_accuracy: 0.6979\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7604 - val_loss: 0.5414 - val_accuracy: 0.6979\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7587 - val_loss: 0.5415 - val_accuracy: 0.6979\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7604 - val_loss: 0.5414 - val_accuracy: 0.6979\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7604 - val_loss: 0.5413 - val_accuracy: 0.6979\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7622 - val_loss: 0.5412 - val_accuracy: 0.6979\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7622 - val_loss: 0.5411 - val_accuracy: 0.6979\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7604 - val_loss: 0.5411 - val_accuracy: 0.6979\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7604 - val_loss: 0.5410 - val_accuracy: 0.6979\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7604 - val_loss: 0.5410 - val_accuracy: 0.7031\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7622 - val_loss: 0.5409 - val_accuracy: 0.7031\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7622 - val_loss: 0.5407 - val_accuracy: 0.7031\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7622 - val_loss: 0.5408 - val_accuracy: 0.7031\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7622 - val_loss: 0.5407 - val_accuracy: 0.7031\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7622 - val_loss: 0.5406 - val_accuracy: 0.7031\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7622 - val_loss: 0.5406 - val_accuracy: 0.7031\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4506 - accuracy: 0.7622 - val_loss: 0.5406 - val_accuracy: 0.7031\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7604 - val_loss: 0.5405 - val_accuracy: 0.7031\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7587 - val_loss: 0.5405 - val_accuracy: 0.7031\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7604 - val_loss: 0.5403 - val_accuracy: 0.7031\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7604 - val_loss: 0.5402 - val_accuracy: 0.7031\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4503 - accuracy: 0.7604 - val_loss: 0.5401 - val_accuracy: 0.7031\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7587 - val_loss: 0.5400 - val_accuracy: 0.7031\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7604 - val_loss: 0.5399 - val_accuracy: 0.6979\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7604 - val_loss: 0.5398 - val_accuracy: 0.6979\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7604 - val_loss: 0.5399 - val_accuracy: 0.7031\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7622 - val_loss: 0.5399 - val_accuracy: 0.7031\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7604 - val_loss: 0.5399 - val_accuracy: 0.7031\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7604 - val_loss: 0.5398 - val_accuracy: 0.6979\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7622 - val_loss: 0.5398 - val_accuracy: 0.6979\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7604 - val_loss: 0.5396 - val_accuracy: 0.6979\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7604 - val_loss: 0.5395 - val_accuracy: 0.6979\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7604 - val_loss: 0.5395 - val_accuracy: 0.6979\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7622 - val_loss: 0.5394 - val_accuracy: 0.6979\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.7587 - val_loss: 0.5392 - val_accuracy: 0.7031\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7604 - val_loss: 0.5392 - val_accuracy: 0.7031\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7587 - val_loss: 0.5393 - val_accuracy: 0.7083\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.7604 - val_loss: 0.5392 - val_accuracy: 0.7083\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7604 - val_loss: 0.5393 - val_accuracy: 0.7083\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7604 - val_loss: 0.5392 - val_accuracy: 0.7083\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.7622 - val_loss: 0.5392 - val_accuracy: 0.7083\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4488 - accuracy: 0.7587 - val_loss: 0.5392 - val_accuracy: 0.7083\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7604 - val_loss: 0.5391 - val_accuracy: 0.7083\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7587 - val_loss: 0.5390 - val_accuracy: 0.7135\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7622 - val_loss: 0.5389 - val_accuracy: 0.7135\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7569 - val_loss: 0.5389 - val_accuracy: 0.7083\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7604 - val_loss: 0.5388 - val_accuracy: 0.7083\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7622 - val_loss: 0.5387 - val_accuracy: 0.7083\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7622 - val_loss: 0.5387 - val_accuracy: 0.7083\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7604 - val_loss: 0.5386 - val_accuracy: 0.7031\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7622 - val_loss: 0.5386 - val_accuracy: 0.7031\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7604 - val_loss: 0.5386 - val_accuracy: 0.7031\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7622 - val_loss: 0.5386 - val_accuracy: 0.7031\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7604 - val_loss: 0.5385 - val_accuracy: 0.7031\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7622 - val_loss: 0.5386 - val_accuracy: 0.7031\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7639 - val_loss: 0.5385 - val_accuracy: 0.7031\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7656 - val_loss: 0.5384 - val_accuracy: 0.7031\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7639 - val_loss: 0.5384 - val_accuracy: 0.7031\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7622 - val_loss: 0.5385 - val_accuracy: 0.7031\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7622 - val_loss: 0.5384 - val_accuracy: 0.7031\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7639 - val_loss: 0.5384 - val_accuracy: 0.7031\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7604 - val_loss: 0.5384 - val_accuracy: 0.7031\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7639 - val_loss: 0.5384 - val_accuracy: 0.7083\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7622 - val_loss: 0.5384 - val_accuracy: 0.7083\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7622 - val_loss: 0.5383 - val_accuracy: 0.7083\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7604 - val_loss: 0.5383 - val_accuracy: 0.7083\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7622 - val_loss: 0.5383 - val_accuracy: 0.7083\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7639 - val_loss: 0.5381 - val_accuracy: 0.7083\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7622 - val_loss: 0.5380 - val_accuracy: 0.7031\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7622 - val_loss: 0.5380 - val_accuracy: 0.7031\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7639 - val_loss: 0.5379 - val_accuracy: 0.7031\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7604 - val_loss: 0.5379 - val_accuracy: 0.7031\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7604 - val_loss: 0.5379 - val_accuracy: 0.7031\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7622 - val_loss: 0.5379 - val_accuracy: 0.7083\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7622 - val_loss: 0.5379 - val_accuracy: 0.7083\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7639 - val_loss: 0.5378 - val_accuracy: 0.7083\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7656 - val_loss: 0.5377 - val_accuracy: 0.7083\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7622 - val_loss: 0.5377 - val_accuracy: 0.7083\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7622 - val_loss: 0.5377 - val_accuracy: 0.7083\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7639 - val_loss: 0.5376 - val_accuracy: 0.7083\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7604 - val_loss: 0.5377 - val_accuracy: 0.7083\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7604 - val_loss: 0.5375 - val_accuracy: 0.7083\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7604 - val_loss: 0.5375 - val_accuracy: 0.7031\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7622 - val_loss: 0.5376 - val_accuracy: 0.7083\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7587 - val_loss: 0.5374 - val_accuracy: 0.7031\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7622 - val_loss: 0.5376 - val_accuracy: 0.7083\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7622 - val_loss: 0.5375 - val_accuracy: 0.7083\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7622 - val_loss: 0.5376 - val_accuracy: 0.7083\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7604 - val_loss: 0.5375 - val_accuracy: 0.7083\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7604 - val_loss: 0.5375 - val_accuracy: 0.7083\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7639 - val_loss: 0.5375 - val_accuracy: 0.7083\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7656 - val_loss: 0.5374 - val_accuracy: 0.6979\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7622 - val_loss: 0.5375 - val_accuracy: 0.6979\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7622 - val_loss: 0.5374 - val_accuracy: 0.7031\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7656 - val_loss: 0.5375 - val_accuracy: 0.7083\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7691 - val_loss: 0.5375 - val_accuracy: 0.7083\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7691 - val_loss: 0.5374 - val_accuracy: 0.7135\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7708 - val_loss: 0.5374 - val_accuracy: 0.7135\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7674 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7674 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7708 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7691 - val_loss: 0.5374 - val_accuracy: 0.7135\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7691 - val_loss: 0.5374 - val_accuracy: 0.7135\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7691 - val_loss: 0.5375 - val_accuracy: 0.7135\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7691 - val_loss: 0.5375 - val_accuracy: 0.7083\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7674 - val_loss: 0.5376 - val_accuracy: 0.7083\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7708 - val_loss: 0.5376 - val_accuracy: 0.7083\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7691 - val_loss: 0.5376 - val_accuracy: 0.7083\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7674 - val_loss: 0.5376 - val_accuracy: 0.7135\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7708 - val_loss: 0.5376 - val_accuracy: 0.7135\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7674 - val_loss: 0.5376 - val_accuracy: 0.7135\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7674 - val_loss: 0.5376 - val_accuracy: 0.7135\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7726 - val_loss: 0.5375 - val_accuracy: 0.7135\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7674 - val_loss: 0.5375 - val_accuracy: 0.7135\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7708 - val_loss: 0.5374 - val_accuracy: 0.7135\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7674 - val_loss: 0.5374 - val_accuracy: 0.7135\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7708 - val_loss: 0.5373 - val_accuracy: 0.7135\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7708 - val_loss: 0.5373 - val_accuracy: 0.7135\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7708 - val_loss: 0.5373 - val_accuracy: 0.7135\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7691 - val_loss: 0.5373 - val_accuracy: 0.7135\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7691 - val_loss: 0.5373 - val_accuracy: 0.7135\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7691 - val_loss: 0.5373 - val_accuracy: 0.7135\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7691 - val_loss: 0.5372 - val_accuracy: 0.7188\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7674 - val_loss: 0.5372 - val_accuracy: 0.7188\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7674 - val_loss: 0.5371 - val_accuracy: 0.7188\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7691 - val_loss: 0.5371 - val_accuracy: 0.7188\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7674 - val_loss: 0.5372 - val_accuracy: 0.7188\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7674 - val_loss: 0.5371 - val_accuracy: 0.7188\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7674 - val_loss: 0.5371 - val_accuracy: 0.7188\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7674 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7656 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7656 - val_loss: 0.5370 - val_accuracy: 0.7240\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7674 - val_loss: 0.5369 - val_accuracy: 0.7240\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7656 - val_loss: 0.5368 - val_accuracy: 0.7240\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7674 - val_loss: 0.5368 - val_accuracy: 0.7240\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7674 - val_loss: 0.5368 - val_accuracy: 0.7240\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7674 - val_loss: 0.5368 - val_accuracy: 0.7240\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7639 - val_loss: 0.5367 - val_accuracy: 0.7240\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7622 - val_loss: 0.5366 - val_accuracy: 0.7240\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7656 - val_loss: 0.5366 - val_accuracy: 0.7240\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7656 - val_loss: 0.5366 - val_accuracy: 0.7240\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7639 - val_loss: 0.5365 - val_accuracy: 0.7240\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7656 - val_loss: 0.5365 - val_accuracy: 0.7240\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7639 - val_loss: 0.5364 - val_accuracy: 0.7188\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7639 - val_loss: 0.5364 - val_accuracy: 0.7188\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7639 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7639 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7639 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7639 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7639 - val_loss: 0.5361 - val_accuracy: 0.7188\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7639 - val_loss: 0.5361 - val_accuracy: 0.7188\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7656 - val_loss: 0.5360 - val_accuracy: 0.7188\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7622 - val_loss: 0.5362 - val_accuracy: 0.7188\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7639 - val_loss: 0.5361 - val_accuracy: 0.7188\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7639 - val_loss: 0.5360 - val_accuracy: 0.7188\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7639 - val_loss: 0.5360 - val_accuracy: 0.7188\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7622 - val_loss: 0.5359 - val_accuracy: 0.7188\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.7639 - val_loss: 0.5358 - val_accuracy: 0.7188\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7639 - val_loss: 0.5357 - val_accuracy: 0.7188\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7656 - val_loss: 0.5357 - val_accuracy: 0.7188\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7656 - val_loss: 0.5356 - val_accuracy: 0.7188\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7639 - val_loss: 0.5355 - val_accuracy: 0.7188\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7656 - val_loss: 0.5354 - val_accuracy: 0.7188\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7691 - val_loss: 0.5355 - val_accuracy: 0.7188\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7691 - val_loss: 0.5355 - val_accuracy: 0.7188\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7691 - val_loss: 0.5354 - val_accuracy: 0.7188\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7691 - val_loss: 0.5353 - val_accuracy: 0.7188\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7691 - val_loss: 0.5353 - val_accuracy: 0.7188\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.7691 - val_loss: 0.5352 - val_accuracy: 0.7188\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7691 - val_loss: 0.5350 - val_accuracy: 0.7188\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7691 - val_loss: 0.5350 - val_accuracy: 0.7188\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.7708 - val_loss: 0.5349 - val_accuracy: 0.7188\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7726 - val_loss: 0.5349 - val_accuracy: 0.7188\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.7726 - val_loss: 0.5348 - val_accuracy: 0.7188\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7726 - val_loss: 0.5348 - val_accuracy: 0.7188\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7726 - val_loss: 0.5348 - val_accuracy: 0.7188\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7726 - val_loss: 0.5348 - val_accuracy: 0.7188\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.7726 - val_loss: 0.5347 - val_accuracy: 0.7188\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7726 - val_loss: 0.5347 - val_accuracy: 0.7188\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7726 - val_loss: 0.5346 - val_accuracy: 0.7188\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7726 - val_loss: 0.5346 - val_accuracy: 0.7188\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7726 - val_loss: 0.5345 - val_accuracy: 0.7188\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7726 - val_loss: 0.5344 - val_accuracy: 0.7188\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7726 - val_loss: 0.5343 - val_accuracy: 0.7188\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7726 - val_loss: 0.5343 - val_accuracy: 0.7188\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7726 - val_loss: 0.5344 - val_accuracy: 0.7188\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7708 - val_loss: 0.5343 - val_accuracy: 0.7188\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7743 - val_loss: 0.5342 - val_accuracy: 0.7188\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7726 - val_loss: 0.5341 - val_accuracy: 0.7188\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.7726 - val_loss: 0.5342 - val_accuracy: 0.7188\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7743 - val_loss: 0.5341 - val_accuracy: 0.7188\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.7708 - val_loss: 0.5340 - val_accuracy: 0.7188\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7743 - val_loss: 0.5339 - val_accuracy: 0.7188\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.5338 - val_accuracy: 0.7188\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.5338 - val_accuracy: 0.7188\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.5337 - val_accuracy: 0.7188\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7795 - val_loss: 0.5336 - val_accuracy: 0.7188\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7743 - val_loss: 0.5336 - val_accuracy: 0.7240\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5335 - val_accuracy: 0.7292\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7760 - val_loss: 0.5335 - val_accuracy: 0.7240\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5335 - val_accuracy: 0.7240\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.5332 - val_accuracy: 0.7240\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.5332 - val_accuracy: 0.7240\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7795 - val_loss: 0.5331 - val_accuracy: 0.7240\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.5332 - val_accuracy: 0.7240\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7795 - val_loss: 0.5330 - val_accuracy: 0.7240\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7778 - val_loss: 0.5331 - val_accuracy: 0.7240\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7795 - val_loss: 0.5331 - val_accuracy: 0.7240\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7795 - val_loss: 0.5331 - val_accuracy: 0.7240\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7812 - val_loss: 0.5330 - val_accuracy: 0.7240\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5330 - val_accuracy: 0.7240\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5329 - val_accuracy: 0.7188\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7188\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7795 - val_loss: 0.5328 - val_accuracy: 0.7188\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7812 - val_loss: 0.5327 - val_accuracy: 0.7188\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7188\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7795 - val_loss: 0.5327 - val_accuracy: 0.7188\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7795 - val_loss: 0.5325 - val_accuracy: 0.7188\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5324 - val_accuracy: 0.7188\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5325 - val_accuracy: 0.7188\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7812 - val_loss: 0.5324 - val_accuracy: 0.7188\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5324 - val_accuracy: 0.7188\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.5325 - val_accuracy: 0.7188\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7760 - val_loss: 0.5325 - val_accuracy: 0.7188\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7188\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7188\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.5323 - val_accuracy: 0.7188\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.5323 - val_accuracy: 0.7188\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7188\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.5322 - val_accuracy: 0.7188\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5321 - val_accuracy: 0.7188\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.5321 - val_accuracy: 0.7188\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5321 - val_accuracy: 0.7188\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5321 - val_accuracy: 0.7188\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.5319 - val_accuracy: 0.7188\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7795 - val_loss: 0.5319 - val_accuracy: 0.7188\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.5318 - val_accuracy: 0.7188\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.7760 - val_loss: 0.5318 - val_accuracy: 0.7188\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7795 - val_loss: 0.5317 - val_accuracy: 0.7188\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5317 - val_accuracy: 0.7188\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5317 - val_accuracy: 0.7188\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7778 - val_loss: 0.5316 - val_accuracy: 0.7188\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.5316 - val_accuracy: 0.7188\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7795 - val_loss: 0.5315 - val_accuracy: 0.7188\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.5316 - val_accuracy: 0.7188\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7778 - val_loss: 0.5317 - val_accuracy: 0.7188\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7778 - val_loss: 0.5315 - val_accuracy: 0.7188\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.5313 - val_accuracy: 0.7188\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7795 - val_loss: 0.5313 - val_accuracy: 0.7188\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7778 - val_loss: 0.5314 - val_accuracy: 0.7188\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7778 - val_loss: 0.5312 - val_accuracy: 0.7188\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.5312 - val_accuracy: 0.7188\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.5311 - val_accuracy: 0.7188\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.5311 - val_accuracy: 0.7188\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7778 - val_loss: 0.5312 - val_accuracy: 0.7188\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5312 - val_accuracy: 0.7188\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5312 - val_accuracy: 0.7188\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5310 - val_accuracy: 0.7240\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7778 - val_loss: 0.5310 - val_accuracy: 0.7240\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.5310 - val_accuracy: 0.7240\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5309 - val_accuracy: 0.7240\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5309 - val_accuracy: 0.7240\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7795 - val_loss: 0.5308 - val_accuracy: 0.7240\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7778 - val_loss: 0.5307 - val_accuracy: 0.7240\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7778 - val_loss: 0.5307 - val_accuracy: 0.7240\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5306 - val_accuracy: 0.7240\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7795 - val_loss: 0.5306 - val_accuracy: 0.7240\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7795 - val_loss: 0.5305 - val_accuracy: 0.7240\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7795 - val_loss: 0.5304 - val_accuracy: 0.7240\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7795 - val_loss: 0.5303 - val_accuracy: 0.7240\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7778 - val_loss: 0.5304 - val_accuracy: 0.7240\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7778 - val_loss: 0.5304 - val_accuracy: 0.7240\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7778 - val_loss: 0.5304 - val_accuracy: 0.7240\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7795 - val_loss: 0.5302 - val_accuracy: 0.7240\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7778 - val_loss: 0.5303 - val_accuracy: 0.7240\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7795 - val_loss: 0.5301 - val_accuracy: 0.7240\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7795 - val_loss: 0.5300 - val_accuracy: 0.7240\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7795 - val_loss: 0.5298 - val_accuracy: 0.7240\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7795 - val_loss: 0.5299 - val_accuracy: 0.7240\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7778 - val_loss: 0.5299 - val_accuracy: 0.7240\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7778 - val_loss: 0.5298 - val_accuracy: 0.7240\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.5297 - val_accuracy: 0.7240\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7795 - val_loss: 0.5294 - val_accuracy: 0.7240\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.5295 - val_accuracy: 0.7240\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.5294 - val_accuracy: 0.7240\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.5294 - val_accuracy: 0.7240\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7778 - val_loss: 0.5293 - val_accuracy: 0.7240\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7778 - val_loss: 0.5294 - val_accuracy: 0.7240\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7778 - val_loss: 0.5294 - val_accuracy: 0.7240\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7778 - val_loss: 0.5296 - val_accuracy: 0.7240\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7743 - val_loss: 0.5293 - val_accuracy: 0.7240\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7760 - val_loss: 0.5291 - val_accuracy: 0.7240\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7760 - val_loss: 0.5292 - val_accuracy: 0.7240\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7778 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7743 - val_loss: 0.5289 - val_accuracy: 0.7240\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7743 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.5289 - val_accuracy: 0.7240\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7760 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7743 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7726 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7743 - val_loss: 0.5285 - val_accuracy: 0.7240\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7778 - val_loss: 0.5283 - val_accuracy: 0.7240\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7743 - val_loss: 0.5283 - val_accuracy: 0.7240\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7743 - val_loss: 0.5282 - val_accuracy: 0.7240\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.5281 - val_accuracy: 0.7240\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7726 - val_loss: 0.5279 - val_accuracy: 0.7240\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7726 - val_loss: 0.5280 - val_accuracy: 0.7240\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7726 - val_loss: 0.5279 - val_accuracy: 0.7240\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7726 - val_loss: 0.5277 - val_accuracy: 0.7240\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7743 - val_loss: 0.5277 - val_accuracy: 0.7240\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7726 - val_loss: 0.5278 - val_accuracy: 0.7240\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7726 - val_loss: 0.5278 - val_accuracy: 0.7240\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7708 - val_loss: 0.5275 - val_accuracy: 0.7240\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.7726 - val_loss: 0.5275 - val_accuracy: 0.7240\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7743 - val_loss: 0.5275 - val_accuracy: 0.7240\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.7726 - val_loss: 0.5274 - val_accuracy: 0.7240\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.7726 - val_loss: 0.5275 - val_accuracy: 0.7292\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.7726 - val_loss: 0.5272 - val_accuracy: 0.7240\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.7726 - val_loss: 0.5271 - val_accuracy: 0.7240\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4386 - accuracy: 0.7726 - val_loss: 0.5269 - val_accuracy: 0.7240\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7726 - val_loss: 0.5269 - val_accuracy: 0.7240\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7708 - val_loss: 0.5267 - val_accuracy: 0.7240\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4386 - accuracy: 0.7743 - val_loss: 0.5266 - val_accuracy: 0.7240\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7743 - val_loss: 0.5266 - val_accuracy: 0.7240\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7726 - val_loss: 0.5264 - val_accuracy: 0.7240\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7743 - val_loss: 0.5264 - val_accuracy: 0.7240\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.7743 - val_loss: 0.5263 - val_accuracy: 0.7292\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.7760 - val_loss: 0.5262 - val_accuracy: 0.7292\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.7743 - val_loss: 0.5260 - val_accuracy: 0.7292\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7743 - val_loss: 0.5260 - val_accuracy: 0.7292\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7743 - val_loss: 0.5260 - val_accuracy: 0.7292\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4381 - accuracy: 0.7743 - val_loss: 0.5260 - val_accuracy: 0.7292\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.5259 - val_accuracy: 0.7292\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7743 - val_loss: 0.5260 - val_accuracy: 0.7292\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4380 - accuracy: 0.7743 - val_loss: 0.5257 - val_accuracy: 0.7292\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7743 - val_loss: 0.5257 - val_accuracy: 0.7292\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7743 - val_loss: 0.5256 - val_accuracy: 0.7292\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.7743 - val_loss: 0.5255 - val_accuracy: 0.7292\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7743 - val_loss: 0.5253 - val_accuracy: 0.7292\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7743 - val_loss: 0.5253 - val_accuracy: 0.7292\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7743 - val_loss: 0.5253 - val_accuracy: 0.7292\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7743 - val_loss: 0.5252 - val_accuracy: 0.7292\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5249 - val_accuracy: 0.7292\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7743 - val_loss: 0.5249 - val_accuracy: 0.7292\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7760 - val_loss: 0.5248 - val_accuracy: 0.7292\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7760 - val_loss: 0.5247 - val_accuracy: 0.7292\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5245 - val_accuracy: 0.7292\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5244 - val_accuracy: 0.7292\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7760 - val_loss: 0.5243 - val_accuracy: 0.7292\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7795 - val_loss: 0.5245 - val_accuracy: 0.7292\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7778 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.5243 - val_accuracy: 0.7292\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7760 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7778 - val_loss: 0.5237 - val_accuracy: 0.7292\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7795 - val_loss: 0.5237 - val_accuracy: 0.7292\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7795 - val_loss: 0.5236 - val_accuracy: 0.7292\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7760 - val_loss: 0.5235 - val_accuracy: 0.7292\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7795 - val_loss: 0.5234 - val_accuracy: 0.7292\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7795 - val_loss: 0.5233 - val_accuracy: 0.7292\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7795 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.5231 - val_accuracy: 0.7292\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7760 - val_loss: 0.5229 - val_accuracy: 0.7292\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7344\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7344\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7778 - val_loss: 0.5227 - val_accuracy: 0.7344\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7795 - val_loss: 0.5226 - val_accuracy: 0.7344\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.5226 - val_accuracy: 0.7344\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7795 - val_loss: 0.5226 - val_accuracy: 0.7344\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7795 - val_loss: 0.5224 - val_accuracy: 0.7344\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7778 - val_loss: 0.5223 - val_accuracy: 0.7344\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7344\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7778 - val_loss: 0.5222 - val_accuracy: 0.7344\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7795 - val_loss: 0.5219 - val_accuracy: 0.7344\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7778 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7778 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7795 - val_loss: 0.5216 - val_accuracy: 0.7344\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7344\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7830 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7830 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7344\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7830 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7830 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7795 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7778 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7778 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7865 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7812 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7812 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7830 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.7830 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7812 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7830 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7830 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.7830 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.7830 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.7830 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7830 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.7830 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7396\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7396\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7396\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.5158 - val_accuracy: 0.7396\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.5158 - val_accuracy: 0.7396\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7865 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7865 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7899 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7917 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7917 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7917 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7917 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7917 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7917 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7917 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7917 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7917 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7917 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7917 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7934 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7396\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7917 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7934 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7934 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.5134 - val_accuracy: 0.7396\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7396\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7344\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5131 - val_accuracy: 0.7344\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7934 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7917 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7934 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7934 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7934 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.8003 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.7986 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.8003 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.7986 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8003 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.8003 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7986 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8003 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.8003 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5104 - val_accuracy: 0.7396\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5105 - val_accuracy: 0.7396\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8021 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.8038 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8021 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8021 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8021 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.8038 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.8021 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8021 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8021 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8038 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8021 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8038 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8021 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8021 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.8021 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8021 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8021 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.8038 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7500\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5091 - val_accuracy: 0.7500\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7500\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8021 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8021 - val_loss: 0.5090 - val_accuracy: 0.7500\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7500\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8003 - val_loss: 0.5087 - val_accuracy: 0.7500\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.7986 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7986 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.7986 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.7986 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.7986 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.7934 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4144 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.7951 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4139 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.7934 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4137 - accuracy: 0.7934 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.7969 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7934 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.7934 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.7969 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.7951 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.7934 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.7969 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.7951 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.7934 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.7934 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.7951 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7951 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7934 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7951 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7951 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8021 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8038 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7500\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8038 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8021 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8021 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8021 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8003 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8021 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8021 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8021 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8021 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5061 - val_accuracy: 0.7552\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8038 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8021 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8003 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8003 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8003 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8021 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8021 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8003 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8003 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8003 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8021 - val_loss: 0.5050 - val_accuracy: 0.7552\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8003 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4093 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8003 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8021 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8003 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8021 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8038 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4092 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8021 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8021 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7552\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8038 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8038 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4087 - accuracy: 0.8003 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.8021 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8021 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4087 - accuracy: 0.8021 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8003 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.8038 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.8021 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4085 - accuracy: 0.8003 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4083 - accuracy: 0.8021 - val_loss: 0.5050 - val_accuracy: 0.7552\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4083 - accuracy: 0.8003 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4081 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4082 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.8003 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.7986 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.7969 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8003 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4076 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8003 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4070 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8003 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8003 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.7986 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8003 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8003 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8003 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8003 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8021 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8003 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8003 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8003 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8003 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8021 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8003 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.7986 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8021 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8021 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8003 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8038 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8038 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8038 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8003 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8038 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8003 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8021 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8038 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8038 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8021 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8021 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8038 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8073 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8038 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8021 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8073 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8038 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8021 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8038 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8038 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8056 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8038 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8073 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8056 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8073 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8056 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8038 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8038 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8056 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8021 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8073 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8056 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8073 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8021 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8021 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8021 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8021 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8038 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8038 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8056 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8056 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8021 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4032 - accuracy: 0.8056 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4032 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8056 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4032 - accuracy: 0.8038 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8073 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8056 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8073 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4027 - accuracy: 0.8056 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4029 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8038 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8038 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8073 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8073 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8056 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8056 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4028 - accuracy: 0.8056 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8073 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4026 - accuracy: 0.8073 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4024 - accuracy: 0.8073 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8056 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8038 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8073 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8056 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8056 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8056 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8038 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8090 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8021 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8038 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8038 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8056 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8021 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8038 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8056 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8038 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8038 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8073 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8038 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8021 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4017 - accuracy: 0.8056 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8038 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8038 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8038 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8038 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8056 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8003 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8038 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8056 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8038 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8038 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8056 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8056 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8056 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8056 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8073 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8056 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8073 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8056 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8073 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8090 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8090 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8073 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8090 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8073 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8073 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8108 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8090 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8108 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8090 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8073 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8108 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8090 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8090 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8073 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8108 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8125 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8090 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8108 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8125 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8090 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8108 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8090 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8073 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8108 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8090 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8108 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8073 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8108 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8090 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8090 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8108 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8125 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8090 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8108 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8090 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8108 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8090 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8125 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8108 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8142 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8108 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8125 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8090 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8108 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8160 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3993 - accuracy: 0.8108 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8090 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8125 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8090 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8108 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3992 - accuracy: 0.8090 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3992 - accuracy: 0.8090 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8073 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8073 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8108 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8125 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8142 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8090 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8108 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8142 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8142 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8125 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8090 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8108 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8142 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8125 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8090 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8090 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8073 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8090 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8108 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8090 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8108 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8108 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8108 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8108 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8090 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8090 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8090 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8125 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8090 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8108 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8108 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8090 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8125 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8108 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8125 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8090 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8108 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8090 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8108 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8125 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8108 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8108 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8108 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8108 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8108 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8108 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8090 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8090 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8125 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8108 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8125 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8108 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8090 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8090 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8125 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8108 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8108 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8090 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8090 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8108 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8125 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8108 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8125 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8090 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8125 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8108 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8108 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8090 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8125 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8125 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8090 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8108 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8090 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8125 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8090 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8108 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8090 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8090 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8108 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8073 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8125 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8090 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8108 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8073 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8073 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8108 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8073 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8073 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8090 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8108 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8090 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8090 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8090 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8090 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8090 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8090 - val_loss: 0.5052 - val_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "kRVgSR7ergZ9",
        "outputId": "19919fd5-f9c8-46e9-eef7-871e6eee9504"
      },
      "id": "kRVgSR7ergZ9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79ad3f72e5c0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_2 = np.argmax(model1.predict(X_test_norm), axis=-1)\n",
        "y_pred_prob_nn_2 = model1.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WU7RtHw3YMD",
        "outputId": "e8f38c9c-d25c-41f5-87bb-5731128b233f"
      },
      "id": "7WU7RtHw3YMD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 5ms/step\n",
            "6/6 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_2, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "Ratr1ZHq3Qla",
        "outputId": "0bf50905-0621-4fb8-9dfd-35d3b0b10274"
      },
      "id": "Ratr1ZHq3Qla",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.641\n",
            "roc-auc is 0.823\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAKqCAYAAADsTEzZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABuH0lEQVR4nO3deVhV5f7+8RuQQUDEFHHInCqH7GRpekw9WqlUZnnSHHPKHFKbKM0pTc2wTNNyNodSEcxjZeVRSfOUaVkOZTnkmJWCmgMKAht4fn/0Zf9EBpnXHt6v6+KqvVhrrw88G7l5nrU+28MYYwQAAABYxNPqAgAAAODeCKQAAACwFIEUAAAAliKQAgAAwFIEUgAAAFiKQAoAAABLEUgBAABgKQIpAAAALEUgBQAAgKUIpAByNHXqVNWqVUteXl5q2LCh1eXAgfTt21c1atTItM3Dw0Ovvvpqvp9r6dKl8vDw0A8//FA0xbmR1q1bq0GDBtfd7/jx4/Lw8NDSpUuLvyigAAikcFgZv6QyPkqVKqWqVauqb9+++vPPP7M9xhijZcuW6V//+peCg4Pl7++v22+/XRMnTlRCQkKO5/roo4/04IMPqkKFCvLx8VGVKlXUpUsXbd68OU+1JiUl6e2331bTpk1VtmxZ+fn56dZbb9WwYcP066+/Fujrt9rGjRs1YsQINW/eXEuWLNHrr79erOfr27evPDw89I9//EPZvaOxh4eHhg0bZn+c8QvWw8ND//nPf7Ls/+qrr8rDw0Nnz54t1rrzKqOejA9/f3/Vr19fY8eOVXx8vH2/7MJZxrGenp76/fffszx3fHy8SpcuneV7dLX9+/fLw8NDfn5+unDhQpF/fY5m3bp1BQrHAKxRyuoCgOuZOHGiatasqaSkJH377bdaunSptm7dqp9//ll+fn72/dLS0tSjRw+tWrVKLVu21Kuvvip/f399/fXXmjBhgj788EN98cUXCg0NtR9jjNGTTz6ppUuX6s4771R4eLgqVaqkU6dO6aOPPtL999+vb775Rvfcc0+O9Z09e1YPPPCAdu7cqYcfflg9evRQYGCgDh48qKioKC1YsEApKSnF+j0qDps3b5anp6cWLVokHx+fEjvv3r17tWbNGnXq1CnPx0ycOFGPPfaYPDw8irGyojF37lwFBgbq8uXL2rhxoyZPnqzNmzfrm2++uW79vr6+WrlypUaMGJFp+5o1a6573uXLl6tSpUo6f/68Vq9eraeeeqpQX0d2rly5olKlHOPXyrp16zR79mxCKeAkHONfDiAXDz74oBo3bixJeuqpp1ShQgW98cYbWrt2rbp06WLf780339SqVav00ksvaerUqfbtAwcOVJcuXdSxY0f17dtX//3vf+2fmzZtmpYuXarnn39e06dPzxQIxowZo2XLll33F2zfvn21e/durV69OkuImjRpksaMGVOorz9Damqq0tPTSywcnj59WqVLly6y8xljlJSUpNKlS+e4T+nSpVWtWrV8BcyGDRtqz549+uijj/TYY48VSa3FqXPnzqpQoYIkafDgwerUqZPWrFmjb7/9Vs2aNcv12IceeijbQBoZGan27dtnO1Ms/f29j4yMVI8ePXTs2DGtWLGiWALp1X8gomASEhIUEBBgdRlAiWPJHk6nZcuWkqQjR47Yt125ckVTp07VrbfeqoiIiCzHdOjQQX369NH69ev17bff2o+JiIhQ3bp19dZbb2Ubfnr16qUmTZrkWMt3332nzz//XP379892Rs/X11dvvfWW/XHr1q3VunXrLPtdez1exnL0W2+9pRkzZqh27dry9fXV7t27VapUKU2YMCHLcxw8eFAeHh6aNWuWfduFCxf0/PPPq1q1avL19dXNN9+sN954Q+np6Tl+TdLfy+NLlixRQkKCfYk549qz1NRUTZo0yV5TjRo1NHr0aCUnJ2d6jho1aujhhx/Whg0b1LhxY5UuXVrz58/P9byenp4aO3asfvrpJ3300Ue57puhW7duuvXWWzVx4sRsl/rzYvfu3XrwwQcVFBSkwMBA3X///fbXSYaMpfRvvvlG4eHhCgkJUUBAgP7973/rzJkzBTqvJN13332SpGPHjl133x49emjPnj06cOCAfVtsbKw2b96sHj165HjcN998o+PHj6tbt27q1q2bvvrqK/3xxx95rvHjjz9WgwYN5OfnpwYNGuQ4NtdeQ/rbb79pyJAhqlOnjkqXLq3y5cvr8ccf1/Hjx7M9PjExUYMGDVL58uUVFBSk3r176/z581n2++9//6uWLVsqICBAZcqUUfv27fXLL7/YP9+3b1/Nnj3bXlPGR4b09HTNmDFDt912m/z8/BQaGqpBgwZlOdcPP/ygsLAwVahQQaVLl1bNmjX15JNPXvf7lfHa37hxoxo2bCg/Pz/Vr18/y0x2xmvqf//7n4YMGaKKFSvqxhtvtH9+zpw5uu222+Tr66sqVapo6NChOV5usXPnTt1zzz32OufNm3fdOiXpwIED6ty5s2644Qb5+fmpcePGWrt2bbZ1bt26Vc8++6xCQkIUHBysQYMGKSUlRRcuXFDv3r1Vrlw5lStXTiNGjCjwzyLcF4EUTifjl1m5cuXs27Zu3arz58+rR48eOc5o9u7dW5L02Wef2Y85d+6cevToIS8vrwLVkvEPd69evQp0/PUsWbJE7777rgYOHKhp06apcuXKatWqlVatWpVl3+joaHl5eenxxx+X9Pcv91atWmn58uXq3bu33nnnHTVv3lyjRo1SeHh4ruddtmyZWrZsKV9fXy1btsx+Xa709yz1uHHjdNddd+ntt99Wq1atFBERoW7dumV5noMHD6p79+5q27atZs6cmacbo3r06KFbbrklzwHTy8tLY8eO1Y8//pjnEHu1X375RS1bttSPP/6oESNG6JVXXtGxY8fUunVrfffdd1n2f+aZZ/Tjjz9q/Pjxevrpp/Xpp5/meN1mXmT8YVW+fPnr7vuvf/1LN954oyIjI+3boqOjFRgYqPbt2+d43IoVK1S7dm3dfffd6tChg/z9/bVy5co81bdx40Z16tRJHh4eioiIUMeOHdWvX7883YD0/fffa9u2berWrZveeecdDR48WJs2bVLr1q2VmJiYZf9hw4Zp//79evXVV9W7d2+tWLFCHTt2zPQ6WLZsmdq3b6/AwEC98cYbeuWVV7Rv3z61aNHC/m/DoEGD1LZtW/v+GR8ZBg0apOHDh6t58+aaOXOm+vXrpxUrVigsLEw2m03S3ysE7dq10/HjxzVy5Ei9++676tmzZ5Y/VHJy6NAhde3aVQ8++KAiIiJUqlQpPf7444qJicmy75AhQ7Rv3z6NGzdOI0eOlPT3dcNDhw5VlSpVNG3aNHXq1Enz589Xu3bt7DVmOH/+vB566CE1atRIb775pm688UY9/fTTWrx4ca41/vLLL/rnP/+p/fv3a+TIkZo2bZoCAgLUsWPHbH+WnnnmGR06dEgTJkzQI488ogULFuiVV15Rhw4dlJaWptdff10tWrTQ1KlTM32/gTwxgINasmSJkWS++OILc+bMGfP777+b1atXm5CQEOPr62t+//13+74zZswwksxHH32U4/OdO3fOSDKPPfaYMcaYmTNnXveY6/n3v/9tJJnz58/naf9WrVqZVq1aZdnep08fU716dfvjY8eOGUkmKCjInD59OtO+8+fPN5LM3r17M22vX7++ue++++yPJ02aZAICAsyvv/6aab+RI0caLy8vc+LEiVxr7dOnjwkICMi0bc+ePUaSeeqppzJtf+mll4wks3nzZvu26tWrG0lm/fr1uZ4nu/O9//77RpJZs2aN/fOSzNChQ+2PM75HU6dONampqeaWW24xd9xxh0lPTzfGGDN+/HgjyZw5cybX83bs2NH4+PiYI0eO2LedPHnSlClTxvzrX/+yb8t4PbZp08Z+DmOMeeGFF4yXl5e5cOFCrufJqOfgwYPmzJkz5tixY2b+/PnG19fXhIaGmoSEhEzn+f7777Mce+bMGfPSSy+Zm2++2f65u+++2/Tr1y/b75ExxqSkpJjy5cubMWPG2Lf16NHD3HHHHbnWm6Fhw4amcuXKmb6+jRs3GkmZXrMZ5x8/frz9cWJiYpbn2759u5FkPvjgA/u2jK+5UaNGJiUlxb79zTffNJLMJ598Yowx5tKlSyY4ONgMGDAg03PGxsaasmXLZto+dOhQk92vuK+//tpIMitWrMi0ff369Zm2f/TRR1nGIa8yXvv/+c9/7NsuXrxoKleubO68884sX3eLFi1Mamqqffvp06eNj4+PadeunUlLS7NvnzVrlpFkFi9ebN/WqlUrI8lMmzbNvi05Odk0bNjQVKxY0f79zPh5WbJkiX2/+++/39x+++0mKSnJvi09Pd3cc8895pZbbslSZ1hYWKbXfrNmzYyHh4cZPHiwfVtqaqq58cYbs/13DsgNM6RweG3atFFISIiqVaumzp07KyAgQGvXrs20tHXp0iVJUpkyZXJ8nozPZdzRnPHf3I65nqJ4jtx06tRJISEhmbY99thjKlWqlKKjo+3bfv75Z+3bt09du3a1b/vwww/VsmVLlStXTmfPnrV/tGnTRmlpafrqq6/yXc+6deskKcsM64svvihJ+vzzzzNtr1mzpsLCwvJ9np49exZ4lvTjjz/O83nS0tK0ceNGdezYUbVq1bJvr1y5snr06KGtW7dmugNe+vua5KuXf1u2bKm0tDT99ttveTpnnTp1FBISopo1a2rQoEG6+eab9fnnn8vf3z9Px/fo0UOHDx/W999/b/9vbsv1//3vf/XXX3+pe/fu9m3du3fXjz/+mGmZOzunTp3Snj171KdPH5UtW9a+vW3btqpfv/51a736emGbzaa//vpLN998s4KDg7Vr164s+w8cOFDe3t72x08//bRKlSplf93FxMTowoUL6t69e6bXtJeXl5o2baovv/zyujV9+OGHKlu2rNq2bZvpORo1aqTAwED7cwQHB0v6e0Xl2hnJvKhSpYr+/e9/2x9nXIKwe/duxcbGZtp3wIABmVZpvvjiC6WkpOj555+Xp6dnpv2CgoKy/JyVKlVKgwYNsj/28fHRoEGDdPr0ae3cuTPb+s6dO6fNmzerS5cuunTpkv378NdffyksLEyHDh3K0s2kf//+mV77TZs2lTFG/fv3t2/z8vJS48aNdfTo0bx8mwA7Aikc3uzZsxUTE6PVq1froYce0tmzZ+Xr65tpn4xAmBFMs3NtaA0KCrruMddTFM+Rm5o1a2bZVqFCBd1///2Zlu2jo6NVqlSpTDf1HDp0SOvXr1dISEimjzZt2kj6e0kyv3777Td5enrq5ptvzrS9UqVKCg4OzhLKsqs/LzIC5p49e/IcMHv27Kmbb745X9eSnjlzRomJiapTp06Wz9WrV0/p6elZ2izddNNNmR5nXDqS3bWO2fnPf/6jmJgYbdmyRYcPH9bPP/+sRo0a5elYSbrzzjtVt25dRUZGasWKFapUqZL9OtTsLF++XDVr1pSvr68OHz6sw4cPq3bt2vL399eKFStyPVfGeN5yyy1ZPpfd9+xaV65c0bhx4+zXMFeoUEEhISG6cOGCLl68mGX/a88TGBioypUr25fiDx06JOnv626vfV1v3LgxT6/pQ4cO6eLFi6pYsWKW57h8+bL9OVq1aqVOnTppwoQJqlChgh599FEtWbIky7XSObn55puzXJd+6623SlKWa2iv/TnJ+L5f+z328fFRrVq1svycValSJcuNUDmdK8Phw4dljNErr7yS5fswfvx4SVn/jbj2tZ/xR0q1atWybM/rzwOQgbvs4fCaNGliv8u+Y8eOatGihXr06KGDBw8qMDBQ0t/hQZJ++ukndezYMdvn+emnnyTJPrNTt25dSX+3GcrpmOu5+jkybrbKjYeHR7ZhKS0tLdv9c7ojvVu3burXr5/27Nmjhg0batWqVbr//vvtd29Lf9+40bZt2yx3ZGfI+IVVEHltr5TbHfXX07NnT02aNEkTJ07M0/hkhNi+ffvqk08+KfB583Ke7OQ1BP/rX//KNE4F0aNHD82dO1dlypRR165dM82iXS0+Pl6ffvqpkpKSsg2VkZGRmjx5crG1y3rmmWe0ZMkSPf/882rWrJnKli0rDw8PdevW7bo31mUn45hly5apUqVKWT6fl5ZT6enpqlixYo5hPGNFwsPDQ6tXr9a3336rTz/9VBs2bNCTTz6padOm6dtvv7X/21MUCvNzUlAZ38uXXnopx1WMa//wzOm1n932vP48ABkIpHAqXl5eioiI0L333qtZs2bZbwBo0aKFgoODFRkZqTFjxmT7D+QHH3wgSXr44Yftx5QrV04rV67U6NGjC3RjU4cOHRQREaHly5fnKZCWK1cu26WsvC73ZujYsaMGDRpkX7b/9ddfNWrUqEz71K5dW5cvX7bPiBaF6tWrKz09XYcOHbL/ESBJcXFxunDhgqpXr15k5ypIwHziiSf02muv2W+6uJ6QkBD5+/vr4MGDWT534MABeXp6Zpn9cQQ9evTQuHHjdOrUqVxvHlmzZo2SkpI0d+7cLCH44MGDGjt2rL755hu1aNEi2+MzxjNjZvLa469n9erV6tOnj6ZNm2bflpSUlOOd4ocOHdK9995rf3z58mWdOnVKDz30kKS/X9OSVLFixeu+rnMK2bVr19YXX3yh5s2b5ykI/vOf/9Q///lPTZ48WZGRkerZs6eioqKu2zYrYwby6joy3iTj2ne4ulbG9/3gwYOZLiVJSUnRsWPHsnztJ0+ezNIu6nrnynheb2/vIv03AigoluzhdFq3bq0mTZpoxowZSkpKkiT5+/vrpZde0sGDB7Pt+/n5559r6dKlCgsL0z//+U/7MS+//LL279+vl19+Odu/6JcvX64dO3bkWEuzZs30wAMP6L333st2aTklJUUvvfSS/XHt2rV14MCBTG2CfvzxR33zzTd5/vqlv69vCwsL06pVqxQVFSUfH58ss4hdunTR9u3btWHDhizHX7hwQampqfk6pyR7MJgxY0am7dOnT5ekXO/0LognnnhCN998c7ZtrrJz9VL/ta1rctq/Xbt2+uSTTzItbcbFxSkyMlItWrSwX5bhSGrXrq0ZM2YoIiIi17Zky5cvV61atTR48GB17tw508dLL72kwMDAXJftK1eurIYNG+r999/PtMQeExOjffv2XbdOLy+vLD9X7777bo4rAgsWLMh0vebcuXOVmpqqBx98UJIUFhamoKAgvf7669le13n1z1VGOLs2/Hbp0kVpaWmaNGlSluNTU1Pt+58/fz5L7RldIvKybH/y5MlMd6rHx8frgw8+UMOGDbOd3b1amzZt5OPjo3feeSdTDYsWLdLFixez/JylpqZmaqmWkpKi+fPnKyQkJMfLQSpWrKjWrVtr/vz5OnXqVJbPF6aVGVAQzJDCKQ0fPlyPP/64li5dqsGDB0uSRo4cqd27d+uNN97Q9u3b1alTJ5UuXVpbt27V8uXLVa9ePb3//vtZnueXX37RtGnT9OWXX6pz586qVKmSYmNj9fHHH2vHjh3atm1brrV88MEHateunR577DF16NBB999/vwICAnTo0CFFRUXp1KlT9l6kTz75pKZPn66wsDD1799fp0+f1rx583TbbbdluXnmerp27aonnnhCc+bMUVhYmP0mjKu/trVr1+rhhx9W37591ahRIyUkJGjv3r1avXq1jh8/nu+l4zvuuEN9+vTRggULdOHCBbVq1Uo7duzQ+++/r44dO2aa3SoKXl5eGjNmjPr165fnYzKW+vfs2ZOn/V977TXFxMSoRYsWGjJkiEqVKqX58+crOTlZb775ZgErL37PPfdcrp8/efKkvvzySz377LPZft7X11dhYWH68MMP9c4772S6mehqERERat++vVq0aKEnn3xS586d07vvvqvbbrtNly9fzrWGhx9+WMuWLVPZsmVVv359bd++XV988UWOLa5SUlJ0//33q0uXLjp48KDmzJmjFi1a2Ge7g4KCNHfuXPXq1Ut33XWXunXrppCQEJ04cUKff/65mjdvbu/DmxHEnn32WYWFhcnLy0vdunVTq1atNGjQIEVERGjPnj1q166dvL29dejQIX344YeaOXOmOnfurPfff19z5szRv//9b9WuXVuXLl3SwoULFRQUZP/DLDe33nqr+vfvr++//16hoaFavHix4uLitGTJkuseGxISolGjRmnChAl64IEH9Mgjj9i/H3fffbeeeOKJTPtXqVJFb7zxho4fP65bb71V0dHR2rNnjxYsWJDjuEp/X5/fokUL3X777RowYIBq1aqluLg4bd++XX/88Yd+/PHH69YKFBlrbu4Hri+79jcZ0tLSTO3atU3t2rUztUtJS0szS5YsMc2bNzdBQUHGz8/P3HbbbWbChAnm8uXLOZ5r9erVpl27duaGG24wpUqVMpUrVzZdu3Y1W7ZsyVOtiYmJ5q233jJ33323CQwMND4+PuaWW24xzzzzjDl8+HCmfZcvX25q1aplfHx8TMOGDc2GDRtybPs0derUHM8ZHx9vSpcubSSZ5cuXZ7vPpUuXzKhRo8zNN99sfHx8TIUKFcw999xj3nrrrUztdbKTXdsnY4yx2WxmwoQJpmbNmsbb29tUq1bNjBo1KlPrGGP+bn3Tvn37XM+R1/PVrl0717ZP18p47SgPbZ+MMWbXrl0mLCzMBAYGGn9/f3Pvvfeabdu2Zfuc174ev/zySyPJfPnll7meI69tqK7X9ik3V3+Ppk2bZiSZTZs25bj/0qVLM7VVysl//vMfU69ePePr62vq169v1qxZk+U1m3H+q9s+nT9/3vTr189UqFDBBAYGmrCwMHPgwAFTvXp106dPnyxf8//+9z8zcOBAU65cORMYGGh69uxp/vrrryz1fPnllyYsLMyULVvW+Pn5mdq1a5u+ffuaH374wb5PamqqeeaZZ0xISIjx8PDI0gJqwYIFplGjRqZ06dKmTJky5vbbbzcjRowwJ0+eNMb8/Zro3r27uemmm4yvr6+pWLGiefjhhzOdIycZr/0NGzaYf/zjH8bX19fUrVvXfPjhh5n2y+3fOGP+bvNUt25d4+3tbUJDQ83TTz+dpcVcq1atzG233WZ++OEH06xZM+Pn52eqV69uZs2alWm/7No+GWPMkSNHTO/evU2lSpWMt7e3qVq1qnn44YfN6tWrr1tnTq/LnH6Wgdx4GMOVxwAAFJUaNWqoQYMG9jfhAHB9XEMKAAAASxFIAQAAYCkCKQAAACzFNaQAAACwFDOkAAAAsBSBFAAAAJZyisb46enpOnnypMqUKVNs77kMAACAgjPG6NKlS6pSpYo8PfM35+kUgfTkyZMO+X7SAAAAyOz333/XjTfemK9jnCKQlilTRtLfX+DV7ytts9m0ceNG+1u/wfUwxu6BcXYPjLPrY4zdQ07jHB8fr2rVqtlzW37kO5B+9dVXmjp1qnbu3KlTp07po48+UseOHXM9ZsuWLQoPD9cvv/yiatWqaezYserbt2+ez5mxTB8UFJQlkPr7+ysoKIgXvotijN0D4+weGGfXxxi7h+uNc0Eur8z3TU0JCQm64447NHv27Dztf+zYMbVv31733nuv9uzZo+eff15PPfWUNmzYkO9iAQAA4HryPUP64IMP6sEHH8zz/vPmzVPNmjU1bdo0SVK9evW0detWvf322woLC8vv6QEAAPLFGKPExESry3AZNptNSUlJKspW9sV+Den27dvVpk2bTNvCwsL0/PPP53hMcnKykpOT7Y/j4+Ml/f0NsNls9u0Z/3/1NrgWxtg9MM7ugXF2fY44xsYYtW7dWtu3b7e6FJdz+vRpBQcH2x8XZtyLPZDGxsYqNDQ007bQ0FDFx8frypUrKl26dJZjIiIiNGHChCzbN27cKH9//yzbY2Jiiq5gOCTG2D0wzu6BcXZ9jjTGSUlJhNFisnnzZvn5+dkfF2YW2iHvsh81apTCw8PtjzPu2mrXrl2Wm5piYmLUtm1bLp52UYyxe2Cc3QPj7PoccYwTEhLs///HH38oICDAwmqc2+HDhxUeHq7Zs2dr3759evjhh+Xj42P/fMaKdkEUeyCtVKmS4uLiMm2Li4tTUFBQtrOjkuTr6ytfX98s2729vbN9gee0Ha6DMXYPjLN7YJxdnyON8dV1BAcHE0gLyBijkydPKjo6WhUqVNDRo0fl4+OT6ftbmDEv9rcObdasmTZt2pRpW0xMjJo1a1bcpwYAAEAhHThwQD179tQjjzyiypUrF8s58h1IL1++rD179mjPnj2S/m7rtGfPHp04cULS38vtvXv3tu8/ePBgHT16VCNGjNCBAwc0Z84crVq1Si+88ELRfAUAAAAoFqdOndLQoUM1ffr0Yj1PvgPpDz/8oDvvvFN33nmnJCk8PFx33nmnxo0bJ+nvwjPCqSTVrFlTn3/+uWJiYnTHHXdo2rRpeu+992j5BAAA4MAOHjwoX19frVmzRpUqVSrWc+X7GtLWrVvn2ndq6dKl2R6ze/fu/J4KAAAAFvjll1/03HPPKTIyUjfccEOxn88h77IHAACOKbcm8xkN0xMSEhzmpqar77JH3q1atUqRkZGqWLFiiZyPQAoAAPLEGKMWLVpo27ZtVpeCYrJ3717FxMRk2w++OBFIAQBAniQmJjptGG3evHm2b66D/2/v3r0KDw/XypUrS/zcBFIAAJBvcXFxWXp62mw2bdiwQWFhYQ6zZJ/B399fHh4eVpfhsM6ePavg4GCtXLlSFSpUKPHzE0gBAEC+BQQEZBtI/fz8FBAQ4HCBFDnbs2ePhg8frs8++yzbNyYqCcXeGB8AAACOKSUlRZMmTVJ0dLRlYVRihhQAAMAt7dq1SwkJCVq9erXllzMwQwoAAOBmdu7cqZEjR6pBgwaWh1GJGVIAAAC3kp6erj/++EOrVq1ScHCw1eVIIpACAFBouTWLdyU0mXd+33//vebMmaMlS5ZYXUomBFIAAAqBZvFwFkePHtUrr7yi6Ohoq0vJgmtIAQAoBGduFl9QNJl3Prt379YNN9yg//znPypbtqzV5WTBDCkAAEUku2bxrogm885l+/btmjhxoqKjox329UkgBQCgiGTXLB6w2vr16xUdHa2goCCrS8kRgRQAAMAFbdu2Tbt27dKECROsLuW6CKQAAAAuZvv27Zo8ebKioqKsLiVPCKQAAAAuJDY2VlWqVFF0dLQCAwOtLidPuMseAADARXz11VcaMGCAqlat6jRhVGKGFADgYJytyTzN4uEoEhISNHv2bEVFRalUKeeKeM5VLQDApdFkHiiYLVu2yN/f3yGb3ucFS/YAAIfhzE3maRYPq3z55ZeaPn26GjRoYHUpBcYMKQDAITlbk3maxcMKqampunTpkqKiopz6DyICKQDAIdFkHsjdF198oTVr1mjOnDlWl1JoBFIAAAAn8/PPP2vWrFlauXKl1aUUCa4hBQAAcCLbtm3TTTfdpKioKJUuXdrqcooEgRQAAMBJbNiwQW+99ZZ8fHzk5+dndTlFhiV7AIBlru05Sk9PIGfGGG3fvl2RkZEuFUYlAikAwCL0HAXybt26dTp58qReffVVq0spFgRSAIAlcus5Sk9P4P/bsGGDlixZouXLl1tdSrEhkAIALHdtz1F6egJ/+/3331WvXj0tX75cvr6+VpdTbLipCQBguYyeoxkfhFFAWrt2rYYPH65q1aq5dBiVCKQAAAAO59y5c1qzZo0++OADt/gDjSV7AAAAB/Lxxx+rZs2aWrp0qdWllBhmSAEAABzEmjVrFB0drfr161tdSokikAIAADiAlJQU+fj46IMPPpC3t7fV5ZQoluwBwEld21Te0dlsNiUlJSkhIUHe3t40wQeusnr1an333XeaOnWq1aVYgkAKAE6IpvKA6/j222/18ccfu9U1o9diyR4AnFBuTeWdDU3w4c6++OIL3XbbbVq6dKlKlXLfeUL3/coBwEVc21TeUdlsNm3YsEFhYWGZro+jCT7c1cqVK/Xf//5XrVu3duswKhFIAcDpZTSTd3Q2m01+fn4KCAhwuxs2gGulpaXp2LFjWrx4sduHUYlACgAAUKJWrFghDw8PjR492upSHAbXkAIAAJSQ6Ohobdq0SV27drW6FIfCDCkAAEAJOHr0qJo3b67OnTvLy8vL6nIcCjOkAAAAxWzp0qWaMmWKbrzxRsJoNpghBQAncG0TfJrKA87j1KlT+v777zVv3jyrS3FYzJACgIPLaIIfGBho/wgNDbW6LAB58P777+vSpUuaPXu2PD2JXTnhOwMADi63Jvg0lQcc13vvvaft27fr5ptvtroUh8eSPQA4kWub4NNUHnBMSUlJuvHGG/Xkk08yM5oHBFIAcCLO0gQfcGfz589XXFycxo0bZ3UpToNACgAAUERiYmK0d+9evfvuu1aX4lQIpAAAAEXgk08+Udu2bdWmTRsupcknLmoAAAAopNmzZ2vz5s0qXbo0YbQACKQAAACFkJKSoqSkJM2YMYMwWkAs2QNACbm2uX1e0QQfcFwzZ85UjRo19OKLL1pdilMjkAJACchobp9TP1EAzmf+/Pk6ceKEnn32WatLcXoEUgAoAbk1t88rmuADjuPAgQPq0KGDKleuzDJ9ESCQAkAJu7a5fV7RBB9wDNOmTdOZM2c0ZcoUq0txGQRSAChhNLcHnNeRI0d07tw5RUREWF2KS+EuewAAgDyYMWOGfHx8NHnyZFYrihgzpAAAANcxZcoUXbp0STfeeKPVpbgkAikAAEAuEhIS1LRpU7Vu3ZqZ0WJCIAWAHBS0b2h26CUKOKfXXntNQUFBtHYqZgRSAMgGfUMBrF69WjabTc8884zVpbg8AikAZKMo+oZmh16igHNYuXKlOnXqpM6dO1tdilsgkALAdRS0b2h26CUKOL5XX31Vnp6e8vHxsboUt0EgBYDroG8o4B4yrhuvXLmyBg0aZHU5boU+pAAAwO0ZYzRu3Djt2LGDMGoBAikAAHB7U6ZMkb+/v+69916rS3FLLNkDAAC3ZYzR3r179dRTTykkJMTqctwWM6QAAMAtGWM0atQobdiwgTBqMWZIAeD/XN0In0b2gOvbu3evQkJC9OKLL1pdittjhhQA9P8b4QcGBiowMFChoaFWlwSgmBhjNGHCBFWuXJkw6iAIpACgnBvh08gecC3GGA0fPlxBQUEs0zsQluwB4BpXN8KnkT3gOowxunTpkh577DHdc889VpeDqxBIAeAaNMIHXI8xRuHh4brrrrvUq1cvq8vBNViyBwAALm/JkiWqVasWYdRBMUMKAABcljFGixcvVt++feXl5WV1OcgBM6QAAMAlGWP07LPPKiUlhTDq4JghBQAALscYo4sXL6pZs2bq0aOH1eXgOgikAJzC1U3riwON8AHXkZ6ermHDhunJJ58kjDoJAikAh5fRtD67PqEAcK2RI0fqzjvvVOPGja0uBXlEIAXg8HJqWl8caIQPOK/09HTt2rVLI0eO1A033GB1OcgHAikAp3J10/riQCN8wDmlp6dr8ODBatasGTOjTohACsCp0LQeQHa+++47NWvWTP369bO6FBQAbZ8AAIDTSktL00svvaTbbruNMOrECKQAAMAppaena+DAgbrjjjsUFBRkdTkoBJbsAQCA00lLS9OlS5c0ZMgQNWrUyOpyUEjMkAIAAKeSlpam/v376+uvvyaMughmSAEUi/w0srfZbEpKSlJCQoK8vb2zfJ6m9QCuNmvWLLVr104dOnSwuhQUEQIpgCJHI3sAxSE1NVULFy7Us88+S3s2F8OSPYAiV1yN7GlaD7iv1NRU9evXTzfccANh1AUxQwqgWOWlkb3NZtOGDRsUFhaW7ZJ9BprWA+4pPT1d58+fV5cuXVimd1EEUgDFKi+N7G02m/z8/BQQEJBrIAXgfmw2m/r27atXXnmFMOrCWLIHAAAO65lnntFjjz2munXrWl0KihEzpAAAwOHYbDbt2rVLb775Jk3v3QAzpAAAwKGkpKToiSee0KlTpwijboIZUgAA4FC+/vpr9ejRQ48++qjVpaCEEEgBAIBDSElJ0QsvvKBp06bJz8/P6nJQgliyBwAAlrPZbHriiSf04IMPEkbdEDOkAADAUsnJyUpMTNS4cePUoEEDq8uBBZghBQAAlklKSlKPHj30448/EkbdGIEUAABY5u2339ZTTz2l1q1bW10KLMSSPQAAKHFJSUlatGiRRo4cyVsCgxlSAABQspKSktS9e3fdcssthFFIYoYUAACUoLS0NJ07d07PPvus7r33XqvLgYMgkAIuzhijxMTEEj1nQkJCiZ4PgHNITExU9+7d9e677xJGkQmBFHBhxhi1aNFC27Zts7oUANDAgQP13HPP6aabbrK6FDgYAingwhITEy0No82bN5e/v79l5wfgGBITE7Vnzx7Nnz9fAQEBVpcDB0QgBdxEXFxcif8i8Pf354YFwM0lJCSoW7dueumllwijyBGBFHATAQEB/DIAUOK+/PJLvfTSS2rVqpXVpcCBFajt0+zZs1WjRg35+fmpadOm2rFjR677z5gxQ3Xq1FHp0qVVrVo1vfDCC0pKSipQwQAAwPFdvnxZAwYM0AMPPEAYxXXlO5BGR0crPDxc48eP165du3THHXcoLCxMp0+fznb/yMhIjRw5UuPHj9f+/fu1aNEiRUdHa/To0YUuHgAAOJ4rV66oW7du6tOnj0qVYjEW15fvQDp9+nQNGDBA/fr1U/369TVv3jz5+/tr8eLF2e6/bds2NW/eXD169FCNGjXUrl07de/e/bqzqgAAwPlcuXJFycnJmj59ulq0aGF1OXAS+fqzJSUlRTt37tSoUaPs2zw9PdWmTRtt374922PuueceLV++XDt27FCTJk109OhRrVu3Tr169crxPMnJyUpOTrY/jo+PlyTZbDbZbDb79oz/v3obXAtjXDjX/rw46veRcXYPjLPrO3funKZOnapq1aqpSZMmjLWLyulnuTDjna9AevbsWaWlpSk0NDTT9tDQUB04cCDbY3r06KGzZ8+qRYsWMsYoNTVVgwcPznXJPiIiQhMmTMiyfePGjdm2kImJicnPlwEnxBjnjTEm0x9zV1+rvWHDBvn5+VlRVp4xzu6BcXZdK1euVJcuXXT27FmtW7fO6nJQzK79WS7Mm7AU+4UdW7Zs0euvv645c+aoadOmOnz4sJ577jlNmjRJr7zySrbHjBo1SuHh4fbH8fHxqlatmtq1a6egoCD7dpvNppiYGLVt21be3t7F/aXAAoxx3hlj1Lp16xxXK8LCwhz2LnvG2T0wzq7r4sWLWr58uRYvXswYu4GcfpYzVrQLIl+BtEKFCvLy8lJcXFym7XFxcapUqVK2x7zyyivq1auXnnrqKUnS7bffroSEBA0cOFBjxoyRp2fWy1h9fX3l6+ubZbu3t3e2L/CctsN1MMbXl5CQkGMYbd68ucqWLevwPUEZZ/fAOLuWixcv6oknntDEiRPt48oYu4drx7kwY56vm5p8fHzUqFEjbdq0yb4tPT1dmzZtUrNmzbI9JjExMUvo9PLykvT3jA6AohcXF6fLly/bP77++muHD6MAnI/NZtOFCxf02muvqUmTJlaXAyeW77vsw8PDtXDhQr3//vvav3+/nn76aSUkJKhfv36SpN69e2e66alDhw6aO3euoqKidOzYMcXExOiVV15Rhw4d7MEUQNHKaIKf8UEYBVDULly4oIcfflj+/v5q3Lix1eXAyeX7GtKuXbvqzJkzGjdunGJjY9WwYUOtX7/efqPTiRMnMs2Ijh07Vh4eHho7dqz+/PNPhYSEqEOHDpo8eXLRfRUAAKDEGGP05JNPavLkyQoJCbG6HLiAAt3UNGzYMA0bNizbz23ZsiXzCUqV0vjx4zV+/PiCnAoAADiQ8+fPa//+/YqMjHT4zh1wHgV661AAAOB+zp07p65du8rPz48wiiLF+3kBAIA82bJli9544w3deeedVpcCF0MgBYqAMaZQDYGLQkJCgqXnB+C6/vrrLw0fPlyLFi3iJkkUCwIpUEjGGLVo0ULbtm2zuhQAKHIXL15Ut27dNG3aNMIoig2BFCikxMREhwqjzZs3z/YtdgEgv86ePStvb2+99957ql69utXlwIURSIEiFBcXZ/nbc/r7+zOLAaDQzpw5o+7du2vWrFmqW7eu1eXAxRFIgSKU0YgeAJzd22+/rRkzZhBGUSIIpAAAwO706dNatWqVXn/9datLgRuhDykAAJD092VH3bt313333Wd1KXAzzJACAAAlJyfr8uXLmjVrlurVq2d1OXAzzJACAODmTp06pfbt2yskJIQwCksQSAEAcGPp6ekaMGCAZs+eraCgIKvLgZtiyR4AADd18uRJ/fbbb1qzZo18fHysLgdujBlSAADc0J9//qknnnhCFSpUIIzCcgRSAADc0NatWzV//nzdcsstVpcCEEgBAHAnf/zxh/r3768uXboQRuEwuIYUAAA3cfr0afXu3VsLFy7kLYbhUAikAAC4gT/++ENBQUFasWKFKleubHU5QCYs2QMA4OJ+++039e7dWxcuXCCMwiExQwrkkzFGiYmJ9scJCQkWVgMA1zdr1iwtXrxYN910k9WlANkikAL5YIxRixYttG3bNqtLAYDrOn78uNatW6epU6daXQqQK5bsgXxITEzMMYw2b95c/v7+JVwRAGTv2LFjevLJJ/Xwww9bXQpwXcyQAgUUFxengIAA+2N/f3/uWgXgEBITE5WSkqKlS5eyTA+nwAwpUEABAQGZPgijABzBkSNH9Mgjj6h69eqEUTgNAikAAC7CZrPpmWee0dKlS+Xn52d1OUCesWQPAIALOHTokM6fP6+1a9eqVCl+vcO5MEMKAICTO3TokAYNGqSqVasSRuGUeNUCAODEjDH6/vvvtXz5clWpUsXqcoACIZACuaAJPgBHdvDgQU2bNk0LFiywuhSgUAikQA5ogg/AkZ04cUJDhgzRihUrrC4FKDSuIQVyQBN8AI7qyJEjKleunFatWqVKlSpZXQ5QaARSIA/i4uJ0+fJl+8fXX39N31EAlti3b58GDhyopKQklS9f3upygCLBkj2QBxnN7wHAaosWLdLKlSsVEhJidSlAkSGQAgDgBH7++Wdt375d06ZNs7oUoMixZA8AgIPbu3evnn/+eXXs2NHqUoBiwQwpAAAO7NKlSypVqpSioqJUoUIFq8sBigUzpAAAOKgff/xRnTt31i233EIYhUtjhhT4PzTBB+BIEhMTNXr0aEVGRvJ2oHB5vMIB0QQfgGPZvXu3JOnTTz+VpyeLmXB9vMoB0QQfgOPYtWuXXn75ZVWvXp0wCrfBDClwjbi4uEw9R/39/WmCD6BEGGO0b98+RUdHq1y5claXA5QYAilwDZrgA7DCDz/8oCVLlmj27NlWlwKUOAIpAAAWO3DggMaMGaPo6GirSwEswcUpAABY6JdfflHVqlX14YcfKjg42OpyAEsQSAEAsMh3332nl156ScYYBQUFWV0OYBmW7OGW6DkKwGrGGEVHRys6OpowCrdHIIXboecoAKtt375dBw8e1PTp060uBXAILNnD7dBzFICVtm3bpkmTJqlTp05WlwI4DGZI4dboOQqgJJ0/f17BwcGKjo5WmTJlrC4HcBjMkMKtZfQczfggjAIoLl9//bX69u2runXrEkaBaxBIAQAoZhcuXND06dO1YsUK3g4UyAZL9gAAFKP//e9/qlChgtasWcMqDJAD/kwDAKCYbNmyRW+99ZZq1KhBGAVywQwpAADFID09XX/++aeio6Pp3gFcB4EULo8m+ABK2qZNm7Ru3TpNmzbN6lIAp0AghUujCT6AkrZz50698847ioqKsroUwGlwDSlcGk3wAZSkH374QXXq1FFUVJRKly5tdTmA02CGFG6DJvgAitOGDRs0b948rVy5Un5+flaXAzgVAincRkbzewAoaunp6friiy8Io0ABEUgBACiE9evX68KFC5o6darVpQBOi2tIAQAooP/+979677339O9//9vqUgCnRiAFAKAAzpw5oxo1amjFihXy9fW1uhzAqRFIAQDIp08//VTPPfec6tatSxgFigDXkMKl0AQfQHGLjY3VypUrtXTpUjp1AEWEGVK4jIwm+IGBgfaP0NBQq8sC4EI+++wzXb58WStWrJCPj4/V5QAug0AKl0ETfADF6aOPPtLy5ctVvXp1ZkaBIsaSPVwSTfABFKW0tDQlJSVp2bJl8vb2trocwOUQSOGSaIIPoKj85z//0Z49ezRp0iSrSwFcFoEUAIAc/O9//9OaNWu0dOlSq0sBXBqBFACAbGzdulWNGjXS+++/r1Kl+HUJFCduagIA4BrR0dFasGCB/Pz8CKNACSCQAgBwFZvNpp9++kmLFy8mjAIlhJ80AAD+T2RkpAIDAzV58mSrSwHcCjOkAABIWrlypWJiYtS+fXurSwHcDjOkAAC3d/LkSd11113q0qWLvLy8rC4HcDsEUgCAW/vggw+0bds2zZs3z+pSALdFIAUAuK1jx47pm2++0Zw5c6wuBXBrXEMKAHBLK1asUKlSpTR//nyW6QGLEUgBAG5n8eLF+vrrr1W1alWrSwEgAikAwM2kpqYqKChIc+bMkacnvwYBR8A1pHAKxhglJCTkus/1Pg8ACxYs0IULFzRixAirSwFwFQIpHJ4xRq1bt9b27dutLgWAE/v000/1448/6t1337W6FADXIJDC4SUnJ+crjDZv3lz+/v7FWBEAZxMTE6P77rtP7du3Z5kecEAEUjiVuLg4BQQE5LqPv7+/PDw8SqgiAI5uzpw52r9/v9q0acO/DYCDIpDCqQQEBFw3kAJAhsTERJ0/f17vvPMOYRRwYARSAIBLmjVrlurVq6cxY8ZYXQqA6+BCGgCAy5kzZ46OHj2q++67z+pSAOQBM6QAAJdy4sQJhYWF6emnn2aZHnASzJACAFzG22+/rXnz5ql27dqEUcCJMEMKh2OMUWJioiTJZrMpKSnJ4ooAOIOff/5ZcXFxioiIsLoUAPlEIIVDMcaoRYsW2rZtm9WlAHAic+fOVadOnTRlyhSrSwFQAARSOJTExMQcwygN7wFk580339T58+cVEhJidSkACohACocVFxcnHx8fbdiwQWFhYSpbtizXhAHIJDk5WXXr1lWHDh349wFwYgRSOKyAgAD5+PjIz89PAQEB/LIBkMnrr7+u8uXLa9CgQVaXAqCQuMseAOB0li1bpqSkJA0cONDqUgAUAWZIAQBOZe3atXr88cfl6+vLygngIpghBQA4jYkTJ2r37t3y8/MjjAIuhBlSAIBTuHDhgsqWLavnnnvO6lIAFDFmSGEpY4wSEhIyfQDA1YwxevXVV/Xrr78SRgEXxQwpLEMTfAB5MXnyZHl7e6tJkyZWlwKgmBBIYZm8NMFPTU0t4aoAOApjjI4cOaLevXvrpptusrocAMWIQAqHEBcXp4CAAPtjf39/blgA3JgxRmPGjFH58uX14osvWl0OgGJGIIVDCAgIyBRIAbi37777TsHBwYRRwE1wUxMAwGEYYzRlyhTVq1dPI0aMsLocACWEQAoAcAjGGL388svy8fFR2bJlrS4HQAliyR4AYDljjK5cuaI2bdqoXbt2VpcDoIQRSAEAljLG6MUXX1TTpk3VtWtXq8sBYAECKYqEMUaJiYn5OoYm+AAkafbs2apRowZhFHBjBFIUGg3uARSEMUYffvihBg8erFKl+HUEuLMC3dSU8desn5+fmjZtqh07duS6/4ULFzR06FBVrlxZvr6+uvXWW7Vu3boCFQzHk1uD+7zIaIIPwH0YY/Tcc8/pzJkzhFEA+Z8hjY6OVnh4uObNm6emTZtqxowZCgsL08GDB1WxYsUs+6ekpKht27aqWLGiVq9erapVq+q3335TcHBwUdQPB3Ntg/u8oAk+4H5Onz6tO++8U/369bO6FAAOIN+BdPr06RowYID9H5F58+bp888/1+LFizVy5Mgs+y9evFjnzp3Ttm3b5O3tLUmqUaNG4aqGw6LBPYDcpKen6/nnn9fQoUMJowDs8rVkn5KSop07d6pNmzb//wk8PdWmTRtt374922PWrl2rZs2aaejQoQoNDVWDBg30+uuvKy0trXCVAwCcztKlS9WgQQPVr1/f6lIAOJB8zZCePXtWaWlpCg0NzbQ9NDRUBw4cyPaYo0ePavPmzerZs6fWrVunw4cPa8iQIbLZbBo/fny2xyQnJys5Odn+OD4+XpJks9lks9ns2zP+/+ptKHnXjklRjgdj7B4YZ9eXnp6uffv2qWPHjuratStj7aL4WXYPOY1zYca92K8kT09PV8WKFbVgwQJ5eXmpUaNG+vPPPzV16tQcA2lERIQmTJiQZfvGjRuzvfklJiamyOtG3iUlJdn/f8OGDfLz8yvyczDG7oFxdk3p6emaP3++br31Vt1///2MsxtgjN3DteOc3/aPV8tXIK1QoYK8vLwUFxeXaXtcXJwqVaqU7TGVK1eWt7e3vLy87Nvq1aun2NhYpaSkyMfHJ8sxo0aNUnh4uP1xfHy8qlWrpnbt2ikoKMi+3WazKSYmRm3btrVfn4q8KUjf0Jxc3U80LCysSK8hZYzdA+Ps2jZt2qROnTqpZ8+ejLOL42fZPeQ0zhkr2gWRr0Dq4+OjRo0aadOmTerYsaOkv//y3bRpk4YNG5btMc2bN1dkZKTS09Pl6fn3Jau//vqrKleunG0YlSRfX1/5+vpm2e7t7Z3tCzyn7checfYNLa6xYIzdA+PsWtLT0zV+/HiNHj1apUuXti/nMc6ujzF2D9eOc2HGPN99SMPDw7Vw4UK9//772r9/v55++mklJCTY75bs3bu3Ro0aZd//6aef1rlz5/Tcc8/p119/1eeff67XX39dQ4cOLXDRKJzC9g3NCf1EAWRIS0vTwIEDdfPNN6t06dJWlwPAweX7GtKuXbvqzJkzGjdunGJjY9WwYUOtX7/efqPTiRMn7DOhklStWjVt2LBBL7zwgv7xj3+oatWqeu655/Tyyy8X3VeBAitI39Cc0E8UgPR3GL1y5Yr69Omjli1bWl0OACdQoJuahg0bluMS/ZYtW7Jsa9asmb799tuCnArFjL6hAIpSWlqannrqKXXt2lUPPPCA1eUAcBIFeutQAACy8+abb6pNmzaEUQD5whsIAwAKLTU1VdHR0RoxYkSmrioAkBfMkAIACiU1NVVPPvmkvLy8CKMACoQZUgBAgRljdOrUKT366KPq1KmT1eUAcFLMkLoBY4wSEhIyfQBAYaWmpqpPnz5KT08njAIoFGZIXVxxNsEH4N4GDRqkRx55RNWrV7e6FABOjkDq4nJrgk8jewAFYbPZ9Ouvv2rKlCkKCQmxuhwALoBA6kaubYJPI3sA+WWz2dS7d2917dpVt912m9XlAHARBFI3QhN8AIW1bt06de3aVR07drS6FAAuhEAKALiulJQUjR49WlOmTFGpUvzqAFC0uMseAJCrlJQUPfHEE2rVqhVhFECx4F8WAECOkpOTlZKSouHDh+vuu++2uhwALooZUgBAtpKTk9WzZ0/99NNPhFEAxYoZUidhjFFiYmK+j6MJPoCCmjRpkp588kk1b97c6lIAuDgCqROguT2AkpSUlKTo6GhNmjSJ1nAASgRL9k4gt+b2eUUTfAB5kZSUpO7du6tSpUqEUQAlhhlSJ3Ntc/u8ogk+gOsxxuiPP/7QkCFD1LZtW6vLAeBGCKROhub2AIrDlStX9MQTT2ju3LmEUQAljiV7AHBzxhj16dNHQ4YMUcWKFa0uB4AbYoYUANxYYmKijhw5ogULFig4ONjqcgC4KWZIAcBNJSQkqGvXrjp79ixhFIClmCEFADf16aef6sUXX1Tr1q2tLgWAmyOQAoCbSUhI0JgxYzR9+nR5erJQBsB6/EsEAG4kY5m+U6dOhFEADoMZUgBwE5cvX5YkRURE6Pbbb7e4GgD4//jzGADcwKVLl9SlSxcdOXKEMArA4RBIAcANTJgwQWPHjtUdd9xhdSkAkAVL9gDgwuLj47VmzRpNnTqVtw8G4LCYIQUAF3Xx4kV16dJFdevWJYwCcGjMkAKAC0pPT9eff/6pCRMmqGnTplaXAwC5YoYUAFzMhQsX1KFDB1WtWpUwCsApEEgBwIWkp6friSee0KuvvqqyZctaXQ4A5AlL9gDgIs6fP6/ff/9dK1euVJkyZawuBwDyjBlSAHAB58+fV9euXZWamkoYBeB0CKQA4ALWrl2rKVOm6K677rK6FADIN5bsAcCJnTt3Tq+++qpmzpxJaycATosZUgBwUufPn1e3bt3Uv39/wigAp8YMKQA4oXPnzsnb21uzZ8/WLbfcYnU5AFAozJACgJM5e/asunTpotjYWMIoAJfADKnFjDFKTEzMdZ+EhIQSqgaAM5gwYYLefvttwigAl0EgtZAxRi1atNC2bdusLgWAEzh9+rTWrVund955h2tGAbgUluwtlJiYmK8w2rx5c/n7+xdjRQAc1enTp9W9e3c1adKEMArA5TBD6iDi4uIUEBCQ6z7+/v78IgLcUGpqqk6dOqV3331X9evXt7ocAChyBFIHERAQcN1ACsD9xMbGqk+fPvr4449VunRpq8sBgGLBkj0AOCibzaY+ffpo5syZhFEALo0ZUgBwQKdOndJff/2ljz76iGvHAbg8ZkgBwMGcPHlSPXv2lI+PD2EUgFtghhQAHMy6des0f/58+owCcBsEUgBwEH/++afefPNNzZw50+pSAKBEEUgBwAGcOnVKvXr10oIFC6wuBQBKHIEUACwWGxurwMBALV26VDfddJPV5QBAieOmJgCw0IkTJ9S9e3fFx8cTRgG4LQIpAFgoIiJCixcvVtWqVa0uBQAsw5I9AFjgt99+01dffaW5c+daXQoAWI4ZUgAoYcePH1e/fv30r3/9y+pSAMAhEEgBoASlpKTor7/+0pIlS1S9enWrywEAh0AgBYAScvToUT3yyCP6xz/+QRgFgKtwDSkAlIArV65o0KBBWrx4sby9va0uBwAcCoEUAIrZ4cOHZbPZ9Nlnn8nX19fqcgDA4bBkDwDF6PDhwxo0aJCCgoIIowCQAwIpABSjTZs26YMPPqDPKADkgiV7ACgGv/76q+bPn69p06ZZXQoAODwCKQAUsaNHj+rpp5/W8uXLrS4FAJwCgRQAitCJEycUEhKiyMhIhYaGWl0OADgFriEFgCKyf/9+9evXTykpKYRRAMgHZkhLkDFGiYmJ9scJCQkWVgOgKBlj9PbbbysyMlLly5e3uhwAcCoE0hJijFGLFi20bds2q0sBUMR++eUX/fTTT1qwYIHVpQCAU2LJvoQkJibmGEabN28uf3//Eq4IQFH4+eef9dxzz6lNmzZWlwIATosZUgvExcUpICDA/tjf318eHh4WVgSgIJKSkpSYmKiVK1cqJCTE6nIAwGkxQ2qBgICATB+EUcD5/PTTT+rcubMaN25MGAWAQmKGFADy6eLFixo+fLgiIyPl6cnf9QBQWARSAMiHPXv2KCAgQJ999pm8vb2tLgcAXAJ/2gNAHu3evVsjRoxQ+fLlCaMAUIQIpACQR999952ioqJ0ww03WF0KALgUluyLCU3wAdexc+dOffjhh5oyZYrVpQCASyKQFgOa4AOu4+eff9bo0aMVHR1tdSkA4LJYsi8GNMEHXMOhQ4d00003KTo6WsHBwVaXAwAui0BazOLi4nT58mX7x9dff03fUcAJ7NixQ8OGDZOHhwdhFACKGUv2xSyj+T0A55Genq5FixZp1apVKlOmjNXlAIDLI5ACwFW+/fZb/fnnn5o/f77VpQCA22DJHgD+z/bt2zVx4kS1bdvW6lIAwK0wQwoA+rs1m5eXl6Kjo1mmB4ASxgwpALe3detW9enTR3fffTdhFAAswAxpEaAJPuC8Tp8+rTfeeEMrV66kAwYAWIQZ0kLKaIIfGBho/wgNDbW6LAB5sHXrViUmJurjjz9WYGCg1eUAgNsikBYSTfAB5/S///1Pb7zxhkJCQuTl5WV1OQDg1liyL0JxcXGZeo76+/uzBAg4IGOM9u/fr6ioKPoEA4ADIJAWIZrgA47vyy+/1JYtWzRhwgSrSwEA/B8CKQC38e2332rGjBlauXKl1aUAAK7CNaQA3MLPP/+sevXqaeXKlVzbDQAOhkAKwOXFxMTolVdeka+vL2EUABwQgRSAS0tNTdXHH3+slStXys/Pz+pyAADZ4BpSAC5rw4YNstlsmj17ttWlAABywQwpAJe0fv16LViwQG3atLG6FADAdTBDCsDlxMfHq3z58oqMjJSvr6/V5QAAroMZUgAu5bPPPtMzzzyju+++mzAKAE6CGVIALuO3337TBx98oGXLllldCgAgH5ghBeAS/vvf/6pUqVKKiopiZhQAnAyBFIDT++STT/T+++8rJCREnp78swYAzoZ/uQE4NWOM4uLi9MEHH8jHx8fqcgAABcA1pACc1po1a/Trr79q5MiRVpcCACgEAikApxQTE6PVq1fr/ffft7oUAEAhEUgBOJ2dO3eqSZMmat26tby9va0uBwBQSFxDCsCprFq1Sm+//bYCAgIIowDgIgikAJzGlStX9O2332rp0qUqVYoFHgBwFfyLDsApREVFqWLFipo+fbrVpQAAihgzpAAc3sqVK7V+/Xr961//sroUAEAxYIYUgEM7d+6c6tatqy5dusjLy8vqcgAAxYBACsBhLVu2TN99951mzZpldSkAgGLkFoHUGKPExMRiee6EhIRieV7A3e3bt09btmzRggULrC4FAFDMCnQN6ezZs1WjRg35+fmpadOm2rFjR56Oi4qKkoeHhzp27FiQ0xaIMUYtWrRQYGBgsXyEhoaW2NcCuIsPP/xQISEheu+991imBwA3kO9AGh0drfDwcI0fP167du3SHXfcobCwMJ0+fTrX444fP66XXnpJLVu2LHCxBZGYmKht27YV+3maN28uf3//Yj8P4OqWLFmimJgYlS9fXh4eHlaXAwAoAflesp8+fboGDBigfv36SZLmzZunzz//XIsXL87x/aTT0tLUs2dPTZgwQV9//bUuXLhQqKILKi4uTgEBAcXy3P7+/vzyBAopPT1d0t//rnh60gQEANxFvgJpSkqKdu7cqVGjRtm3eXp6qk2bNtq+fXuOx02cOFEVK1ZU//799fXXXxe82kIKCAgotkAKoHBiYmJ07NgxPf/881aXAgAoYfkKpGfPnlVaWlqW6yZDQ0N14MCBbI/ZunWrFi1apD179uT5PMnJyUpOTrY/jo+PlyTZbDbZbDb79oz/v3rbta7dP7d94XjyMsZwfqtWrdKRI0c0ZcoUxtqF8fPs+hhj95DTOBdm3Iv1LvtLly6pV69eWrhwoSpUqJDn4yIiIjRhwoQs2zdu3JjtdZoxMTE5PldSUpL9/zds2CA/P7881wHHkdsYw7kdOHBAN910kwYOHKhNmzZZXQ5KAD/Pro8xdg/XjnNhOhp5GGNMXndOSUmRv7+/Vq9enelO+T59+ujChQv65JNPMu2/Z88e3XnnnZnuks24RszT01MHDx5U7dq1s5wnuxnSatWq6ezZswoKCrJvt9lsiomJUdu2beXt7Z1tzQkJCSpXrpwk6fz58yzZO5m8jDGc14IFC/TLL79o6tSp+uKLLxhnF8fPs+tjjN1DTuMcHx+vChUq6OLFi5nyWl7ka4bUx8dHjRo10qZNm+yBND09XZs2bdKwYcOy7F+3bl3t3bs307axY8fq0qVLmjlzpqpVq5bteXx9feXr65tlu7e3d7Yv8Jy2Z3wuL/vBsTF2rufixYs6deqUZs+erdTUVEmMs7tgnF0fY+werh3nwox5vpfsw8PD1adPHzVu3FhNmjTRjBkzlJCQYL/rvnfv3qpataoiIiLk5+enBg0aZDo+ODhYkrJsB+A+5syZo0aNGum1116zuhQAgAPIdyDt2rWrzpw5o3Hjxik2NlYNGzbU+vXr7Tc6nThxgnYtAHI0e/ZsHTp0SE8//bTVpQAAHESBbmoaNmxYtkv0krRly5Zcj126dGlBTgnABZw+fVotW7bUkCFD6NsLALBzi/eyB2C9GTNm6OzZsyzTAwCyIJACKHY7duzQH3/8oalTp1pdCgDAAXGxJ4BitWjRItWpU0dTp05lmR4AkC1mSAEUm6lTp+qvv/5SUFAQYRQAkCMCKYBikZqaqipVquill14ijAIAckUgBVDkpkyZosqVK6tPnz5WlwIAcAJcQwqgSC1atEgJCQnq3bu31aUAAJwEM6QAiszmzZvVrVs3+fv7s0wPAMgzAimAIjFp0iSlpaXpvvvus7oUAICTIZACKLTTp0/L19dXI0aMsLoUAIAT4hpSAIUyceJEnT59mjAKACgwAimAAps4caI8PT3VoEEDq0sBADgxluwB5JsxRqdOnVKXLl1Ut25dq8sBADg5ZkgB5IsxRq+88oqioqIIowCAIkEgBZAvmzZtUmBgoMLDw60uBQDgIliyB5AnxhjNnDlTgwYNUps2bawuBwDgQpghBXBdxhiNHDlSqampKl26tNXlAABcDDOkAHJljFFycrKaNWumjh07Wl0OAMAFEUgB5MgYo+HDh6tFixaEUQBAsWHJHkCOpk+frmrVqhFGAQDFihlSAFkYY7R+/XoNHTpUfn5+VpcDAHBxzJACyMQYo+eff15HjhwhjAIASgQzpAAyOXHihG677TYNHDjQ6lIAAG6CGVIAkv6eGX3hhReUnp5OGAUAlCgCKQBJ0gsvvKA6deqoZs2aVpcCAHAzLNkDbi49PV1//PGHnn32WdWqVcvqcgAAbogZUsCNpaena+jQodq8eTNhFABgGQIp4MbWrl2rRo0aqW/fvlaXAgBwYyzZA24oPT1dERERGjFihLy9va0uBwDg5pghBdxMenq6Bg0apKpVqxJGAQAOgRlSwI2kpaUpKSlJnTt3VlhYmNXlAAAgiRlSwG2kpaVpwIAB2rFjB2EUAOBQCKSAm5gwYYLuu+8+3XvvvVaXAgBAJizZAy4uLS1Nn3/+ucaOHSsfHx+rywEAIAtmSAEXlpqaqieffFIJCQmEUQCAw2KGFHBhR44cUfv27dWlSxerSwEAIEfMkAIuKDU1Vf3791fZsmUJowAAh0cgBVyMMUb9+/fXAw88oEqVKlldDgAA18WSPeBCbDab/vjjD7322muqVq2a1eUAAJAnzJACLsJms6l379768ccfCaMAAKdCIAVcxKpVq/T444+rY8eOVpcCAEC+sGQPOLmUlBRNnjxZ48ePl6cnf2MCAJwPv70AJ5aSkqJevXrprrvuIowCAJwWM6SAk0pJSVFycrKGDRumli1bWl0OAAAFxpQK4ISSk5PVs2dPHThwgDAKAHB6BFLACY0ePVp9+/bV3XffbXUpAAAUGkv2gBNJSkrSunXr9MYbb6hUKX58AQCugRlSwEkkJSWpR48e8vf3J4wCAFwKv9UAJ/Hrr79q0KBBCgsLs7oUAACKFDOkgIO7cuWKunXrpptuuokwCgBwSQRSwIGlp6erZ8+e6t+/v4KDg60uBwCAYsGSPeCgEhMTFRsbqzlz5qhSpUpWlwMAQLFhhhRwQImJierevbt+++03wigAwOURSAEHFBkZqeeee0733nuv1aUAAFDsWLIHHEhCQoJef/11vfbaa/Lw8LC6HAAASgQzpICDSEhIUNeuXdWuXTvCKADArTBDCjiAxMREpaWl6dVXX1Xjxo2tLgcAgBLFDClgscuXL+vxxx/Xn3/+SRgFALglAilgseHDh2v06NGqV6+e1aUAAGAJluwBi1y6dEkbN27U7Nmz5enJ34YAAPfFb0HAAvHx8erSpYuqVKlCGAUAuD1mSIESZozRgQMHNH78eP3zn/+0uhwAACzH1AxQgi5evKjHHntMDRo0IIwCAPB/CKRACUlNTVW3bt00atQo+fv7W10OAAAOgyV7oARcuHBB586d07Jly1ShQgWrywEAwKEwQwoUs/Pnz6tLly46d+4cYRQAgGwwQwoUs5UrVyoiIkKNGjWyuhQAABwSgRQoJufOndO0adM0efJkq0sBAMChsWQPFINz586pW7du6ty5s9WlAADg8JghBYpYfHy8vLy8NGPGDNWvX9/qcgAAcHjMkAJF6OzZs3rsscd0/vx5wigAAHlEIAWK0IgRIzR9+nTVqFHD6lIAAHAaLNkDReDMmTP66quvtGjRInl4eFhdDgAAToUZUqCQTp8+rW7duqlOnTqEUQAACoAZUqAQjDH69ddf9c477+i2226zuhwAAJwSM6RAAcXFxenRRx9V06ZNCaMAABQCM6RAASQlJalnz55699135e3tbXU5AAA4NQIpkE+nTp1ScnKyVq9ereDgYKvLAQDA6bFkD+TDqVOn1LNnTyUnJxNGAQAoIgRSIB+io6M1d+5c1alTx+pSAABwGSzZA3nw559/au7cuXrttdesLgUAAJfDDClwHSdPnlTv3r3Vt29fq0sBAMAlMUMK5OKvv/5S6dKltXDhQtWqVcvqcgAAcEnMkAI5+P333/X4448rJSWFMAoAQDFyuRlSY4wSExPtjxMSEiysBs7KGKPRo0frvffeU2hoqNXlAADg0lwqkBpj1KJFC23bts3qUuDEfvvtN+3atUsffPAB700PAEAJcKkl+8TExBzDaPPmzeXv71/CFcHZHD9+XP369dOdd95JGAUAoIS41Azp1eLi4hQQEGB/7O/vT8BArtLS0nT8+HEtXrxYNWrUsLocAADchssG0oCAgEyBFMjNsWPH9Pzzz+ujjz6Sp6dLLRwAAODwXDaQAnkVHx+v/v37a+nSpYRRAAAsQCCFWzty5Ih8fHy0du1aBQYGWl0OAABuiekguK3Dhw9r4MCB8vT0JIwCAGAhAinc1ieffKIPPvhAVatWtboUAADcGkv2cDuHDh3S8uXLNWHCBKtLAQAAIpDCzRw+fFiDBw/WsmXLrC4FAAD8HwIp3EZsbKxuuOEGLV++XJUrV7a6HAAA8H+4hhRu4cCBA+rRo4c8PT0JowAAOBgCKVyeMUaTJk1SZGSkgoODrS4HAABcgyV7uLR9+/bpyJEjWrFihdWlAACAHDBDCpf1yy+/6Nlnn1XTpk2tLgUAAOSCQAqXlJqaqri4OEVGRqpixYpWlwMAAHJBIIXL2bt3r7p166Z7772XMAoAgBPgGlK4lDNnzig8PFwrV66Uh4eH1eUAAIA8YIYULmPv3r2y2Wxau3atKlSoYHU5AAAgjwikcAl79uzRiy++KF9fX5UuXdrqcgAAQD6wZA+XEBMTo6ioKN1www1WlwIAAPKJQAqntmvXLq1bt05jx461uhQAAFBABFI4rR9//FGjRo1SVFSU1aUAAIBC4BpSOKXff/9dVapUUVRUlMqVK2d1OQAAoBAIpHA633//vZ566ikFBAQQRgEAcAEFCqSzZ89WjRo15Ofnp6ZNm2rHjh057rtw4UK1bNlS5cqVU7ly5dSmTZtc9wdyk5qaqpkzZ2rVqlXy9/e3uhwAAFAE8h1Io6OjFR4ervHjx2vXrl264447FBYWptOnT2e7/5YtW9S9e3d9+eWX2r59u6pVq6Z27drpzz//LHTxcC/fffedNm3apOXLl6ts2bJWlwMAAIpIvgPp9OnTNWDAAPXr10/169fXvHnz5O/vr8WLF2e7/4oVKzRkyBA1bNhQdevW1Xvvvaf09HRt2rSp0MXDfXz33Xd69dVX1axZM6tLAQAARSxfd9mnpKRo586dGjVqlH2bp6en2rRpo+3bt+fpORITE2Wz2XLtF5mcnKzk5GT74/j4eEmSzWaTzWazb8/4/2v/m92+cE4Z43jx4kUtX75cpUuXZlxdUHY/w3A9jLPrY4zdQ07jXJhxz1cgPXv2rNLS0hQaGpppe2hoqA4cOJCn53j55ZdVpUoVtWnTJsd9IiIiNGHChCzbN27cmO11gzExMZKkpKQk+7YNGzbIz88vTzXBcR04cEDr1q1TeHi4tm7danU5KGYZP8twbYyz62OM3cO145yYmFjg5yrRPqRTpkxRVFSUtmzZkmtYHDVqlMLDw+2P4+Pj7deeBgUF2bfbbDbFxMSobdu28vb2VkJCgv1zYWFhCggIKJ4vBCXixIkTmjt3rp5++mn7GMM1XfuzDNfEOLs+xtg95DTOGSvaBZGvQFqhQgV5eXkpLi4u0/a4uDhVqlQp12PfeustTZkyRV988YX+8Y9/5Lqvr6+vfH19s2z39vbO9gWesf3qz+W0L5zDt99+q1q1amn16tXatGkT4+kmGGf3wDi7PsbYPWSXvQoqXzc1+fj4qFGjRpluSMq4QSm3m03efPNNTZo0SevXr1fjxo0LXCzcw1dffaXJkycrICAg2z9MAACAa8n3kn14eLj69Omjxo0bq0mTJpoxY4YSEhLUr18/SVLv3r1VtWpVRURESJLeeOMNjRs3TpGRkapRo4ZiY2MlSYGBgQoMDCzCLwWuYseOHYqKilJAQAAXxgMA4AbyHUi7du2qM2fOaNy4cYqNjVXDhg21fv16+41OJ06ckKfn/594nTt3rlJSUtS5c+dMzzN+/Hi9+uqrhaseLmXLli36/vvvNXz4cKtLAQAAJahANzUNGzZMw4YNy/ZzW7ZsyfT4+PHjBTkF3MzWrVs1ffp0RUVFWV0KAAAoYbyXPSx35MgR1alTR1FRUbwdKAAAbohACkt98cUXCg8PV3BwMGEUAAA3RSCFZZKSkhQZGamoqCjagwAA4MZKtDE+kGHjxo3y9fXV4sWLrS4FAABYjBlSlLgNGzZo3rx5atq0qdWlAAAAB0AgRYlKSkqSj4+PIiMjc337WAAA4D5YskeJWbdunT7++GMtWLDA6lIAAIADIZCiRBw4cEBLlizR8uXLrS4FAAA4GJbsUew2bdqkkJAQrVy5kvemBwAAWRBIUazWrl2r+fPnq0yZMipVigl5AACQFYEUxcYYo8OHD2v58uXy8fGxuhwAAOCgmLJCsfj444/1+++/Kzw83OpSAACAgyOQositW7dO0dHR+uCDD6wuBQAAOAECKYrU/v37dffdd6tt27a8HSgAAMgTriFFkVm9erVee+01lS9fnjAKAADyjECKIhEfH6/Nmzfr/fffl6cnLysAAJB3LNmj0KKjo1WzZk3NmTPH6lIAAIATYioLhRIVFaXPP/9cd911l9WlAAAAJ0UgRYFdvnxZVapU0eLFi2l6DwAACowUgQJZvny5du3apenTp1tdCgAAcHIEUuTbDz/8oM2bN2vhwoVWlwIAAFwAS/bIl08++US33HKLFi5cKC8vL6vLAQAALoBAijxbunSpPvvsM5UpU4YwCgAAigyBFHmSnp6u+Ph4zZ8/nz6jAACgSHENKa5r8eLFkqRnn33W4koAAIArYqoLuVq5cqV27Nihvn37Wl0KAABwUcyQIkc//vij2rZtq65du7JMDwAAig0pA9maP3++FixYoPLlyxNGAQBAsSJpIIszZ87oyJEjmjVrljw8PKwuBwAAuDgCKTKZN2+eYmNj9eabbxJGAQBAiSCQwm727Nnav3+/GjRoYHUpAADAjXBTEyRJFy9e1F133aUhQ4YwMwoAAEoUgRSaOXOmLly4oPHjx1tdCgAAcEMEUjf35Zdf6sSJE3rrrbesLgUAALgpAqkbW7FihTp27KjWrVuzTA8AACzDTU1uatq0afrxxx/l7+9PGAUAAJZihtQN2Ww2BQUFKTw8nDAKAAAsRyB1M2+++aZq1qypAQMGWF0KAACAJJbs3crcuXN18eJFde7c2epSAAAA7JghdRPff/+9unXrpuDgYJbpAQCAQ2GG1A1MnjxZa9euVbly5QijAADA4RBIXdyJEyckSRMnTrS4EgAAgOwRSF1YRESEUlNTNWbMGGZGAQCAw+IaUhc1YcIEeXh4qFatWlaXAgAAkCsCqYsxxujcuXN6+OGH1ahRI6vLAQAAuC4CqQsxxmjcuHEKCQnRs88+a3U5AAAAecI1pC5k7dq18vf3J4wCAACnwgypCzDGaMGCBerXr58effRRq8sBAADIF2ZInZwxRqNGjVJ8fLx8fHysLgcAACDfmCF1YsYYJSUl6fbbb1fPnj2tLgcAAKBAmCF1UsYYvfzyy/rqq68IowAAwKkRSJ1URESEKleurLCwMKtLAQAAKBSW7J2MMUbffPONhg0bpqCgIKvLAQAAKDRmSJ2IMUbh4eHatWsXYRQAALgMZkidyK+//qpbbrlFQ4YMsboUAACAIsMMqRMwxmjEiBEKCgoijAIAAJdDIHVwxhg999xzqlmzpipXrmx1OQAAAEWOJXsHlp6errNnz2rgwIFq0KCB1eUAAAAUC2ZIHVR6erqGDRumDRs2EEYBAIBLI5A6qMjISN15553q1auX1aUAAAAUK5bsHUx6erreeecdPfvss/L05O8FAADg+kg8DiQ9PV2DBw9WUFAQYRQAALgNZkgdRHp6uhISEtS+fXs9+uijVpcDAABQYpiGcwBpaWkaOHCgfv75Z8IoAABwOwRSBzB69Gi1atVKzZo1s7oUAACAEseSvYXS0tL01Vdfafz48fL397e6HAAAAEswQ2qRtLQ0PfXUUzp58iRhFAAAuDVmSC2yd+9etWvXTt27d7e6FAAAAEsxQ1rCUlNT9fTTT6t69eqEUQAAABFIS5QxRv369VPr1q1Vrlw5q8sBAABwCCzZl5DU1FSdPXtWY8eOVZ06dawuBwAAwGEwQ1oCbDab+vTpo++//54wCgAAcA0CaQlYvHixHnvsMXXo0MHqUgAAABwOS/bFyGaz6e2339bw4cPl4eFhdTkAAAAOiRnSYpKSkqJevXrp1ltvJYwCAADkghnSYmCz2ZSYmKinnnpKbdq0sbocAAAAh8YMaRFLSUlRz5499fvvvxNGAQAA8oBAWsReeOEF9e7dW7fffrvVpQAAADgFluyLSHJysr766itNmzZNfn5+VpcDAADgNJghLQLJycnq2bOnUlNTCaMAAAD5xAxpEdi5c6eeeuopPfDAA1aXAgAA4HSYIS2EpKQk9e3bV3fccQdhFAAAoIAIpAWUmpqq7t27q0ePHgoICLC6HAAAAKfFkn0BXLlyRRcvXtT06dNVs2ZNq8sBAABwasyQ5lNiYqK6deumgwcPEkYBAACKAIE0nxYsWKBnn31WrVq1sroUAAAAl8CSfR4lJCTonXfe0ahRo6wuBQAAwKUwQ5oHCQkJ6tatm5o1a2Z1KQAAAC6HGdLrSE5OVlJSkkaPHk0gBQAAKAbMkObi8uXL6tSpky5evEgYBQAAKCYE0lwMGzZMI0eOVK1atawuBQAAwGWxZJ+NS5cuafv27Vq4cKG8vb2tLgcAAMClMUN6jUuXLqlr164KDAwkjAIAAJQAZkiv8f333+uVV17hmlEAAIASQiD9P/Hx8Ro8eLCWLl0qHx8fq8sBAABwGyzZS0pKSlKXLl30/PPPE0YBAABKmNvPkF64cEHJyclatGiRqlatanU5AAAAbsetZ0gvXLigrl276s8//ySMAgAAWMStA+n8+fM1efJk3XXXXVaXAgAA4Lbccsn+/PnzmjdvnkaNGmV1KQAAAG7P7WZIz507p65duyosLMzqUgAAACA3myFNTExUamqqpk6dqjvuuMPqcgAAACA3miH966+/9OijjyotLY0wCgAA4ECceobUGKOkpCQlJCTI29tbCQkJOe47dOhQvfXWW6pcuXIJVggAAIDrcdpAaoxR69attX379lz3O3v2rHbt2qXly5erVCmn/XIBAABcltMu2ScmJuYYRps3by5/f3+dOXNG3bp1U5UqVQijAAAADsolUtoff/yh4OBg+2N/f39J0s6dOzVjxgw1aNDAosoAAABwPS4RSAMCAhQQEGB/fPr0aT3zzDOKjIyUl5eXhZUBAADgelwikF7t0qVL6tGjh9555x3CKAAAgBNwqUAaGxsrLy8vrVixQqGhoVaXAwAAgDwo0E1Ns2fPVo0aNeTn56emTZtqx44due7/4Ycfqm7duvLz89Ptt9+udevWFajY3Jw6dUo9e/bU+fPnCaMAAABOJN+BNDo6WuHh4Ro/frx27dqlO+64Q2FhYTp9+nS2+2/btk3du3dX//79tXv3bnXs2FEdO3bUzz//XOjir7Zo0SLNmTNHt956a5E+LwAAAIpXvgPp9OnTNWDAAPXr10/169fXvHnz5O/vr8WLF2e7/8yZM/XAAw9o+PDhqlevniZNmqS77rpLs2bNKnTxGd5++22NHTtWderUKbLnBAAAQMnI1zWkKSkp2rlzp0aNGmXf5unpqTZt2uTYE3T79u0KDw/PtC0sLEwff/xxjudJTk5WcnKy/XF8fLwkyWazyWaz2f8/w0MPPZTpMVxHduMN18M4uwfG2fUxxu4hp3EuzLjnK5CePXtWaWlpWa7RDA0N1YEDB7I9JjY2Ntv9Y2NjczxPRESEJkyYkGX7xo0b7T1Gk5KS7NuPHz+e6/PB+cXExFhdAkoA4+weGGfXxxi7h2vHOTExscDP5ZB32Y8aNSrTrGp8fLyqVaumdu3aKSgoSNLfbx16+vRpbd68WQ8//LB8fHysKhfFyGazKSYmRm3btpW3t7fV5aCYMM7ugXF2fYyxe8hpnDNWtAsiX4G0QoUK8vLyUlxcXKbtcXFxqlSpUrbHVKpUKV/7S5Kvr698fX2zbPf29s70hQcHB8vPz08+Pj688F3ctWMP18Q4uwfG2fUxxu7h2nEuzJjn66YmHx8fNWrUSJs2bbJvS09P16ZNm9SsWbNsj2nWrFmm/aW/p3hz2h8AAADuJd9L9uHh4erTp48aN26sJk2aaMaMGUpISFC/fv0kSb1791bVqlUVEREhSXruuefUqlUrTZs2Te3bt1dUVJR++OEHLViwoGi/EgAAADilfAfSrl276syZMxo3bpxiY2PVsGFDrV+/3n7j0okTJ+Tp+f8nXu+55x5FRkZq7NixGj16tG655RZ9/PHHatCgQZ7PaYyRlPXaBJvNpsTERMXHx7M04KIYY/fAOLsHxtn1McbuIadxzshpGbktPzxMQY4qYX/88YeqVatmdRkAAAC4jt9//1033nhjvo5xikCanp6ukydPqkyZMvLw8LBvz7j7/vfff7fffQ/Xwhi7B8bZPTDOro8xdg85jbMxRpcuXVKVKlUyrZbnhUO2fbqWp6dnrkk7KCiIF76LY4zdA+PsHhhn18cYu4fsxrls2bIFeq58v3UoAAAAUJQIpAAAALCUUwdSX19fjR8/Ptsm+nANjLF7YJzdA+Ps+hhj91Ac4+wUNzUBAADAdTn1DCkAAACcH4EUAAAAliKQAgAAwFIEUgAAAFjK4QPp7NmzVaNGDfn5+alp06basWNHrvt/+OGHqlu3rvz8/HT77bdr3bp1JVQpCio/Y7xw4UK1bNlS5cqVU7ly5dSmTZvrvibgGPL7s5whKipKHh4e6tixY/EWiELL7xhfuHBBQ4cOVeXKleXr66tbb72Vf7OdQH7HecaMGapTp45Kly6tatWq6YUXXlBSUlIJVYv8+uqrr9ShQwdVqVJFHh4e+vjjj697zJYtW3TXXXfJ19dXN998s5YuXZr/ExsHFhUVZXx8fMzixYvNL7/8YgYMGGCCg4NNXFxctvt/8803xsvLy7z55ptm3759ZuzYscbb29vs3bu3hCtHXuV3jHv06GFmz55tdu/ebfbv32/69u1rypYta/74448Srhz5kd9xznDs2DFTtWpV07JlS/Poo4+WTLEokPyOcXJysmncuLF56KGHzNatW82xY8fMli1bzJ49e0q4cuRHfsd5xYoVxtfX16xYscIcO3bMbNiwwVSuXNm88MILJVw58mrdunVmzJgxZs2aNUaS+eijj3Ld/+jRo8bf39+Eh4ebffv2mXfffdd4eXmZ9evX5+u8Dh1ImzRpYoYOHWp/nJaWZqpUqWIiIiKy3b9Lly6mffv2mbY1bdrUDBo0qFjrRMHld4yvlZqaasqUKWPef//94ioRRaAg45yammruuece895775k+ffoQSB1cfsd47ty5platWiYlJaWkSkQRyO84Dx061Nx3332ZtoWHh5vmzZsXa50oGnkJpCNGjDC33XZbpm1du3Y1YWFh+TqXwy7Zp6SkaOfOnWrTpo19m6enp9q0aaPt27dne8z27dsz7S9JYWFhOe4PaxVkjK+VmJgom82mG264objKRCEVdJwnTpyoihUrqn///iVRJgqhIGO8du1aNWvWTEOHDlVoaKgaNGig119/XWlpaSVVNvKpION8zz33aOfOnfZl/aNHj2rdunV66KGHSqRmFL+iyl6lirKoonT27FmlpaUpNDQ00/bQ0FAdOHAg22NiY2Oz3T82NrbY6kTBFWSMr/Xyyy+rSpUqWX4Y4DgKMs5bt27VokWLtGfPnhKoEIVVkDE+evSoNm/erJ49e2rdunU6fPiwhgwZIpvNpvHjx5dE2cingoxzjx49dPbsWbVo0ULGGKWmpmrw4MEaPXp0SZSMEpBT9oqPj9eVK1dUunTpPD2Pw86QAtczZcoURUVF6aOPPpKfn5/V5aCIXLp0Sb169dLChQtVoUIFq8tBMUlPT1fFihW1YMECNWrUSF27dtWYMWM0b948q0tDEdqyZYtef/11zZkzR7t27dKaNWv0+eefa9KkSVaXBgfjsDOkFSpUkJeXl+Li4jJtj4uLU6VKlbI9plKlSvnaH9YqyBhneOuttzRlyhR98cUX+sc//lGcZaKQ8jvOR44c0fHjx9WhQwf7tvT0dElSqVKldPDgQdWuXbt4i0a+FORnuXLlyvL29paXl5d9W7169RQbG6uUlBT5+PgUa83Iv4KM8yuvvKJevXrpqaeekiTdfvvtSkhI0MCBAzVmzBh5ejIv5uxyyl5BQUF5nh2VHHiG1MfHR40aNdKmTZvs29LT07Vp0yY1a9Ys22OaNWuWaX9JiomJyXF/WKsgYyxJb775piZNmqT169ercePGJVEqCiG/41y3bl3t3btXe/bssX888sgjuvfee7Vnzx5Vq1atJMtHHhTkZ7l58+Y6fPiw/Y8NSfr1119VuXJlwqiDKsg4JyYmZgmdGX+E/H3PDJxdkWWv/N1vVbKioqKMr6+vWbp0qdm3b58ZOHCgCQ4ONrGxscYYY3r16mVGjhxp3/+bb74xpUqVMm+99ZbZv3+/GT9+PG2fHFx+x3jKlCnGx8fHrF692pw6dcr+cenSJau+BORBfsf5Wtxl7/jyO8YnTpwwZcqUMcOGDTMHDx40n332malYsaJ57bXXrPoSkAf5Hefx48ebMmXKmJUrV5qjR4+ajRs3mtq1a5suXbpY9SXgOi5dumR2795tdu/ebSSZ6dOnm927d5vffvvNGGPMyJEjTa9evez7Z7R9Gj58uNm/f7+ZPXu267V9MsaYd99919x0003Gx8fHNGnSxHz77bf2z7Vq1cr06dMn0/6rVq0yt956q/Hx8TG33Xab+fzzz0u4YuRXfsa4evXqRlKWj/Hjx5d84ciX/P4sX41A6hzyO8bbtm0zTZs2Nb6+vqZWrVpm8uTJJjU1tYSrRn7lZ5xtNpt59dVXTe3atY2fn5+pVq2aGTJkiDl//nzJF448+fLLL7P9PZsxrn369DGtWrXKckzDhg2Nj4+PqVWrllmyZEm+z+thDHPmAAAAsI7DXkMKAAAA90AgBQAAgKUIpAAAALAUgRQAAACWIpACAADAUgRSAAAAWIpACgAAAEsRSAEAAGApAikAAAAsRSAFAACApQikAAAAsBSBFAAAAJb6f5oeueGdGZV1AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "**Observation**:\n",
        "- In this supplementary exercise model 1, I am tasked to create a model with 2 hidden layers with 6 hidden nodes each. As you can see in the code above, I created 2 hidden layers with 6 nodes each and \"relu\" as the activation function. The output layer with 1 output node still stays the same. For the parameters of the compiled model, we still used SGD with the same learning rate but our number of epochs increase to 1500 from 200.\n",
        "\n",
        "- Our final training accuracy for this model is 0.8090 and training loss of 0.3962. The validation accuracy for this model is 0.75 and validation loss of 0.5052. We can observe overfitting from the result of the model because the gap of the accuracy and loss is quite large.\n",
        "\n",
        "- We can observe in the graph for the training loss and validation loss that as the validation approaches 0.50, it became stagnant regardless of the number of epoch.\n",
        "\n",
        "- For our ROC curve, we can observe that it is much smoother than the previous ROC curve and it also has a higher value of 0.823. The accuracy remains the same, it is 0.641. This is because the dataset used for validation and training is the same.\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "UHf7ThXss_hc"
      },
      "id": "UHf7ThXss_hc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model with 2 hidden layers, with 5 and 3 hidden nodes respectively"
      ],
      "metadata": {
        "id": "z1GAi0zv_TRr"
      },
      "id": "z1GAi0zv_TRr"
    },
    {
      "cell_type": "code",
      "source": [
        "model2  = Sequential([\n",
        "    Dense(5, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(3, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "zCa1mg6v_eJt"
      },
      "id": "zCa1mg6v_eJt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(SGD(lr = .01), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_3 = model2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=3000, batch_size = 32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwHRescuA6y_",
        "outputId": "97e4f130-c0c1-419e-9647-ccf585a5c726"
      },
      "id": "VwHRescuA6y_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
            "Epoch 502/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
            "Epoch 503/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
            "Epoch 504/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
            "Epoch 505/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
            "Epoch 506/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
            "Epoch 507/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
            "Epoch 508/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
            "Epoch 509/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
            "Epoch 510/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7917 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
            "Epoch 511/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
            "Epoch 512/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
            "Epoch 513/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
            "Epoch 514/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
            "Epoch 515/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7917 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
            "Epoch 516/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
            "Epoch 517/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
            "Epoch 518/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7917 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
            "Epoch 519/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7917 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
            "Epoch 520/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
            "Epoch 521/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
            "Epoch 522/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
            "Epoch 523/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
            "Epoch 524/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 525/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 526/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
            "Epoch 527/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
            "Epoch 528/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
            "Epoch 529/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4380 - accuracy: 0.7899 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
            "Epoch 530/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7899 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 531/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
            "Epoch 532/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 533/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
            "Epoch 534/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
            "Epoch 535/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
            "Epoch 536/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 537/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 538/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 539/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7899 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 540/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 541/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 542/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 543/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 544/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 545/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 546/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 547/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 548/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7882 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 549/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7917 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 550/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4371 - accuracy: 0.7917 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 551/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 552/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7899 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 553/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
            "Epoch 554/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 555/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 556/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 557/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
            "Epoch 558/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 559/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
            "Epoch 560/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 561/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 562/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 563/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7917 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 564/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7917 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 565/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7917 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 566/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 567/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7917 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 568/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 569/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7917 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 570/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
            "Epoch 571/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 572/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7899 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 573/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 574/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
            "Epoch 575/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 576/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 577/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7917 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
            "Epoch 578/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 579/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 580/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
            "Epoch 581/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
            "Epoch 582/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
            "Epoch 583/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
            "Epoch 584/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
            "Epoch 585/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
            "Epoch 586/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
            "Epoch 587/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7917 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
            "Epoch 588/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7969 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
            "Epoch 589/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
            "Epoch 590/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
            "Epoch 591/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
            "Epoch 592/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
            "Epoch 593/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
            "Epoch 594/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7934 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
            "Epoch 595/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
            "Epoch 596/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
            "Epoch 597/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
            "Epoch 598/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7917 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
            "Epoch 599/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 600/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 601/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7917 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
            "Epoch 602/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
            "Epoch 603/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7899 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
            "Epoch 604/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7899 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
            "Epoch 605/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
            "Epoch 606/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
            "Epoch 607/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7899 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
            "Epoch 608/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7882 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
            "Epoch 609/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7899 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
            "Epoch 610/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
            "Epoch 611/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
            "Epoch 612/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
            "Epoch 613/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.7882 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
            "Epoch 614/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
            "Epoch 615/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7917 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
            "Epoch 616/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7934 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
            "Epoch 617/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
            "Epoch 618/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7934 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
            "Epoch 619/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7917 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
            "Epoch 620/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7934 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 621/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7917 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
            "Epoch 622/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7899 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
            "Epoch 623/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7899 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
            "Epoch 624/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7934 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
            "Epoch 625/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7899 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
            "Epoch 626/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7882 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
            "Epoch 627/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7882 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
            "Epoch 628/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
            "Epoch 629/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7899 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
            "Epoch 630/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7899 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
            "Epoch 631/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7917 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
            "Epoch 632/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7917 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
            "Epoch 633/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7917 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
            "Epoch 634/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7882 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
            "Epoch 635/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7882 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
            "Epoch 636/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7899 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
            "Epoch 637/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7899 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
            "Epoch 638/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7899 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
            "Epoch 639/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7882 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
            "Epoch 640/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
            "Epoch 641/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7882 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
            "Epoch 642/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7882 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
            "Epoch 643/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7917 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
            "Epoch 644/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7899 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
            "Epoch 645/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7917 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
            "Epoch 646/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7899 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
            "Epoch 647/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7899 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
            "Epoch 648/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7917 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
            "Epoch 649/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7917 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
            "Epoch 650/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7899 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
            "Epoch 651/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7899 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
            "Epoch 652/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
            "Epoch 653/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7899 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
            "Epoch 654/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7899 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
            "Epoch 655/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
            "Epoch 656/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
            "Epoch 657/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7917 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
            "Epoch 658/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
            "Epoch 659/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
            "Epoch 660/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
            "Epoch 661/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
            "Epoch 662/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
            "Epoch 663/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
            "Epoch 664/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
            "Epoch 665/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7899 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
            "Epoch 666/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
            "Epoch 667/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7899 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
            "Epoch 668/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
            "Epoch 669/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
            "Epoch 670/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
            "Epoch 671/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 672/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 673/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
            "Epoch 674/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
            "Epoch 675/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
            "Epoch 676/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7899 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
            "Epoch 677/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
            "Epoch 678/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
            "Epoch 679/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
            "Epoch 680/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
            "Epoch 681/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
            "Epoch 682/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5156 - val_accuracy: 0.7500\n",
            "Epoch 683/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
            "Epoch 684/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
            "Epoch 685/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5158 - val_accuracy: 0.7500\n",
            "Epoch 686/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5158 - val_accuracy: 0.7500\n",
            "Epoch 687/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7899 - val_loss: 0.5159 - val_accuracy: 0.7500\n",
            "Epoch 688/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7899 - val_loss: 0.5158 - val_accuracy: 0.7500\n",
            "Epoch 689/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
            "Epoch 690/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.7899 - val_loss: 0.5159 - val_accuracy: 0.7500\n",
            "Epoch 691/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.7899 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
            "Epoch 692/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
            "Epoch 693/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
            "Epoch 694/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
            "Epoch 695/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7917 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
            "Epoch 696/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
            "Epoch 697/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7917 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
            "Epoch 698/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7899 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
            "Epoch 699/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7917 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
            "Epoch 700/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
            "Epoch 701/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.7917 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
            "Epoch 702/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7899 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
            "Epoch 703/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.7917 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
            "Epoch 704/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
            "Epoch 705/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7917 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
            "Epoch 706/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
            "Epoch 707/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7899 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
            "Epoch 708/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
            "Epoch 709/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7934 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
            "Epoch 710/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
            "Epoch 711/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
            "Epoch 712/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
            "Epoch 713/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7934 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
            "Epoch 714/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
            "Epoch 715/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
            "Epoch 716/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
            "Epoch 717/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
            "Epoch 718/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
            "Epoch 719/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
            "Epoch 720/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
            "Epoch 721/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
            "Epoch 722/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
            "Epoch 723/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7552\n",
            "Epoch 724/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
            "Epoch 725/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7917 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
            "Epoch 726/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
            "Epoch 727/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7917 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
            "Epoch 728/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7917 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
            "Epoch 729/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
            "Epoch 730/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
            "Epoch 731/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5176 - val_accuracy: 0.7552\n",
            "Epoch 732/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5174 - val_accuracy: 0.7552\n",
            "Epoch 733/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7552\n",
            "Epoch 734/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7552\n",
            "Epoch 735/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7917 - val_loss: 0.5175 - val_accuracy: 0.7552\n",
            "Epoch 736/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
            "Epoch 737/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7865 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
            "Epoch 738/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7917 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
            "Epoch 739/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
            "Epoch 740/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7917 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 741/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
            "Epoch 742/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 743/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7917 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 744/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
            "Epoch 745/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7917 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
            "Epoch 746/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7899 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 747/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 748/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
            "Epoch 749/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 750/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
            "Epoch 751/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 752/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 753/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
            "Epoch 754/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 755/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 756/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 757/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7917 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 758/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
            "Epoch 759/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 760/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
            "Epoch 761/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.5188 - val_accuracy: 0.7552\n",
            "Epoch 762/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7917 - val_loss: 0.5187 - val_accuracy: 0.7604\n",
            "Epoch 763/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7917 - val_loss: 0.5186 - val_accuracy: 0.7604\n",
            "Epoch 764/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7604\n",
            "Epoch 765/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.5187 - val_accuracy: 0.7604\n",
            "Epoch 766/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
            "Epoch 767/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
            "Epoch 768/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7847 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
            "Epoch 769/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
            "Epoch 770/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7847 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
            "Epoch 771/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
            "Epoch 772/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
            "Epoch 773/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7899 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
            "Epoch 774/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7604\n",
            "Epoch 775/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7604\n",
            "Epoch 776/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.5194 - val_accuracy: 0.7604\n",
            "Epoch 777/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7604\n",
            "Epoch 778/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7604\n",
            "Epoch 779/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
            "Epoch 780/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
            "Epoch 781/3000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
            "Epoch 782/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
            "Epoch 783/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7604\n",
            "Epoch 784/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
            "Epoch 785/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
            "Epoch 786/3000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
            "Epoch 787/3000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
            "Epoch 788/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
            "Epoch 789/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4285 - accuracy: 0.7847 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
            "Epoch 790/3000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4288 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
            "Epoch 791/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4285 - accuracy: 0.7847 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
            "Epoch 792/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
            "Epoch 793/3000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
            "Epoch 794/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
            "Epoch 795/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7604\n",
            "Epoch 796/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7917 - val_loss: 0.5200 - val_accuracy: 0.7604\n",
            "Epoch 797/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
            "Epoch 798/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
            "Epoch 799/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5201 - val_accuracy: 0.7604\n",
            "Epoch 800/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
            "Epoch 801/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
            "Epoch 802/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 803/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
            "Epoch 804/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 805/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 806/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7934 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
            "Epoch 807/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
            "Epoch 808/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
            "Epoch 809/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
            "Epoch 810/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
            "Epoch 811/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
            "Epoch 812/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
            "Epoch 813/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
            "Epoch 814/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
            "Epoch 815/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
            "Epoch 816/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 817/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.7865 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 818/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7917 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 819/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.7934 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 820/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.7917 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
            "Epoch 821/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
            "Epoch 822/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
            "Epoch 823/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 824/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
            "Epoch 825/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 826/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.7917 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 827/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
            "Epoch 828/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
            "Epoch 829/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
            "Epoch 830/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 831/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 832/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
            "Epoch 833/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.7865 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
            "Epoch 834/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
            "Epoch 835/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
            "Epoch 836/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
            "Epoch 837/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
            "Epoch 838/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
            "Epoch 839/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7865 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
            "Epoch 840/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 841/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 842/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
            "Epoch 843/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 844/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7917 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 845/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
            "Epoch 846/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7917 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 847/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
            "Epoch 848/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 849/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7934 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 850/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7917 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 851/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
            "Epoch 852/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 853/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
            "Epoch 854/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
            "Epoch 855/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
            "Epoch 856/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
            "Epoch 857/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 858/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
            "Epoch 859/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 860/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
            "Epoch 861/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
            "Epoch 862/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
            "Epoch 863/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
            "Epoch 864/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
            "Epoch 865/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
            "Epoch 866/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
            "Epoch 867/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
            "Epoch 868/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
            "Epoch 869/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
            "Epoch 870/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 871/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 872/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 873/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
            "Epoch 874/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
            "Epoch 875/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
            "Epoch 876/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7882 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
            "Epoch 877/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
            "Epoch 878/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 879/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
            "Epoch 880/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
            "Epoch 881/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
            "Epoch 882/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7847 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
            "Epoch 883/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
            "Epoch 884/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
            "Epoch 885/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
            "Epoch 886/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
            "Epoch 887/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7917 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
            "Epoch 888/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
            "Epoch 889/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
            "Epoch 890/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7917 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
            "Epoch 891/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7917 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
            "Epoch 892/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
            "Epoch 893/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
            "Epoch 894/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
            "Epoch 895/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
            "Epoch 896/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
            "Epoch 897/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
            "Epoch 898/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
            "Epoch 899/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
            "Epoch 900/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7917 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
            "Epoch 901/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
            "Epoch 902/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7882 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
            "Epoch 903/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
            "Epoch 904/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7917 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
            "Epoch 905/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
            "Epoch 906/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
            "Epoch 907/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.7917 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 908/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 909/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 910/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7917 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
            "Epoch 911/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
            "Epoch 912/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
            "Epoch 913/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
            "Epoch 914/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
            "Epoch 915/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
            "Epoch 916/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
            "Epoch 917/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
            "Epoch 918/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7917 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
            "Epoch 919/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
            "Epoch 920/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7917 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
            "Epoch 921/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7934 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 922/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7934 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
            "Epoch 923/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
            "Epoch 924/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 925/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7917 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 926/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7917 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
            "Epoch 927/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 928/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7917 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 929/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7917 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 930/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
            "Epoch 931/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
            "Epoch 932/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 933/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
            "Epoch 934/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7934 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 935/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
            "Epoch 936/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 937/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 938/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 939/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 940/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 941/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7986 - val_loss: 0.5235 - val_accuracy: 0.7500\n",
            "Epoch 942/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 943/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 944/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 945/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 946/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5235 - val_accuracy: 0.7500\n",
            "Epoch 947/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 948/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5235 - val_accuracy: 0.7500\n",
            "Epoch 949/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 950/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 951/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
            "Epoch 952/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 953/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
            "Epoch 954/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
            "Epoch 955/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
            "Epoch 956/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 957/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5245 - val_accuracy: 0.7500\n",
            "Epoch 958/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
            "Epoch 959/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 960/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 961/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
            "Epoch 962/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
            "Epoch 963/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
            "Epoch 964/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 965/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 966/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 967/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
            "Epoch 968/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 969/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 970/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 971/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
            "Epoch 972/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 973/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 974/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 975/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 976/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.5244 - val_accuracy: 0.7448\n",
            "Epoch 977/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4228 - accuracy: 0.7934 - val_loss: 0.5245 - val_accuracy: 0.7448\n",
            "Epoch 978/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
            "Epoch 979/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 980/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5246 - val_accuracy: 0.7448\n",
            "Epoch 981/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
            "Epoch 982/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
            "Epoch 983/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 984/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 985/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
            "Epoch 986/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7934 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 987/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
            "Epoch 988/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7934 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 989/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 990/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5248 - val_accuracy: 0.7500\n",
            "Epoch 991/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
            "Epoch 992/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
            "Epoch 993/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 994/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 995/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7934 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 996/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 997/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 998/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7934 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 999/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 1000/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7986 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
            "Epoch 1001/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
            "Epoch 1002/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1003/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1004/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1005/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1006/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1007/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1008/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1009/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7934 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1010/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7917 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1011/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1012/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1013/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1014/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1015/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1016/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7934 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1017/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 1018/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1019/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1020/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1021/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1022/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1023/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1024/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1025/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1026/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1027/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1028/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7917 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1029/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1030/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1031/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 1032/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 1033/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8003 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1034/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1035/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1036/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1037/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1038/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1039/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1040/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1041/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1042/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1043/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1044/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1045/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1046/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1047/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 1048/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1049/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1050/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1051/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1052/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1053/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1054/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8003 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1055/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1056/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5259 - val_accuracy: 0.7448\n",
            "Epoch 1057/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1058/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1059/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1060/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1061/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1062/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1063/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1064/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1065/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1066/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7934 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1067/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7986 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1068/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1069/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1070/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 1071/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.8003 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 1072/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1073/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5259 - val_accuracy: 0.7448\n",
            "Epoch 1074/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7986 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1075/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1076/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
            "Epoch 1077/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7986 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1078/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 1079/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
            "Epoch 1080/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1081/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1082/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5259 - val_accuracy: 0.7448\n",
            "Epoch 1083/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 1084/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1085/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7934 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1086/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1087/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1088/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1089/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 1090/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 1091/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.7917 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1092/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
            "Epoch 1093/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1094/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 1095/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1096/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 1097/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
            "Epoch 1098/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 1099/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.7917 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
            "Epoch 1100/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 1101/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1102/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.8003 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1103/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1104/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
            "Epoch 1105/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
            "Epoch 1106/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5267 - val_accuracy: 0.7448\n",
            "Epoch 1107/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
            "Epoch 1108/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8003 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 1109/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
            "Epoch 1110/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8021 - val_loss: 0.5267 - val_accuracy: 0.7448\n",
            "Epoch 1111/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
            "Epoch 1112/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.7986 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 1113/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
            "Epoch 1114/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
            "Epoch 1115/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 1116/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8003 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 1117/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1118/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 1119/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
            "Epoch 1120/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
            "Epoch 1121/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 1122/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
            "Epoch 1123/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 1124/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1125/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
            "Epoch 1126/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 1127/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1128/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8021 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
            "Epoch 1129/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
            "Epoch 1130/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
            "Epoch 1131/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
            "Epoch 1132/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
            "Epoch 1133/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5268 - val_accuracy: 0.7396\n",
            "Epoch 1134/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 1135/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1136/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
            "Epoch 1137/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5266 - val_accuracy: 0.7396\n",
            "Epoch 1138/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5267 - val_accuracy: 0.7396\n",
            "Epoch 1139/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5266 - val_accuracy: 0.7396\n",
            "Epoch 1140/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5265 - val_accuracy: 0.7396\n",
            "Epoch 1141/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
            "Epoch 1142/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5263 - val_accuracy: 0.7396\n",
            "Epoch 1143/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5262 - val_accuracy: 0.7396\n",
            "Epoch 1144/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1145/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5261 - val_accuracy: 0.7396\n",
            "Epoch 1146/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5262 - val_accuracy: 0.7396\n",
            "Epoch 1147/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
            "Epoch 1148/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
            "Epoch 1149/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8021 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1150/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1151/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
            "Epoch 1152/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 1153/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
            "Epoch 1154/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1155/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1156/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1157/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
            "Epoch 1158/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1159/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
            "Epoch 1160/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.5261 - val_accuracy: 0.7396\n",
            "Epoch 1161/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
            "Epoch 1162/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7986 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1163/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
            "Epoch 1164/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 1165/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 1166/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7986 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
            "Epoch 1167/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
            "Epoch 1168/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 1169/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 1170/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7986 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1171/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1172/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7986 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
            "Epoch 1173/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7986 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 1174/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1175/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1176/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 1177/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7882 - val_loss: 0.5259 - val_accuracy: 0.7448\n",
            "Epoch 1178/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
            "Epoch 1179/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 1180/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 1181/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 1182/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1183/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 1184/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 1185/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7986 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
            "Epoch 1186/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1187/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
            "Epoch 1188/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 1189/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 1190/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
            "Epoch 1191/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7986 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 1192/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
            "Epoch 1193/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 1194/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7986 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 1195/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 1196/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7986 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 1197/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 1198/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 1199/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 1200/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 1201/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
            "Epoch 1202/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 1203/3000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 1204/3000\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 1205/3000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 1206/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
            "Epoch 1207/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
            "Epoch 1208/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
            "Epoch 1209/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
            "Epoch 1210/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1211/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1212/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7917 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 1213/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1214/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1215/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 1216/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 1217/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1218/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
            "Epoch 1219/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.7934 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1220/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 1221/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1222/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1223/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1224/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1225/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.7986 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 1226/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 1227/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1228/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 1229/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5248 - val_accuracy: 0.7396\n",
            "Epoch 1230/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1231/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1232/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1233/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1234/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1235/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4180 - accuracy: 0.7934 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1236/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1237/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1238/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 1239/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1240/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5249 - val_accuracy: 0.7396\n",
            "Epoch 1241/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1242/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1243/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.7899 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 1244/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5245 - val_accuracy: 0.7448\n",
            "Epoch 1245/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5249 - val_accuracy: 0.7396\n",
            "Epoch 1246/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1247/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5246 - val_accuracy: 0.7448\n",
            "Epoch 1248/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
            "Epoch 1249/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1250/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1251/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 1252/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5249 - val_accuracy: 0.7396\n",
            "Epoch 1253/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1254/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1255/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1256/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1257/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.7934 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1258/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1259/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7934 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1260/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1261/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
            "Epoch 1262/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7934 - val_loss: 0.5248 - val_accuracy: 0.7396\n",
            "Epoch 1263/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7934 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
            "Epoch 1264/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1265/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1266/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1267/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1268/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 1269/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1270/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1271/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 1272/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1273/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5259 - val_accuracy: 0.7448\n",
            "Epoch 1274/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5249 - val_accuracy: 0.7396\n",
            "Epoch 1275/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
            "Epoch 1276/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1277/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1278/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1279/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1280/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1281/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1282/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 1283/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1284/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1285/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1286/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7934 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
            "Epoch 1287/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1288/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1289/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1290/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1291/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 1292/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1293/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 1294/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8003 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
            "Epoch 1295/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
            "Epoch 1296/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
            "Epoch 1297/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
            "Epoch 1298/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1299/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1300/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 1301/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 1302/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
            "Epoch 1303/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.7917 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 1304/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
            "Epoch 1305/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 1306/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8003 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
            "Epoch 1307/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
            "Epoch 1308/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 1309/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.7986 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
            "Epoch 1310/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 1311/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 1312/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 1313/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7986 - val_loss: 0.5245 - val_accuracy: 0.7448\n",
            "Epoch 1314/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
            "Epoch 1315/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 1316/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.5246 - val_accuracy: 0.7448\n",
            "Epoch 1317/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.7986 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 1318/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.7951 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1319/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1320/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1321/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 1322/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1323/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
            "Epoch 1324/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1325/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
            "Epoch 1326/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7986 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1327/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.7986 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
            "Epoch 1328/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 1329/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 1330/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 1331/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
            "Epoch 1332/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
            "Epoch 1333/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1334/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
            "Epoch 1335/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 1336/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8003 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1337/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1338/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1339/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1340/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 1341/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 1342/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
            "Epoch 1343/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
            "Epoch 1344/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
            "Epoch 1345/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8003 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 1346/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.7986 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1347/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 1348/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
            "Epoch 1349/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
            "Epoch 1350/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
            "Epoch 1351/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8038 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
            "Epoch 1352/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
            "Epoch 1353/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
            "Epoch 1354/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8003 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
            "Epoch 1355/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
            "Epoch 1356/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8038 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
            "Epoch 1357/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8003 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
            "Epoch 1358/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
            "Epoch 1359/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
            "Epoch 1360/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8056 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
            "Epoch 1361/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8090 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
            "Epoch 1362/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 1363/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8038 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
            "Epoch 1364/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8021 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 1365/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8038 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
            "Epoch 1366/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
            "Epoch 1367/3000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.4151 - accuracy: 0.8056 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 1368/3000\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4150 - accuracy: 0.8021 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
            "Epoch 1369/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8056 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
            "Epoch 1370/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8021 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
            "Epoch 1371/3000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4151 - accuracy: 0.8038 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
            "Epoch 1372/3000\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.4150 - accuracy: 0.8038 - val_loss: 0.5245 - val_accuracy: 0.7500\n",
            "Epoch 1373/3000\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.4150 - accuracy: 0.8056 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 1374/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8073 - val_loss: 0.5245 - val_accuracy: 0.7500\n",
            "Epoch 1375/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8056 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 1376/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8073 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 1377/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8021 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 1378/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8021 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 1379/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8056 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
            "Epoch 1380/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 1381/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8056 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 1382/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8073 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 1383/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8056 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
            "Epoch 1384/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8056 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 1385/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8056 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 1386/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8056 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1387/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8056 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
            "Epoch 1388/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8056 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
            "Epoch 1389/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
            "Epoch 1390/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8056 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
            "Epoch 1391/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
            "Epoch 1392/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
            "Epoch 1393/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8056 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
            "Epoch 1394/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8056 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
            "Epoch 1395/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8056 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 1396/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8021 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 1397/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8056 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
            "Epoch 1398/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8021 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 1399/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8056 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
            "Epoch 1400/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8073 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 1401/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8073 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 1402/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8090 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
            "Epoch 1403/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8073 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
            "Epoch 1404/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8021 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
            "Epoch 1405/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8073 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
            "Epoch 1406/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8073 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 1407/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8073 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 1408/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8021 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
            "Epoch 1409/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8056 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1410/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8021 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
            "Epoch 1411/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8056 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
            "Epoch 1412/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8056 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
            "Epoch 1413/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8073 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
            "Epoch 1414/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8038 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 1415/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8056 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
            "Epoch 1416/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8073 - val_loss: 0.5262 - val_accuracy: 0.7552\n",
            "Epoch 1417/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8073 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 1418/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8056 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
            "Epoch 1419/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 1420/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8125 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1421/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8090 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
            "Epoch 1422/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8056 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 1423/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8056 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
            "Epoch 1424/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8090 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 1425/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8090 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1426/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8090 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 1427/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8038 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 1428/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 1429/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8056 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
            "Epoch 1430/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 1431/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8090 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
            "Epoch 1432/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8090 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1433/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 1434/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 1435/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 1436/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8056 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 1437/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8108 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 1438/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8108 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 1439/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1440/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8090 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 1441/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8038 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 1442/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
            "Epoch 1443/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 1444/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 1445/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8056 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 1446/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 1447/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8073 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 1448/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8073 - val_loss: 0.5276 - val_accuracy: 0.7500\n",
            "Epoch 1449/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8108 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
            "Epoch 1450/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8108 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1451/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 1452/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
            "Epoch 1453/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8090 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 1454/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8108 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
            "Epoch 1455/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8090 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 1456/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8090 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 1457/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 1458/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 1459/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8073 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
            "Epoch 1460/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8090 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 1461/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1462/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8073 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
            "Epoch 1463/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8090 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 1464/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 1465/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8056 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 1466/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 1467/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8090 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 1468/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8073 - val_loss: 0.5276 - val_accuracy: 0.7500\n",
            "Epoch 1469/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8108 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
            "Epoch 1470/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8056 - val_loss: 0.5266 - val_accuracy: 0.7448\n",
            "Epoch 1471/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5267 - val_accuracy: 0.7448\n",
            "Epoch 1472/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8056 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 1473/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 1474/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8056 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 1475/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8073 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 1476/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8038 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
            "Epoch 1477/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8090 - val_loss: 0.5272 - val_accuracy: 0.7448\n",
            "Epoch 1478/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8073 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 1479/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4126 - accuracy: 0.8125 - val_loss: 0.5272 - val_accuracy: 0.7448\n",
            "Epoch 1480/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8108 - val_loss: 0.5272 - val_accuracy: 0.7448\n",
            "Epoch 1481/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8108 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 1482/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8108 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
            "Epoch 1483/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8125 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 1484/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
            "Epoch 1485/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8108 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
            "Epoch 1486/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8056 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
            "Epoch 1487/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8108 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 1488/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8021 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
            "Epoch 1489/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8073 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
            "Epoch 1490/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8073 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
            "Epoch 1491/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8073 - val_loss: 0.5274 - val_accuracy: 0.7396\n",
            "Epoch 1492/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8056 - val_loss: 0.5267 - val_accuracy: 0.7396\n",
            "Epoch 1493/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8056 - val_loss: 0.5274 - val_accuracy: 0.7396\n",
            "Epoch 1494/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5279 - val_accuracy: 0.7396\n",
            "Epoch 1495/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 1496/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8073 - val_loss: 0.5278 - val_accuracy: 0.7396\n",
            "Epoch 1497/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 1498/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8125 - val_loss: 0.5267 - val_accuracy: 0.7448\n",
            "Epoch 1499/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4123 - accuracy: 0.8090 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 1500/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8056 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1501/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5276 - val_accuracy: 0.7500\n",
            "Epoch 1502/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8090 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1503/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8073 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1504/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8038 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1505/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 1506/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8073 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
            "Epoch 1507/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8108 - val_loss: 0.5284 - val_accuracy: 0.7396\n",
            "Epoch 1508/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8056 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 1509/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8056 - val_loss: 0.5283 - val_accuracy: 0.7396\n",
            "Epoch 1510/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5289 - val_accuracy: 0.7396\n",
            "Epoch 1511/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8108 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
            "Epoch 1512/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8021 - val_loss: 0.5279 - val_accuracy: 0.7396\n",
            "Epoch 1513/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
            "Epoch 1514/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 1515/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8108 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
            "Epoch 1516/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.5279 - val_accuracy: 0.7396\n",
            "Epoch 1517/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8108 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
            "Epoch 1518/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
            "Epoch 1519/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
            "Epoch 1520/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
            "Epoch 1521/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8021 - val_loss: 0.5284 - val_accuracy: 0.7396\n",
            "Epoch 1522/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
            "Epoch 1523/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8108 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1524/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8038 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
            "Epoch 1525/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
            "Epoch 1526/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
            "Epoch 1527/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8125 - val_loss: 0.5282 - val_accuracy: 0.7396\n",
            "Epoch 1528/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
            "Epoch 1529/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8090 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
            "Epoch 1530/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8090 - val_loss: 0.5278 - val_accuracy: 0.7396\n",
            "Epoch 1531/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 1532/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8090 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 1533/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 1534/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8073 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 1535/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8090 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
            "Epoch 1536/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1537/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8090 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 1538/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
            "Epoch 1539/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8073 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 1540/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8090 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 1541/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8090 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 1542/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 1543/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8108 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
            "Epoch 1544/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
            "Epoch 1545/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8073 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1546/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
            "Epoch 1547/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8073 - val_loss: 0.5284 - val_accuracy: 0.7396\n",
            "Epoch 1548/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8090 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
            "Epoch 1549/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8125 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1550/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8125 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 1551/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8142 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
            "Epoch 1552/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8090 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 1553/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 1554/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
            "Epoch 1555/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8090 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
            "Epoch 1556/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 1557/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8090 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
            "Epoch 1558/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1559/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8125 - val_loss: 0.5295 - val_accuracy: 0.7448\n",
            "Epoch 1560/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
            "Epoch 1561/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
            "Epoch 1562/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8073 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
            "Epoch 1563/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8142 - val_loss: 0.5291 - val_accuracy: 0.7396\n",
            "Epoch 1564/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8090 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
            "Epoch 1565/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 1566/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
            "Epoch 1567/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8073 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
            "Epoch 1568/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8142 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 1569/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8142 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
            "Epoch 1570/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
            "Epoch 1571/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8142 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
            "Epoch 1572/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8177 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
            "Epoch 1573/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
            "Epoch 1574/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8090 - val_loss: 0.5313 - val_accuracy: 0.7396\n",
            "Epoch 1575/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8090 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
            "Epoch 1576/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8073 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
            "Epoch 1577/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8090 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
            "Epoch 1578/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8090 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
            "Epoch 1579/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
            "Epoch 1580/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8073 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
            "Epoch 1581/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
            "Epoch 1582/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
            "Epoch 1583/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8142 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 1584/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8108 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
            "Epoch 1585/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
            "Epoch 1586/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8142 - val_loss: 0.5311 - val_accuracy: 0.7396\n",
            "Epoch 1587/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8073 - val_loss: 0.5313 - val_accuracy: 0.7396\n",
            "Epoch 1588/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8142 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
            "Epoch 1589/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
            "Epoch 1590/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8090 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
            "Epoch 1591/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8125 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
            "Epoch 1592/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8108 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
            "Epoch 1593/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 1594/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8108 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
            "Epoch 1595/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8090 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
            "Epoch 1596/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8108 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
            "Epoch 1597/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8108 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
            "Epoch 1598/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8090 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
            "Epoch 1599/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
            "Epoch 1600/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
            "Epoch 1601/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
            "Epoch 1602/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8160 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
            "Epoch 1603/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8125 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
            "Epoch 1604/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8090 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
            "Epoch 1605/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8125 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
            "Epoch 1606/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8125 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
            "Epoch 1607/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8125 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
            "Epoch 1608/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8090 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
            "Epoch 1609/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8142 - val_loss: 0.5311 - val_accuracy: 0.7396\n",
            "Epoch 1610/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4110 - accuracy: 0.8142 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
            "Epoch 1611/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8125 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
            "Epoch 1612/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8125 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
            "Epoch 1613/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4101 - accuracy: 0.8108 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
            "Epoch 1614/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8142 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
            "Epoch 1615/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4101 - accuracy: 0.8108 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
            "Epoch 1616/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8142 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
            "Epoch 1617/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8108 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
            "Epoch 1618/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8108 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
            "Epoch 1619/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
            "Epoch 1620/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4102 - accuracy: 0.8125 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
            "Epoch 1621/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8090 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
            "Epoch 1622/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8108 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
            "Epoch 1623/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8125 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
            "Epoch 1624/3000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4105 - accuracy: 0.8090 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
            "Epoch 1625/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8108 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
            "Epoch 1626/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8125 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
            "Epoch 1627/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4106 - accuracy: 0.8142 - val_loss: 0.5320 - val_accuracy: 0.7344\n",
            "Epoch 1628/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
            "Epoch 1629/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4102 - accuracy: 0.8142 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
            "Epoch 1630/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
            "Epoch 1631/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8125 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
            "Epoch 1632/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8125 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
            "Epoch 1633/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
            "Epoch 1634/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8142 - val_loss: 0.5334 - val_accuracy: 0.7344\n",
            "Epoch 1635/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8160 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
            "Epoch 1636/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8108 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
            "Epoch 1637/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8160 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
            "Epoch 1638/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8160 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
            "Epoch 1639/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8090 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
            "Epoch 1640/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8142 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
            "Epoch 1641/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8090 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
            "Epoch 1642/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8125 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
            "Epoch 1643/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8142 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 1644/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8142 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
            "Epoch 1645/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8142 - val_loss: 0.5350 - val_accuracy: 0.7344\n",
            "Epoch 1646/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8090 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
            "Epoch 1647/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8160 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
            "Epoch 1648/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8142 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
            "Epoch 1649/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8125 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
            "Epoch 1650/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8108 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
            "Epoch 1651/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8177 - val_loss: 0.5353 - val_accuracy: 0.7396\n",
            "Epoch 1652/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8177 - val_loss: 0.5336 - val_accuracy: 0.7344\n",
            "Epoch 1653/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8142 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
            "Epoch 1654/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8142 - val_loss: 0.5334 - val_accuracy: 0.7344\n",
            "Epoch 1655/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.8108 - val_loss: 0.5337 - val_accuracy: 0.7344\n",
            "Epoch 1656/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8160 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
            "Epoch 1657/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8160 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
            "Epoch 1658/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.8142 - val_loss: 0.5352 - val_accuracy: 0.7344\n",
            "Epoch 1659/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8125 - val_loss: 0.5351 - val_accuracy: 0.7344\n",
            "Epoch 1660/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8125 - val_loss: 0.5347 - val_accuracy: 0.7396\n",
            "Epoch 1661/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4097 - accuracy: 0.8160 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
            "Epoch 1662/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8142 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
            "Epoch 1663/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8142 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
            "Epoch 1664/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8160 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
            "Epoch 1665/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8125 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
            "Epoch 1666/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8160 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
            "Epoch 1667/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8194 - val_loss: 0.5352 - val_accuracy: 0.7344\n",
            "Epoch 1668/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8142 - val_loss: 0.5349 - val_accuracy: 0.7344\n",
            "Epoch 1669/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8125 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
            "Epoch 1670/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8125 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
            "Epoch 1671/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8108 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
            "Epoch 1672/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8142 - val_loss: 0.5340 - val_accuracy: 0.7344\n",
            "Epoch 1673/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8125 - val_loss: 0.5348 - val_accuracy: 0.7344\n",
            "Epoch 1674/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8125 - val_loss: 0.5349 - val_accuracy: 0.7344\n",
            "Epoch 1675/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8125 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
            "Epoch 1676/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8142 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
            "Epoch 1677/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8177 - val_loss: 0.5355 - val_accuracy: 0.7344\n",
            "Epoch 1678/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8108 - val_loss: 0.5351 - val_accuracy: 0.7344\n",
            "Epoch 1679/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8142 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
            "Epoch 1680/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8108 - val_loss: 0.5353 - val_accuracy: 0.7344\n",
            "Epoch 1681/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8125 - val_loss: 0.5352 - val_accuracy: 0.7344\n",
            "Epoch 1682/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8108 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
            "Epoch 1683/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8160 - val_loss: 0.5359 - val_accuracy: 0.7344\n",
            "Epoch 1684/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8125 - val_loss: 0.5355 - val_accuracy: 0.7344\n",
            "Epoch 1685/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8125 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
            "Epoch 1686/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8160 - val_loss: 0.5349 - val_accuracy: 0.7344\n",
            "Epoch 1687/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8160 - val_loss: 0.5354 - val_accuracy: 0.7344\n",
            "Epoch 1688/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8108 - val_loss: 0.5348 - val_accuracy: 0.7396\n",
            "Epoch 1689/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8090 - val_loss: 0.5354 - val_accuracy: 0.7344\n",
            "Epoch 1690/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8142 - val_loss: 0.5356 - val_accuracy: 0.7344\n",
            "Epoch 1691/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8142 - val_loss: 0.5356 - val_accuracy: 0.7344\n",
            "Epoch 1692/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8160 - val_loss: 0.5362 - val_accuracy: 0.7344\n",
            "Epoch 1693/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8125 - val_loss: 0.5348 - val_accuracy: 0.7396\n",
            "Epoch 1694/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8090 - val_loss: 0.5351 - val_accuracy: 0.7396\n",
            "Epoch 1695/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8108 - val_loss: 0.5346 - val_accuracy: 0.7396\n",
            "Epoch 1696/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8142 - val_loss: 0.5355 - val_accuracy: 0.7344\n",
            "Epoch 1697/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8160 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
            "Epoch 1698/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8108 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
            "Epoch 1699/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8160 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
            "Epoch 1700/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8108 - val_loss: 0.5357 - val_accuracy: 0.7396\n",
            "Epoch 1701/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8142 - val_loss: 0.5364 - val_accuracy: 0.7344\n",
            "Epoch 1702/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8212 - val_loss: 0.5361 - val_accuracy: 0.7344\n",
            "Epoch 1703/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8125 - val_loss: 0.5356 - val_accuracy: 0.7396\n",
            "Epoch 1704/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8125 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
            "Epoch 1705/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8160 - val_loss: 0.5365 - val_accuracy: 0.7344\n",
            "Epoch 1706/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8142 - val_loss: 0.5363 - val_accuracy: 0.7344\n",
            "Epoch 1707/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8108 - val_loss: 0.5356 - val_accuracy: 0.7396\n",
            "Epoch 1708/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8125 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
            "Epoch 1709/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8142 - val_loss: 0.5367 - val_accuracy: 0.7344\n",
            "Epoch 1710/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8125 - val_loss: 0.5352 - val_accuracy: 0.7448\n",
            "Epoch 1711/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8108 - val_loss: 0.5352 - val_accuracy: 0.7396\n",
            "Epoch 1712/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.8160 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
            "Epoch 1713/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8142 - val_loss: 0.5371 - val_accuracy: 0.7344\n",
            "Epoch 1714/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8108 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
            "Epoch 1715/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8125 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
            "Epoch 1716/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8125 - val_loss: 0.5364 - val_accuracy: 0.7344\n",
            "Epoch 1717/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8125 - val_loss: 0.5368 - val_accuracy: 0.7344\n",
            "Epoch 1718/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8125 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
            "Epoch 1719/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8142 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
            "Epoch 1720/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8142 - val_loss: 0.5368 - val_accuracy: 0.7344\n",
            "Epoch 1721/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8108 - val_loss: 0.5362 - val_accuracy: 0.7396\n",
            "Epoch 1722/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8160 - val_loss: 0.5369 - val_accuracy: 0.7344\n",
            "Epoch 1723/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8090 - val_loss: 0.5374 - val_accuracy: 0.7344\n",
            "Epoch 1724/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8142 - val_loss: 0.5365 - val_accuracy: 0.7344\n",
            "Epoch 1725/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8125 - val_loss: 0.5371 - val_accuracy: 0.7344\n",
            "Epoch 1726/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8142 - val_loss: 0.5362 - val_accuracy: 0.7396\n",
            "Epoch 1727/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.8125 - val_loss: 0.5366 - val_accuracy: 0.7344\n",
            "Epoch 1728/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8125 - val_loss: 0.5368 - val_accuracy: 0.7344\n",
            "Epoch 1729/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8108 - val_loss: 0.5374 - val_accuracy: 0.7344\n",
            "Epoch 1730/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8142 - val_loss: 0.5375 - val_accuracy: 0.7344\n",
            "Epoch 1731/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8108 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
            "Epoch 1732/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8125 - val_loss: 0.5368 - val_accuracy: 0.7396\n",
            "Epoch 1733/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8108 - val_loss: 0.5373 - val_accuracy: 0.7344\n",
            "Epoch 1734/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8108 - val_loss: 0.5377 - val_accuracy: 0.7344\n",
            "Epoch 1735/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8090 - val_loss: 0.5377 - val_accuracy: 0.7344\n",
            "Epoch 1736/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8142 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
            "Epoch 1737/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8125 - val_loss: 0.5372 - val_accuracy: 0.7344\n",
            "Epoch 1738/3000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4094 - accuracy: 0.8090 - val_loss: 0.5385 - val_accuracy: 0.7292\n",
            "Epoch 1739/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8125 - val_loss: 0.5370 - val_accuracy: 0.7344\n",
            "Epoch 1740/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8108 - val_loss: 0.5374 - val_accuracy: 0.7344\n",
            "Epoch 1741/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8142 - val_loss: 0.5378 - val_accuracy: 0.7344\n",
            "Epoch 1742/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8160 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
            "Epoch 1743/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4095 - accuracy: 0.8125 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
            "Epoch 1744/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.8125 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
            "Epoch 1745/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4093 - accuracy: 0.8125 - val_loss: 0.5371 - val_accuracy: 0.7396\n",
            "Epoch 1746/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8125 - val_loss: 0.5370 - val_accuracy: 0.7396\n",
            "Epoch 1747/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8125 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
            "Epoch 1748/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8090 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
            "Epoch 1749/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8177 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
            "Epoch 1750/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8108 - val_loss: 0.5373 - val_accuracy: 0.7396\n",
            "Epoch 1751/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.8160 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
            "Epoch 1752/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4091 - accuracy: 0.8108 - val_loss: 0.5378 - val_accuracy: 0.7396\n",
            "Epoch 1753/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.8108 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
            "Epoch 1754/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.8125 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
            "Epoch 1755/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4089 - accuracy: 0.8142 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
            "Epoch 1756/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.8125 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
            "Epoch 1757/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.8142 - val_loss: 0.5386 - val_accuracy: 0.7344\n",
            "Epoch 1758/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.8125 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
            "Epoch 1759/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8142 - val_loss: 0.5392 - val_accuracy: 0.7292\n",
            "Epoch 1760/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
            "Epoch 1761/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.8142 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
            "Epoch 1762/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8108 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
            "Epoch 1763/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8108 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
            "Epoch 1764/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4088 - accuracy: 0.8108 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
            "Epoch 1765/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8125 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
            "Epoch 1766/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8108 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
            "Epoch 1767/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.8090 - val_loss: 0.5396 - val_accuracy: 0.7292\n",
            "Epoch 1768/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8142 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
            "Epoch 1769/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.8142 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
            "Epoch 1770/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4090 - accuracy: 0.8108 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
            "Epoch 1771/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8125 - val_loss: 0.5387 - val_accuracy: 0.7344\n",
            "Epoch 1772/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 1773/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8090 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
            "Epoch 1774/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8142 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
            "Epoch 1775/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
            "Epoch 1776/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8142 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
            "Epoch 1777/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8142 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
            "Epoch 1778/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8125 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
            "Epoch 1779/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8108 - val_loss: 0.5396 - val_accuracy: 0.7292\n",
            "Epoch 1780/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8125 - val_loss: 0.5393 - val_accuracy: 0.7344\n",
            "Epoch 1781/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8160 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
            "Epoch 1782/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 1783/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8125 - val_loss: 0.5391 - val_accuracy: 0.7396\n",
            "Epoch 1784/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8142 - val_loss: 0.5388 - val_accuracy: 0.7396\n",
            "Epoch 1785/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.5393 - val_accuracy: 0.7344\n",
            "Epoch 1786/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4085 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
            "Epoch 1787/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8125 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
            "Epoch 1788/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8142 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
            "Epoch 1789/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8125 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
            "Epoch 1790/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 1791/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8073 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
            "Epoch 1792/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8142 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
            "Epoch 1793/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8125 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
            "Epoch 1794/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
            "Epoch 1795/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8108 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
            "Epoch 1796/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
            "Epoch 1797/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8108 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
            "Epoch 1798/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.8090 - val_loss: 0.5406 - val_accuracy: 0.7292\n",
            "Epoch 1799/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7292\n",
            "Epoch 1800/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8142 - val_loss: 0.5397 - val_accuracy: 0.7396\n",
            "Epoch 1801/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8125 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
            "Epoch 1802/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8142 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
            "Epoch 1803/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8108 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
            "Epoch 1804/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8125 - val_loss: 0.5394 - val_accuracy: 0.7448\n",
            "Epoch 1805/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
            "Epoch 1806/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8142 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
            "Epoch 1807/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8090 - val_loss: 0.5412 - val_accuracy: 0.7292\n",
            "Epoch 1808/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4083 - accuracy: 0.8125 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
            "Epoch 1809/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
            "Epoch 1810/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
            "Epoch 1811/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8125 - val_loss: 0.5413 - val_accuracy: 0.7344\n",
            "Epoch 1812/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8125 - val_loss: 0.5414 - val_accuracy: 0.7344\n",
            "Epoch 1813/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.8108 - val_loss: 0.5414 - val_accuracy: 0.7344\n",
            "Epoch 1814/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.5416 - val_accuracy: 0.7292\n",
            "Epoch 1815/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8108 - val_loss: 0.5413 - val_accuracy: 0.7344\n",
            "Epoch 1816/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.8108 - val_loss: 0.5419 - val_accuracy: 0.7292\n",
            "Epoch 1817/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
            "Epoch 1818/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8125 - val_loss: 0.5420 - val_accuracy: 0.7292\n",
            "Epoch 1819/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8142 - val_loss: 0.5424 - val_accuracy: 0.7344\n",
            "Epoch 1820/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8125 - val_loss: 0.5421 - val_accuracy: 0.7292\n",
            "Epoch 1821/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8142 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
            "Epoch 1822/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7448\n",
            "Epoch 1823/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5408 - val_accuracy: 0.7396\n",
            "Epoch 1824/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8142 - val_loss: 0.5418 - val_accuracy: 0.7344\n",
            "Epoch 1825/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.8108 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
            "Epoch 1826/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5413 - val_accuracy: 0.7396\n",
            "Epoch 1827/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8125 - val_loss: 0.5417 - val_accuracy: 0.7344\n",
            "Epoch 1828/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8073 - val_loss: 0.5420 - val_accuracy: 0.7396\n",
            "Epoch 1829/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.8125 - val_loss: 0.5416 - val_accuracy: 0.7396\n",
            "Epoch 1830/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.5421 - val_accuracy: 0.7344\n",
            "Epoch 1831/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8125 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
            "Epoch 1832/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7448\n",
            "Epoch 1833/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8125 - val_loss: 0.5413 - val_accuracy: 0.7396\n",
            "Epoch 1834/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8125 - val_loss: 0.5413 - val_accuracy: 0.7344\n",
            "Epoch 1835/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
            "Epoch 1836/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8090 - val_loss: 0.5411 - val_accuracy: 0.7292\n",
            "Epoch 1837/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8108 - val_loss: 0.5419 - val_accuracy: 0.7344\n",
            "Epoch 1838/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8125 - val_loss: 0.5411 - val_accuracy: 0.7292\n",
            "Epoch 1839/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5418 - val_accuracy: 0.7344\n",
            "Epoch 1840/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.8108 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 1841/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8125 - val_loss: 0.5414 - val_accuracy: 0.7396\n",
            "Epoch 1842/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8108 - val_loss: 0.5425 - val_accuracy: 0.7344\n",
            "Epoch 1843/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8108 - val_loss: 0.5426 - val_accuracy: 0.7344\n",
            "Epoch 1844/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8125 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
            "Epoch 1845/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8108 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 1846/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8142 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
            "Epoch 1847/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8142 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
            "Epoch 1848/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8125 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
            "Epoch 1849/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8090 - val_loss: 0.5439 - val_accuracy: 0.7344\n",
            "Epoch 1850/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5434 - val_accuracy: 0.7292\n",
            "Epoch 1851/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4083 - accuracy: 0.8125 - val_loss: 0.5434 - val_accuracy: 0.7292\n",
            "Epoch 1852/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8125 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
            "Epoch 1853/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8108 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
            "Epoch 1854/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8108 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
            "Epoch 1855/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8125 - val_loss: 0.5435 - val_accuracy: 0.7292\n",
            "Epoch 1856/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8108 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
            "Epoch 1857/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
            "Epoch 1858/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8108 - val_loss: 0.5433 - val_accuracy: 0.7344\n",
            "Epoch 1859/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
            "Epoch 1860/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8090 - val_loss: 0.5438 - val_accuracy: 0.7292\n",
            "Epoch 1861/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8125 - val_loss: 0.5442 - val_accuracy: 0.7292\n",
            "Epoch 1862/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4083 - accuracy: 0.8108 - val_loss: 0.5438 - val_accuracy: 0.7292\n",
            "Epoch 1863/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8125 - val_loss: 0.5424 - val_accuracy: 0.7344\n",
            "Epoch 1864/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 1865/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8125 - val_loss: 0.5436 - val_accuracy: 0.7292\n",
            "Epoch 1866/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8125 - val_loss: 0.5441 - val_accuracy: 0.7292\n",
            "Epoch 1867/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8125 - val_loss: 0.5438 - val_accuracy: 0.7292\n",
            "Epoch 1868/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8142 - val_loss: 0.5438 - val_accuracy: 0.7292\n",
            "Epoch 1869/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8056 - val_loss: 0.5439 - val_accuracy: 0.7292\n",
            "Epoch 1870/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8090 - val_loss: 0.5447 - val_accuracy: 0.7292\n",
            "Epoch 1871/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8125 - val_loss: 0.5439 - val_accuracy: 0.7292\n",
            "Epoch 1872/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8142 - val_loss: 0.5435 - val_accuracy: 0.7292\n",
            "Epoch 1873/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.5438 - val_accuracy: 0.7292\n",
            "Epoch 1874/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.8125 - val_loss: 0.5437 - val_accuracy: 0.7292\n",
            "Epoch 1875/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4079 - accuracy: 0.8142 - val_loss: 0.5431 - val_accuracy: 0.7344\n",
            "Epoch 1876/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8073 - val_loss: 0.5437 - val_accuracy: 0.7344\n",
            "Epoch 1877/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8125 - val_loss: 0.5446 - val_accuracy: 0.7292\n",
            "Epoch 1878/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.8125 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
            "Epoch 1879/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8108 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 1880/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4082 - accuracy: 0.8108 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 1881/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8090 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 1882/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
            "Epoch 1883/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.8125 - val_loss: 0.5441 - val_accuracy: 0.7292\n",
            "Epoch 1884/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8108 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 1885/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8090 - val_loss: 0.5448 - val_accuracy: 0.7292\n",
            "Epoch 1886/3000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4078 - accuracy: 0.8125 - val_loss: 0.5453 - val_accuracy: 0.7344\n",
            "Epoch 1887/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8108 - val_loss: 0.5458 - val_accuracy: 0.7344\n",
            "Epoch 1888/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.8125 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 1889/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5454 - val_accuracy: 0.7344\n",
            "Epoch 1890/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8108 - val_loss: 0.5454 - val_accuracy: 0.7344\n",
            "Epoch 1891/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.8125 - val_loss: 0.5445 - val_accuracy: 0.7292\n",
            "Epoch 1892/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8142 - val_loss: 0.5451 - val_accuracy: 0.7344\n",
            "Epoch 1893/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8090 - val_loss: 0.5452 - val_accuracy: 0.7344\n",
            "Epoch 1894/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.8090 - val_loss: 0.5451 - val_accuracy: 0.7344\n",
            "Epoch 1895/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8090 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
            "Epoch 1896/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4084 - accuracy: 0.8125 - val_loss: 0.5444 - val_accuracy: 0.7292\n",
            "Epoch 1897/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4079 - accuracy: 0.8108 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
            "Epoch 1898/3000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4075 - accuracy: 0.8090 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 1899/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8160 - val_loss: 0.5459 - val_accuracy: 0.7292\n",
            "Epoch 1900/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4081 - accuracy: 0.8108 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
            "Epoch 1901/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8125 - val_loss: 0.5462 - val_accuracy: 0.7292\n",
            "Epoch 1902/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8142 - val_loss: 0.5461 - val_accuracy: 0.7292\n",
            "Epoch 1903/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8108 - val_loss: 0.5458 - val_accuracy: 0.7344\n",
            "Epoch 1904/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8125 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 1905/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5452 - val_accuracy: 0.7344\n",
            "Epoch 1906/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8142 - val_loss: 0.5451 - val_accuracy: 0.7292\n",
            "Epoch 1907/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8108 - val_loss: 0.5454 - val_accuracy: 0.7344\n",
            "Epoch 1908/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8125 - val_loss: 0.5450 - val_accuracy: 0.7292\n",
            "Epoch 1909/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8073 - val_loss: 0.5455 - val_accuracy: 0.7344\n",
            "Epoch 1910/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8125 - val_loss: 0.5453 - val_accuracy: 0.7344\n",
            "Epoch 1911/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8090 - val_loss: 0.5458 - val_accuracy: 0.7344\n",
            "Epoch 1912/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8142 - val_loss: 0.5446 - val_accuracy: 0.7396\n",
            "Epoch 1913/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8056 - val_loss: 0.5448 - val_accuracy: 0.7396\n",
            "Epoch 1914/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8125 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 1915/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8108 - val_loss: 0.5451 - val_accuracy: 0.7292\n",
            "Epoch 1916/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 1917/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 1918/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.8108 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
            "Epoch 1919/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5451 - val_accuracy: 0.7344\n",
            "Epoch 1920/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.5458 - val_accuracy: 0.7344\n",
            "Epoch 1921/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 1922/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8056 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
            "Epoch 1923/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8125 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 1924/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
            "Epoch 1925/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.5473 - val_accuracy: 0.7396\n",
            "Epoch 1926/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
            "Epoch 1927/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8125 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
            "Epoch 1928/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5469 - val_accuracy: 0.7344\n",
            "Epoch 1929/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8125 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
            "Epoch 1930/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8125 - val_loss: 0.5469 - val_accuracy: 0.7344\n",
            "Epoch 1931/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
            "Epoch 1932/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8090 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
            "Epoch 1933/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5460 - val_accuracy: 0.7292\n",
            "Epoch 1934/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8125 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
            "Epoch 1935/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8125 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 1936/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8056 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
            "Epoch 1937/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8108 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
            "Epoch 1938/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
            "Epoch 1939/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8108 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
            "Epoch 1940/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
            "Epoch 1941/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8125 - val_loss: 0.5467 - val_accuracy: 0.7292\n",
            "Epoch 1942/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8142 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
            "Epoch 1943/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8073 - val_loss: 0.5469 - val_accuracy: 0.7344\n",
            "Epoch 1944/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8125 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
            "Epoch 1945/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8125 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 1946/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8108 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 1947/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
            "Epoch 1948/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5469 - val_accuracy: 0.7292\n",
            "Epoch 1949/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
            "Epoch 1950/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8125 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 1951/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.5463 - val_accuracy: 0.7344\n",
            "Epoch 1952/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8142 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 1953/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
            "Epoch 1954/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8056 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
            "Epoch 1955/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 1956/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8108 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 1957/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 1958/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8073 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 1959/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8108 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
            "Epoch 1960/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8038 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 1961/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4075 - accuracy: 0.8090 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 1962/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8073 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 1963/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5486 - val_accuracy: 0.7396\n",
            "Epoch 1964/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8142 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
            "Epoch 1965/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
            "Epoch 1966/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8090 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
            "Epoch 1967/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
            "Epoch 1968/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
            "Epoch 1969/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
            "Epoch 1970/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5482 - val_accuracy: 0.7292\n",
            "Epoch 1971/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
            "Epoch 1972/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8125 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
            "Epoch 1973/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8125 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 1974/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 1975/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
            "Epoch 1976/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
            "Epoch 1977/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8160 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 1978/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5482 - val_accuracy: 0.7292\n",
            "Epoch 1979/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5488 - val_accuracy: 0.7344\n",
            "Epoch 1980/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8056 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 1981/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
            "Epoch 1982/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5477 - val_accuracy: 0.7292\n",
            "Epoch 1983/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 1984/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5488 - val_accuracy: 0.7344\n",
            "Epoch 1985/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8108 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
            "Epoch 1986/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5492 - val_accuracy: 0.7344\n",
            "Epoch 1987/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8090 - val_loss: 0.5491 - val_accuracy: 0.7344\n",
            "Epoch 1988/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8073 - val_loss: 0.5492 - val_accuracy: 0.7344\n",
            "Epoch 1989/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 1990/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
            "Epoch 1991/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.5491 - val_accuracy: 0.7344\n",
            "Epoch 1992/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8142 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 1993/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8073 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
            "Epoch 1994/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8125 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
            "Epoch 1995/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
            "Epoch 1996/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8056 - val_loss: 0.5487 - val_accuracy: 0.7240\n",
            "Epoch 1997/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 1998/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8108 - val_loss: 0.5486 - val_accuracy: 0.7240\n",
            "Epoch 1999/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8056 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 2000/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 2001/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8073 - val_loss: 0.5505 - val_accuracy: 0.7344\n",
            "Epoch 2002/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5495 - val_accuracy: 0.7344\n",
            "Epoch 2003/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 2004/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8108 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
            "Epoch 2005/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4070 - accuracy: 0.8090 - val_loss: 0.5492 - val_accuracy: 0.7240\n",
            "Epoch 2006/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5500 - val_accuracy: 0.7344\n",
            "Epoch 2007/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5499 - val_accuracy: 0.7344\n",
            "Epoch 2008/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8090 - val_loss: 0.5495 - val_accuracy: 0.7240\n",
            "Epoch 2009/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
            "Epoch 2010/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5496 - val_accuracy: 0.7240\n",
            "Epoch 2011/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8160 - val_loss: 0.5501 - val_accuracy: 0.7344\n",
            "Epoch 2012/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5502 - val_accuracy: 0.7344\n",
            "Epoch 2013/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
            "Epoch 2014/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8142 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 2015/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
            "Epoch 2016/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.8142 - val_loss: 0.5502 - val_accuracy: 0.7292\n",
            "Epoch 2017/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
            "Epoch 2018/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4074 - accuracy: 0.8073 - val_loss: 0.5495 - val_accuracy: 0.7240\n",
            "Epoch 2019/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8073 - val_loss: 0.5498 - val_accuracy: 0.7240\n",
            "Epoch 2020/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
            "Epoch 2021/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5501 - val_accuracy: 0.7240\n",
            "Epoch 2022/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5502 - val_accuracy: 0.7240\n",
            "Epoch 2023/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5504 - val_accuracy: 0.7344\n",
            "Epoch 2024/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
            "Epoch 2025/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.8073 - val_loss: 0.5504 - val_accuracy: 0.7344\n",
            "Epoch 2026/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.5503 - val_accuracy: 0.7240\n",
            "Epoch 2027/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8160 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
            "Epoch 2028/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4066 - accuracy: 0.8125 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 2029/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5502 - val_accuracy: 0.7240\n",
            "Epoch 2030/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8073 - val_loss: 0.5508 - val_accuracy: 0.7344\n",
            "Epoch 2031/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5505 - val_accuracy: 0.7292\n",
            "Epoch 2032/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5502 - val_accuracy: 0.7240\n",
            "Epoch 2033/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5498 - val_accuracy: 0.7292\n",
            "Epoch 2034/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5501 - val_accuracy: 0.7240\n",
            "Epoch 2035/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
            "Epoch 2036/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5508 - val_accuracy: 0.7240\n",
            "Epoch 2037/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8090 - val_loss: 0.5511 - val_accuracy: 0.7344\n",
            "Epoch 2038/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8090 - val_loss: 0.5502 - val_accuracy: 0.7292\n",
            "Epoch 2039/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5510 - val_accuracy: 0.7292\n",
            "Epoch 2040/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.5503 - val_accuracy: 0.7240\n",
            "Epoch 2041/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8038 - val_loss: 0.5507 - val_accuracy: 0.7240\n",
            "Epoch 2042/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
            "Epoch 2043/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5515 - val_accuracy: 0.7292\n",
            "Epoch 2044/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
            "Epoch 2045/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
            "Epoch 2046/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5515 - val_accuracy: 0.7292\n",
            "Epoch 2047/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
            "Epoch 2048/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5511 - val_accuracy: 0.7240\n",
            "Epoch 2049/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8038 - val_loss: 0.5516 - val_accuracy: 0.7344\n",
            "Epoch 2050/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5515 - val_accuracy: 0.7292\n",
            "Epoch 2051/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8142 - val_loss: 0.5508 - val_accuracy: 0.7240\n",
            "Epoch 2052/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.5513 - val_accuracy: 0.7240\n",
            "Epoch 2053/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8142 - val_loss: 0.5519 - val_accuracy: 0.7344\n",
            "Epoch 2054/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5511 - val_accuracy: 0.7240\n",
            "Epoch 2055/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5512 - val_accuracy: 0.7240\n",
            "Epoch 2056/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5516 - val_accuracy: 0.7292\n",
            "Epoch 2057/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5516 - val_accuracy: 0.7240\n",
            "Epoch 2058/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5518 - val_accuracy: 0.7292\n",
            "Epoch 2059/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8125 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
            "Epoch 2060/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8125 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
            "Epoch 2061/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8125 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
            "Epoch 2062/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8090 - val_loss: 0.5511 - val_accuracy: 0.7240\n",
            "Epoch 2063/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5516 - val_accuracy: 0.7240\n",
            "Epoch 2064/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5517 - val_accuracy: 0.7292\n",
            "Epoch 2065/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8142 - val_loss: 0.5515 - val_accuracy: 0.7292\n",
            "Epoch 2066/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8038 - val_loss: 0.5518 - val_accuracy: 0.7292\n",
            "Epoch 2067/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
            "Epoch 2068/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8125 - val_loss: 0.5517 - val_accuracy: 0.7292\n",
            "Epoch 2069/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8073 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
            "Epoch 2070/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 2071/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8160 - val_loss: 0.5521 - val_accuracy: 0.7292\n",
            "Epoch 2072/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5517 - val_accuracy: 0.7292\n",
            "Epoch 2073/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.5512 - val_accuracy: 0.7240\n",
            "Epoch 2074/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5514 - val_accuracy: 0.7240\n",
            "Epoch 2075/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
            "Epoch 2076/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.5521 - val_accuracy: 0.7240\n",
            "Epoch 2077/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5520 - val_accuracy: 0.7292\n",
            "Epoch 2078/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8073 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
            "Epoch 2079/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8090 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
            "Epoch 2080/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8142 - val_loss: 0.5523 - val_accuracy: 0.7292\n",
            "Epoch 2081/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.5516 - val_accuracy: 0.7240\n",
            "Epoch 2082/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8073 - val_loss: 0.5509 - val_accuracy: 0.7344\n",
            "Epoch 2083/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5517 - val_accuracy: 0.7240\n",
            "Epoch 2084/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.5524 - val_accuracy: 0.7344\n",
            "Epoch 2085/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5524 - val_accuracy: 0.7344\n",
            "Epoch 2086/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5519 - val_accuracy: 0.7292\n",
            "Epoch 2087/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8142 - val_loss: 0.5515 - val_accuracy: 0.7240\n",
            "Epoch 2088/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8108 - val_loss: 0.5516 - val_accuracy: 0.7240\n",
            "Epoch 2089/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5523 - val_accuracy: 0.7240\n",
            "Epoch 2090/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
            "Epoch 2091/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5521 - val_accuracy: 0.7240\n",
            "Epoch 2092/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8142 - val_loss: 0.5522 - val_accuracy: 0.7240\n",
            "Epoch 2093/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4065 - accuracy: 0.8090 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
            "Epoch 2094/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5522 - val_accuracy: 0.7240\n",
            "Epoch 2095/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
            "Epoch 2096/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5525 - val_accuracy: 0.7240\n",
            "Epoch 2097/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8090 - val_loss: 0.5519 - val_accuracy: 0.7240\n",
            "Epoch 2098/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5518 - val_accuracy: 0.7240\n",
            "Epoch 2099/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5524 - val_accuracy: 0.7292\n",
            "Epoch 2100/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8090 - val_loss: 0.5521 - val_accuracy: 0.7240\n",
            "Epoch 2101/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5525 - val_accuracy: 0.7292\n",
            "Epoch 2102/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 2103/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8073 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
            "Epoch 2104/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
            "Epoch 2105/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 2106/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5521 - val_accuracy: 0.7240\n",
            "Epoch 2107/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
            "Epoch 2108/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8073 - val_loss: 0.5522 - val_accuracy: 0.7240\n",
            "Epoch 2109/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8073 - val_loss: 0.5525 - val_accuracy: 0.7292\n",
            "Epoch 2110/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5525 - val_accuracy: 0.7292\n",
            "Epoch 2111/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5520 - val_accuracy: 0.7292\n",
            "Epoch 2112/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5528 - val_accuracy: 0.7292\n",
            "Epoch 2113/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
            "Epoch 2114/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5525 - val_accuracy: 0.7292\n",
            "Epoch 2115/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.5521 - val_accuracy: 0.7240\n",
            "Epoch 2116/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
            "Epoch 2117/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8090 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
            "Epoch 2118/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8090 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
            "Epoch 2119/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
            "Epoch 2120/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5524 - val_accuracy: 0.7240\n",
            "Epoch 2121/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8073 - val_loss: 0.5518 - val_accuracy: 0.7292\n",
            "Epoch 2122/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.5522 - val_accuracy: 0.7240\n",
            "Epoch 2123/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5523 - val_accuracy: 0.7240\n",
            "Epoch 2124/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5529 - val_accuracy: 0.7292\n",
            "Epoch 2125/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8090 - val_loss: 0.5523 - val_accuracy: 0.7240\n",
            "Epoch 2126/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8090 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
            "Epoch 2127/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5529 - val_accuracy: 0.7292\n",
            "Epoch 2128/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
            "Epoch 2129/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5529 - val_accuracy: 0.7292\n",
            "Epoch 2130/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8142 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
            "Epoch 2131/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8142 - val_loss: 0.5525 - val_accuracy: 0.7240\n",
            "Epoch 2132/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5522 - val_accuracy: 0.7240\n",
            "Epoch 2133/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8142 - val_loss: 0.5525 - val_accuracy: 0.7240\n",
            "Epoch 2134/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8073 - val_loss: 0.5532 - val_accuracy: 0.7292\n",
            "Epoch 2135/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8142 - val_loss: 0.5526 - val_accuracy: 0.7240\n",
            "Epoch 2136/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5526 - val_accuracy: 0.7240\n",
            "Epoch 2137/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.5530 - val_accuracy: 0.7240\n",
            "Epoch 2138/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8090 - val_loss: 0.5530 - val_accuracy: 0.7240\n",
            "Epoch 2139/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8142 - val_loss: 0.5523 - val_accuracy: 0.7292\n",
            "Epoch 2140/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5522 - val_accuracy: 0.7292\n",
            "Epoch 2141/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5528 - val_accuracy: 0.7240\n",
            "Epoch 2142/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
            "Epoch 2143/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.8142 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
            "Epoch 2144/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5525 - val_accuracy: 0.7240\n",
            "Epoch 2145/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5528 - val_accuracy: 0.7240\n",
            "Epoch 2146/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8125 - val_loss: 0.5532 - val_accuracy: 0.7292\n",
            "Epoch 2147/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.5534 - val_accuracy: 0.7292\n",
            "Epoch 2148/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.5531 - val_accuracy: 0.7240\n",
            "Epoch 2149/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
            "Epoch 2150/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5532 - val_accuracy: 0.7240\n",
            "Epoch 2151/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.5530 - val_accuracy: 0.7240\n",
            "Epoch 2152/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4068 - accuracy: 0.8125 - val_loss: 0.5536 - val_accuracy: 0.7292\n",
            "Epoch 2153/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.5525 - val_accuracy: 0.7292\n",
            "Epoch 2154/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8160 - val_loss: 0.5530 - val_accuracy: 0.7240\n",
            "Epoch 2155/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.5525 - val_accuracy: 0.7292\n",
            "Epoch 2156/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5528 - val_accuracy: 0.7240\n",
            "Epoch 2157/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.5541 - val_accuracy: 0.7344\n",
            "Epoch 2158/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4068 - accuracy: 0.8125 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
            "Epoch 2159/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8142 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
            "Epoch 2160/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5534 - val_accuracy: 0.7292\n",
            "Epoch 2161/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4066 - accuracy: 0.8090 - val_loss: 0.5534 - val_accuracy: 0.7292\n",
            "Epoch 2162/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4063 - accuracy: 0.8090 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
            "Epoch 2163/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8090 - val_loss: 0.5544 - val_accuracy: 0.7344\n",
            "Epoch 2164/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8090 - val_loss: 0.5539 - val_accuracy: 0.7344\n",
            "Epoch 2165/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5543 - val_accuracy: 0.7344\n",
            "Epoch 2166/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8160 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
            "Epoch 2167/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5538 - val_accuracy: 0.7344\n",
            "Epoch 2168/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8090 - val_loss: 0.5527 - val_accuracy: 0.7240\n",
            "Epoch 2169/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8142 - val_loss: 0.5521 - val_accuracy: 0.7292\n",
            "Epoch 2170/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.5527 - val_accuracy: 0.7240\n",
            "Epoch 2171/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.5530 - val_accuracy: 0.7292\n",
            "Epoch 2172/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8142 - val_loss: 0.5529 - val_accuracy: 0.7292\n",
            "Epoch 2173/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8073 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
            "Epoch 2174/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8003 - val_loss: 0.5543 - val_accuracy: 0.7344\n",
            "Epoch 2175/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5528 - val_accuracy: 0.7292\n",
            "Epoch 2176/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
            "Epoch 2177/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8108 - val_loss: 0.5530 - val_accuracy: 0.7240\n",
            "Epoch 2178/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8142 - val_loss: 0.5530 - val_accuracy: 0.7292\n",
            "Epoch 2179/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5540 - val_accuracy: 0.7344\n",
            "Epoch 2180/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5536 - val_accuracy: 0.7292\n",
            "Epoch 2181/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8090 - val_loss: 0.5540 - val_accuracy: 0.7344\n",
            "Epoch 2182/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
            "Epoch 2183/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8142 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
            "Epoch 2184/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
            "Epoch 2185/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8090 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
            "Epoch 2186/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8090 - val_loss: 0.5532 - val_accuracy: 0.7292\n",
            "Epoch 2187/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8090 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
            "Epoch 2188/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
            "Epoch 2189/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.5531 - val_accuracy: 0.7292\n",
            "Epoch 2190/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.5523 - val_accuracy: 0.7292\n",
            "Epoch 2191/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.5519 - val_accuracy: 0.7344\n",
            "Epoch 2192/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
            "Epoch 2193/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
            "Epoch 2194/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8056 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
            "Epoch 2195/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
            "Epoch 2196/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
            "Epoch 2197/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8056 - val_loss: 0.5523 - val_accuracy: 0.7292\n",
            "Epoch 2198/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.5542 - val_accuracy: 0.7344\n",
            "Epoch 2199/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8125 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
            "Epoch 2200/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
            "Epoch 2201/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.5522 - val_accuracy: 0.7292\n",
            "Epoch 2202/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8090 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
            "Epoch 2203/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8090 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
            "Epoch 2204/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8073 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
            "Epoch 2205/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8108 - val_loss: 0.5513 - val_accuracy: 0.7344\n",
            "Epoch 2206/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8073 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
            "Epoch 2207/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
            "Epoch 2208/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 2209/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8090 - val_loss: 0.5511 - val_accuracy: 0.7344\n",
            "Epoch 2210/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8108 - val_loss: 0.5511 - val_accuracy: 0.7344\n",
            "Epoch 2211/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8090 - val_loss: 0.5520 - val_accuracy: 0.7344\n",
            "Epoch 2212/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8142 - val_loss: 0.5512 - val_accuracy: 0.7292\n",
            "Epoch 2213/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8090 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
            "Epoch 2214/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8090 - val_loss: 0.5504 - val_accuracy: 0.7344\n",
            "Epoch 2215/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8056 - val_loss: 0.5516 - val_accuracy: 0.7292\n",
            "Epoch 2216/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8108 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 2217/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8108 - val_loss: 0.5510 - val_accuracy: 0.7292\n",
            "Epoch 2218/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.5503 - val_accuracy: 0.7344\n",
            "Epoch 2219/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 2220/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8108 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
            "Epoch 2221/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8090 - val_loss: 0.5512 - val_accuracy: 0.7292\n",
            "Epoch 2222/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8142 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
            "Epoch 2223/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.5505 - val_accuracy: 0.7292\n",
            "Epoch 2224/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
            "Epoch 2225/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5510 - val_accuracy: 0.7292\n",
            "Epoch 2226/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
            "Epoch 2227/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
            "Epoch 2228/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8160 - val_loss: 0.5498 - val_accuracy: 0.7344\n",
            "Epoch 2229/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.5502 - val_accuracy: 0.7344\n",
            "Epoch 2230/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5500 - val_accuracy: 0.7344\n",
            "Epoch 2231/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8073 - val_loss: 0.5507 - val_accuracy: 0.7292\n",
            "Epoch 2232/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5499 - val_accuracy: 0.7344\n",
            "Epoch 2233/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.5501 - val_accuracy: 0.7292\n",
            "Epoch 2234/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8073 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
            "Epoch 2235/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8142 - val_loss: 0.5510 - val_accuracy: 0.7344\n",
            "Epoch 2236/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8108 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
            "Epoch 2237/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8090 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
            "Epoch 2238/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8073 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
            "Epoch 2239/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8073 - val_loss: 0.5494 - val_accuracy: 0.7344\n",
            "Epoch 2240/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8108 - val_loss: 0.5488 - val_accuracy: 0.7344\n",
            "Epoch 2241/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8090 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 2242/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8073 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 2243/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8108 - val_loss: 0.5497 - val_accuracy: 0.7448\n",
            "Epoch 2244/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8142 - val_loss: 0.5478 - val_accuracy: 0.7448\n",
            "Epoch 2245/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8073 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
            "Epoch 2246/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8090 - val_loss: 0.5483 - val_accuracy: 0.7396\n",
            "Epoch 2247/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8090 - val_loss: 0.5478 - val_accuracy: 0.7396\n",
            "Epoch 2248/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8073 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
            "Epoch 2249/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8073 - val_loss: 0.5471 - val_accuracy: 0.7396\n",
            "Epoch 2250/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5461 - val_accuracy: 0.7448\n",
            "Epoch 2251/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8073 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
            "Epoch 2252/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8056 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
            "Epoch 2253/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8125 - val_loss: 0.5454 - val_accuracy: 0.7500\n",
            "Epoch 2254/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8125 - val_loss: 0.5449 - val_accuracy: 0.7500\n",
            "Epoch 2255/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8108 - val_loss: 0.5445 - val_accuracy: 0.7500\n",
            "Epoch 2256/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
            "Epoch 2257/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
            "Epoch 2258/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5440 - val_accuracy: 0.7500\n",
            "Epoch 2259/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8125 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 2260/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8038 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
            "Epoch 2261/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
            "Epoch 2262/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8073 - val_loss: 0.5436 - val_accuracy: 0.7396\n",
            "Epoch 2263/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
            "Epoch 2264/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5427 - val_accuracy: 0.7396\n",
            "Epoch 2265/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8056 - val_loss: 0.5424 - val_accuracy: 0.7396\n",
            "Epoch 2266/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8108 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
            "Epoch 2267/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8073 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
            "Epoch 2268/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8090 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 2269/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 2270/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 2271/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8090 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 2272/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8056 - val_loss: 0.5413 - val_accuracy: 0.7344\n",
            "Epoch 2273/3000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4034 - accuracy: 0.8073 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
            "Epoch 2274/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8073 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
            "Epoch 2275/3000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4029 - accuracy: 0.8073 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
            "Epoch 2276/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8073 - val_loss: 0.5397 - val_accuracy: 0.7448\n",
            "Epoch 2277/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8090 - val_loss: 0.5395 - val_accuracy: 0.7448\n",
            "Epoch 2278/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8125 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
            "Epoch 2279/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4027 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
            "Epoch 2280/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5389 - val_accuracy: 0.7396\n",
            "Epoch 2281/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.5388 - val_accuracy: 0.7396\n",
            "Epoch 2282/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8108 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
            "Epoch 2283/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
            "Epoch 2284/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8142 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
            "Epoch 2285/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
            "Epoch 2286/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8108 - val_loss: 0.5385 - val_accuracy: 0.7448\n",
            "Epoch 2287/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8038 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 2288/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8125 - val_loss: 0.5386 - val_accuracy: 0.7448\n",
            "Epoch 2289/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.8108 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
            "Epoch 2290/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8073 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 2291/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4021 - accuracy: 0.8108 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
            "Epoch 2292/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8125 - val_loss: 0.5382 - val_accuracy: 0.7448\n",
            "Epoch 2293/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8142 - val_loss: 0.5382 - val_accuracy: 0.7448\n",
            "Epoch 2294/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8090 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
            "Epoch 2295/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4019 - accuracy: 0.8073 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
            "Epoch 2296/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8142 - val_loss: 0.5378 - val_accuracy: 0.7448\n",
            "Epoch 2297/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.8056 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
            "Epoch 2298/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8142 - val_loss: 0.5388 - val_accuracy: 0.7396\n",
            "Epoch 2299/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4013 - accuracy: 0.8160 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
            "Epoch 2300/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8108 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
            "Epoch 2301/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8125 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
            "Epoch 2302/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8125 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
            "Epoch 2303/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8160 - val_loss: 0.5388 - val_accuracy: 0.7396\n",
            "Epoch 2304/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8056 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
            "Epoch 2305/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8160 - val_loss: 0.5375 - val_accuracy: 0.7448\n",
            "Epoch 2306/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8160 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
            "Epoch 2307/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5387 - val_accuracy: 0.7396\n",
            "Epoch 2308/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8142 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
            "Epoch 2309/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8108 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
            "Epoch 2310/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8142 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
            "Epoch 2311/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8090 - val_loss: 0.5378 - val_accuracy: 0.7396\n",
            "Epoch 2312/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8090 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
            "Epoch 2313/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8090 - val_loss: 0.5385 - val_accuracy: 0.7448\n",
            "Epoch 2314/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8125 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
            "Epoch 2315/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8142 - val_loss: 0.5377 - val_accuracy: 0.7448\n",
            "Epoch 2316/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8073 - val_loss: 0.5384 - val_accuracy: 0.7448\n",
            "Epoch 2317/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8108 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
            "Epoch 2318/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8125 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
            "Epoch 2319/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8125 - val_loss: 0.5393 - val_accuracy: 0.7448\n",
            "Epoch 2320/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8177 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
            "Epoch 2321/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8056 - val_loss: 0.5392 - val_accuracy: 0.7448\n",
            "Epoch 2322/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8142 - val_loss: 0.5392 - val_accuracy: 0.7448\n",
            "Epoch 2323/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8142 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
            "Epoch 2324/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8090 - val_loss: 0.5398 - val_accuracy: 0.7448\n",
            "Epoch 2325/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8125 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
            "Epoch 2326/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8160 - val_loss: 0.5394 - val_accuracy: 0.7448\n",
            "Epoch 2327/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8160 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
            "Epoch 2328/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8142 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
            "Epoch 2329/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8142 - val_loss: 0.5398 - val_accuracy: 0.7448\n",
            "Epoch 2330/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8194 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
            "Epoch 2331/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 0.5408 - val_accuracy: 0.7396\n",
            "Epoch 2332/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7448\n",
            "Epoch 2333/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8125 - val_loss: 0.5408 - val_accuracy: 0.7396\n",
            "Epoch 2334/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8108 - val_loss: 0.5409 - val_accuracy: 0.7396\n",
            "Epoch 2335/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8177 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
            "Epoch 2336/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8194 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
            "Epoch 2337/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8142 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
            "Epoch 2338/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8108 - val_loss: 0.5404 - val_accuracy: 0.7448\n",
            "Epoch 2339/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5407 - val_accuracy: 0.7448\n",
            "Epoch 2340/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8142 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
            "Epoch 2341/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8108 - val_loss: 0.5411 - val_accuracy: 0.7396\n",
            "Epoch 2342/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8194 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
            "Epoch 2343/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8108 - val_loss: 0.5408 - val_accuracy: 0.7448\n",
            "Epoch 2344/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8073 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
            "Epoch 2345/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8194 - val_loss: 0.5407 - val_accuracy: 0.7396\n",
            "Epoch 2346/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8177 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
            "Epoch 2347/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8108 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
            "Epoch 2348/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8177 - val_loss: 0.5414 - val_accuracy: 0.7448\n",
            "Epoch 2349/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8194 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
            "Epoch 2350/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8142 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
            "Epoch 2351/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8194 - val_loss: 0.5416 - val_accuracy: 0.7396\n",
            "Epoch 2352/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8194 - val_loss: 0.5408 - val_accuracy: 0.7448\n",
            "Epoch 2353/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5419 - val_accuracy: 0.7448\n",
            "Epoch 2354/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8177 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
            "Epoch 2355/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8108 - val_loss: 0.5417 - val_accuracy: 0.7396\n",
            "Epoch 2356/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
            "Epoch 2357/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8142 - val_loss: 0.5425 - val_accuracy: 0.7396\n",
            "Epoch 2358/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8194 - val_loss: 0.5416 - val_accuracy: 0.7396\n",
            "Epoch 2359/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8160 - val_loss: 0.5418 - val_accuracy: 0.7396\n",
            "Epoch 2360/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8177 - val_loss: 0.5416 - val_accuracy: 0.7396\n",
            "Epoch 2361/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8108 - val_loss: 0.5422 - val_accuracy: 0.7448\n",
            "Epoch 2362/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8073 - val_loss: 0.5431 - val_accuracy: 0.7344\n",
            "Epoch 2363/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8212 - val_loss: 0.5421 - val_accuracy: 0.7396\n",
            "Epoch 2364/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8177 - val_loss: 0.5423 - val_accuracy: 0.7396\n",
            "Epoch 2365/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8160 - val_loss: 0.5424 - val_accuracy: 0.7448\n",
            "Epoch 2366/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8142 - val_loss: 0.5423 - val_accuracy: 0.7396\n",
            "Epoch 2367/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8160 - val_loss: 0.5424 - val_accuracy: 0.7396\n",
            "Epoch 2368/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8125 - val_loss: 0.5419 - val_accuracy: 0.7448\n",
            "Epoch 2369/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8056 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
            "Epoch 2370/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8090 - val_loss: 0.5430 - val_accuracy: 0.7396\n",
            "Epoch 2371/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8160 - val_loss: 0.5429 - val_accuracy: 0.7448\n",
            "Epoch 2372/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8194 - val_loss: 0.5427 - val_accuracy: 0.7396\n",
            "Epoch 2373/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8142 - val_loss: 0.5430 - val_accuracy: 0.7448\n",
            "Epoch 2374/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8142 - val_loss: 0.5437 - val_accuracy: 0.7344\n",
            "Epoch 2375/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8177 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
            "Epoch 2376/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8194 - val_loss: 0.5434 - val_accuracy: 0.7396\n",
            "Epoch 2377/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8177 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
            "Epoch 2378/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8177 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
            "Epoch 2379/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8108 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 2380/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8194 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 2381/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8142 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 2382/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8212 - val_loss: 0.5438 - val_accuracy: 0.7448\n",
            "Epoch 2383/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8212 - val_loss: 0.5434 - val_accuracy: 0.7396\n",
            "Epoch 2384/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8177 - val_loss: 0.5439 - val_accuracy: 0.7344\n",
            "Epoch 2385/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8125 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
            "Epoch 2386/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8125 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
            "Epoch 2387/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8160 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
            "Epoch 2388/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8090 - val_loss: 0.5441 - val_accuracy: 0.7448\n",
            "Epoch 2389/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8160 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 2390/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8142 - val_loss: 0.5450 - val_accuracy: 0.7344\n",
            "Epoch 2391/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8177 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
            "Epoch 2392/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8142 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
            "Epoch 2393/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8125 - val_loss: 0.5446 - val_accuracy: 0.7396\n",
            "Epoch 2394/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8108 - val_loss: 0.5446 - val_accuracy: 0.7396\n",
            "Epoch 2395/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8177 - val_loss: 0.5446 - val_accuracy: 0.7396\n",
            "Epoch 2396/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8177 - val_loss: 0.5441 - val_accuracy: 0.7448\n",
            "Epoch 2397/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8177 - val_loss: 0.5453 - val_accuracy: 0.7344\n",
            "Epoch 2398/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8177 - val_loss: 0.5455 - val_accuracy: 0.7344\n",
            "Epoch 2399/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8142 - val_loss: 0.5456 - val_accuracy: 0.7344\n",
            "Epoch 2400/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8142 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 2401/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8177 - val_loss: 0.5441 - val_accuracy: 0.7448\n",
            "Epoch 2402/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8160 - val_loss: 0.5445 - val_accuracy: 0.7448\n",
            "Epoch 2403/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8125 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
            "Epoch 2404/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5445 - val_accuracy: 0.7448\n",
            "Epoch 2405/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 2406/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8142 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 2407/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8142 - val_loss: 0.5463 - val_accuracy: 0.7344\n",
            "Epoch 2408/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
            "Epoch 2409/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8125 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 2410/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8160 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 2411/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8194 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 2412/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8125 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 2413/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8194 - val_loss: 0.5448 - val_accuracy: 0.7448\n",
            "Epoch 2414/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8142 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 2415/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8142 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 2416/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8125 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
            "Epoch 2417/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8142 - val_loss: 0.5469 - val_accuracy: 0.7344\n",
            "Epoch 2418/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 2419/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8142 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
            "Epoch 2420/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5467 - val_accuracy: 0.7344\n",
            "Epoch 2421/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8142 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
            "Epoch 2422/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8194 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 2423/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 2424/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8142 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
            "Epoch 2425/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8142 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
            "Epoch 2426/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5466 - val_accuracy: 0.7344\n",
            "Epoch 2427/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8194 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
            "Epoch 2428/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8090 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
            "Epoch 2429/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8212 - val_loss: 0.5460 - val_accuracy: 0.7448\n",
            "Epoch 2430/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8177 - val_loss: 0.5463 - val_accuracy: 0.7396\n",
            "Epoch 2431/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8212 - val_loss: 0.5456 - val_accuracy: 0.7448\n",
            "Epoch 2432/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8160 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
            "Epoch 2433/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8194 - val_loss: 0.5461 - val_accuracy: 0.7396\n",
            "Epoch 2434/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8160 - val_loss: 0.5462 - val_accuracy: 0.7396\n",
            "Epoch 2435/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8177 - val_loss: 0.5458 - val_accuracy: 0.7448\n",
            "Epoch 2436/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8177 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
            "Epoch 2437/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8108 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
            "Epoch 2438/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8177 - val_loss: 0.5471 - val_accuracy: 0.7344\n",
            "Epoch 2439/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8125 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
            "Epoch 2440/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8212 - val_loss: 0.5465 - val_accuracy: 0.7396\n",
            "Epoch 2441/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8160 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
            "Epoch 2442/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8142 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
            "Epoch 2443/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8125 - val_loss: 0.5471 - val_accuracy: 0.7344\n",
            "Epoch 2444/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8142 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
            "Epoch 2445/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
            "Epoch 2446/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8194 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
            "Epoch 2447/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8177 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
            "Epoch 2448/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5466 - val_accuracy: 0.7448\n",
            "Epoch 2449/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8142 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
            "Epoch 2450/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8142 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
            "Epoch 2451/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8194 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
            "Epoch 2452/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8194 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
            "Epoch 2453/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8177 - val_loss: 0.5469 - val_accuracy: 0.7396\n",
            "Epoch 2454/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.5472 - val_accuracy: 0.7396\n",
            "Epoch 2455/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8194 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 2456/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8177 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
            "Epoch 2457/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 2458/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8125 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
            "Epoch 2459/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8177 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
            "Epoch 2460/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8194 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
            "Epoch 2461/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8160 - val_loss: 0.5474 - val_accuracy: 0.7344\n",
            "Epoch 2462/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8160 - val_loss: 0.5470 - val_accuracy: 0.7396\n",
            "Epoch 2463/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8108 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
            "Epoch 2464/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8160 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 2465/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8194 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
            "Epoch 2466/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
            "Epoch 2467/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 2468/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8194 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
            "Epoch 2469/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
            "Epoch 2470/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8142 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 2471/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8194 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
            "Epoch 2472/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8142 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
            "Epoch 2473/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8160 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 2474/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8177 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 2475/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5478 - val_accuracy: 0.7396\n",
            "Epoch 2476/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5479 - val_accuracy: 0.7396\n",
            "Epoch 2477/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
            "Epoch 2478/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8212 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 2479/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8160 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 2480/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8194 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 2481/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8229 - val_loss: 0.5484 - val_accuracy: 0.7344\n",
            "Epoch 2482/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8142 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
            "Epoch 2483/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5498 - val_accuracy: 0.7292\n",
            "Epoch 2484/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8194 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 2485/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8212 - val_loss: 0.5492 - val_accuracy: 0.7344\n",
            "Epoch 2486/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8177 - val_loss: 0.5480 - val_accuracy: 0.7396\n",
            "Epoch 2487/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8125 - val_loss: 0.5494 - val_accuracy: 0.7344\n",
            "Epoch 2488/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8177 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
            "Epoch 2489/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8108 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 2490/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8212 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 2491/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8212 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
            "Epoch 2492/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8142 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 2493/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8194 - val_loss: 0.5492 - val_accuracy: 0.7344\n",
            "Epoch 2494/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8160 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 2495/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8177 - val_loss: 0.5492 - val_accuracy: 0.7344\n",
            "Epoch 2496/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8160 - val_loss: 0.5496 - val_accuracy: 0.7344\n",
            "Epoch 2497/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5485 - val_accuracy: 0.7396\n",
            "Epoch 2498/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8177 - val_loss: 0.5482 - val_accuracy: 0.7448\n",
            "Epoch 2499/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8177 - val_loss: 0.5489 - val_accuracy: 0.7396\n",
            "Epoch 2500/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8142 - val_loss: 0.5495 - val_accuracy: 0.7344\n",
            "Epoch 2501/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5495 - val_accuracy: 0.7344\n",
            "Epoch 2502/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8212 - val_loss: 0.5488 - val_accuracy: 0.7448\n",
            "Epoch 2503/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8142 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 2504/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8142 - val_loss: 0.5497 - val_accuracy: 0.7396\n",
            "Epoch 2505/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8160 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 2506/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8160 - val_loss: 0.5491 - val_accuracy: 0.7396\n",
            "Epoch 2507/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5501 - val_accuracy: 0.7344\n",
            "Epoch 2508/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8194 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 2509/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 2510/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8194 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 2511/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8194 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 2512/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8142 - val_loss: 0.5497 - val_accuracy: 0.7396\n",
            "Epoch 2513/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8212 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 2514/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8212 - val_loss: 0.5497 - val_accuracy: 0.7396\n",
            "Epoch 2515/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8160 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
            "Epoch 2516/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8177 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 2517/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8142 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 2518/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8142 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 2519/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8229 - val_loss: 0.5491 - val_accuracy: 0.7396\n",
            "Epoch 2520/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8160 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 2521/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8229 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 2522/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8125 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
            "Epoch 2523/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8142 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
            "Epoch 2524/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8212 - val_loss: 0.5500 - val_accuracy: 0.7396\n",
            "Epoch 2525/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8177 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 2526/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8194 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 2527/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8125 - val_loss: 0.5500 - val_accuracy: 0.7396\n",
            "Epoch 2528/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8194 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 2529/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8142 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 2530/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 2531/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8142 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 2532/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8194 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
            "Epoch 2533/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8281 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 2534/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8177 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 2535/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8194 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 2536/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 2537/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8212 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
            "Epoch 2538/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8194 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 2539/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8194 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 2540/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8108 - val_loss: 0.5510 - val_accuracy: 0.7396\n",
            "Epoch 2541/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8194 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 2542/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8247 - val_loss: 0.5497 - val_accuracy: 0.7396\n",
            "Epoch 2543/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8125 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 2544/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8160 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 2545/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 2546/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8142 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 2547/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8142 - val_loss: 0.5520 - val_accuracy: 0.7344\n",
            "Epoch 2548/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
            "Epoch 2549/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8160 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 2550/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 2551/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 2552/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8160 - val_loss: 0.5497 - val_accuracy: 0.7396\n",
            "Epoch 2553/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8160 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
            "Epoch 2554/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8194 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
            "Epoch 2555/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8160 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 2556/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8142 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
            "Epoch 2557/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8212 - val_loss: 0.5509 - val_accuracy: 0.7396\n",
            "Epoch 2558/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8212 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 2559/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8212 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
            "Epoch 2560/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8160 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 2561/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3977 - accuracy: 0.8160 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 2562/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8142 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 2563/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8160 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
            "Epoch 2564/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8160 - val_loss: 0.5500 - val_accuracy: 0.7396\n",
            "Epoch 2565/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
            "Epoch 2566/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8142 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 2567/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8177 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 2568/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8160 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 2569/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8142 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 2570/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8194 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 2571/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8229 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
            "Epoch 2572/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8194 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 2573/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8177 - val_loss: 0.5497 - val_accuracy: 0.7396\n",
            "Epoch 2574/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8177 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 2575/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8125 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 2576/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 2577/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8125 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
            "Epoch 2578/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8177 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
            "Epoch 2579/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
            "Epoch 2580/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8229 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 2581/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8212 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 2582/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8194 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 2583/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8142 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 2584/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8212 - val_loss: 0.5510 - val_accuracy: 0.7396\n",
            "Epoch 2585/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8229 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 2586/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8160 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 2587/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8160 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 2588/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8177 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 2589/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8212 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 2590/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8212 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 2591/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8177 - val_loss: 0.5512 - val_accuracy: 0.7396\n",
            "Epoch 2592/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8177 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 2593/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8142 - val_loss: 0.5512 - val_accuracy: 0.7396\n",
            "Epoch 2594/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8229 - val_loss: 0.5509 - val_accuracy: 0.7396\n",
            "Epoch 2595/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8229 - val_loss: 0.5501 - val_accuracy: 0.7448\n",
            "Epoch 2596/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8177 - val_loss: 0.5502 - val_accuracy: 0.7448\n",
            "Epoch 2597/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8125 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
            "Epoch 2598/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8177 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 2599/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8229 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 2600/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.5509 - val_accuracy: 0.7396\n",
            "Epoch 2601/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 2602/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8229 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 2603/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8177 - val_loss: 0.5500 - val_accuracy: 0.7396\n",
            "Epoch 2604/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8125 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 2605/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 2606/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5510 - val_accuracy: 0.7396\n",
            "Epoch 2607/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8177 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 2608/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8212 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 2609/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8125 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 2610/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8281 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
            "Epoch 2611/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8125 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
            "Epoch 2612/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
            "Epoch 2613/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8212 - val_loss: 0.5513 - val_accuracy: 0.7396\n",
            "Epoch 2614/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 2615/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
            "Epoch 2616/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 2617/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
            "Epoch 2618/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
            "Epoch 2619/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 2620/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 2621/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8177 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 2622/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8264 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 2623/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8177 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
            "Epoch 2624/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5516 - val_accuracy: 0.7396\n",
            "Epoch 2625/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
            "Epoch 2626/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8229 - val_loss: 0.5506 - val_accuracy: 0.7448\n",
            "Epoch 2627/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8125 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 2628/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8212 - val_loss: 0.5513 - val_accuracy: 0.7396\n",
            "Epoch 2629/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8177 - val_loss: 0.5513 - val_accuracy: 0.7396\n",
            "Epoch 2630/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 2631/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8264 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 2632/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8142 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 2633/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
            "Epoch 2634/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8160 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
            "Epoch 2635/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8125 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
            "Epoch 2636/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8160 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
            "Epoch 2637/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8177 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
            "Epoch 2638/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8212 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
            "Epoch 2639/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8142 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
            "Epoch 2640/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8194 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
            "Epoch 2641/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8177 - val_loss: 0.5522 - val_accuracy: 0.7396\n",
            "Epoch 2642/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8125 - val_loss: 0.5522 - val_accuracy: 0.7396\n",
            "Epoch 2643/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8160 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
            "Epoch 2644/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8160 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 2645/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
            "Epoch 2646/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8229 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
            "Epoch 2647/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8125 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
            "Epoch 2648/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8142 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
            "Epoch 2649/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8177 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
            "Epoch 2650/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8229 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
            "Epoch 2651/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8125 - val_loss: 0.5523 - val_accuracy: 0.7396\n",
            "Epoch 2652/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8177 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
            "Epoch 2653/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8212 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
            "Epoch 2654/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8177 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
            "Epoch 2655/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5516 - val_accuracy: 0.7396\n",
            "Epoch 2656/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8177 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 2657/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8142 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
            "Epoch 2658/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
            "Epoch 2659/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8142 - val_loss: 0.5522 - val_accuracy: 0.7396\n",
            "Epoch 2660/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5514 - val_accuracy: 0.7448\n",
            "Epoch 2661/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8177 - val_loss: 0.5522 - val_accuracy: 0.7396\n",
            "Epoch 2662/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8125 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 2663/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8177 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 2664/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8160 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
            "Epoch 2665/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
            "Epoch 2666/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8212 - val_loss: 0.5525 - val_accuracy: 0.7396\n",
            "Epoch 2667/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8177 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
            "Epoch 2668/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
            "Epoch 2669/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8212 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
            "Epoch 2670/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8177 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
            "Epoch 2671/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3964 - accuracy: 0.8212 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 2672/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8212 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
            "Epoch 2673/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8160 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 2674/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3965 - accuracy: 0.8177 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
            "Epoch 2675/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5522 - val_accuracy: 0.7396\n",
            "Epoch 2676/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8229 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
            "Epoch 2677/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8125 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
            "Epoch 2678/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8194 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
            "Epoch 2679/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8177 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
            "Epoch 2680/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8142 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
            "Epoch 2681/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8160 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
            "Epoch 2682/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 2683/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5523 - val_accuracy: 0.7396\n",
            "Epoch 2684/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8177 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
            "Epoch 2685/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8212 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
            "Epoch 2686/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 2687/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8177 - val_loss: 0.5530 - val_accuracy: 0.7396\n",
            "Epoch 2688/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8194 - val_loss: 0.5539 - val_accuracy: 0.7344\n",
            "Epoch 2689/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8212 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
            "Epoch 2690/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8229 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
            "Epoch 2691/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 2692/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8160 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
            "Epoch 2693/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8160 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 2694/3000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3962 - accuracy: 0.8160 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
            "Epoch 2695/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3971 - accuracy: 0.8142 - val_loss: 0.5538 - val_accuracy: 0.7396\n",
            "Epoch 2696/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8160 - val_loss: 0.5543 - val_accuracy: 0.7396\n",
            "Epoch 2697/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8177 - val_loss: 0.5544 - val_accuracy: 0.7344\n",
            "Epoch 2698/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3968 - accuracy: 0.8177 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
            "Epoch 2699/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3965 - accuracy: 0.8177 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
            "Epoch 2700/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8212 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
            "Epoch 2701/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8194 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
            "Epoch 2702/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8177 - val_loss: 0.5538 - val_accuracy: 0.7396\n",
            "Epoch 2703/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
            "Epoch 2704/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8194 - val_loss: 0.5538 - val_accuracy: 0.7396\n",
            "Epoch 2705/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8108 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
            "Epoch 2706/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
            "Epoch 2707/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8177 - val_loss: 0.5538 - val_accuracy: 0.7396\n",
            "Epoch 2708/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8229 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
            "Epoch 2709/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.5544 - val_accuracy: 0.7344\n",
            "Epoch 2710/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8177 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 2711/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8229 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
            "Epoch 2712/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5530 - val_accuracy: 0.7396\n",
            "Epoch 2713/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8142 - val_loss: 0.5543 - val_accuracy: 0.7396\n",
            "Epoch 2714/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8177 - val_loss: 0.5550 - val_accuracy: 0.7344\n",
            "Epoch 2715/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5536 - val_accuracy: 0.7396\n",
            "Epoch 2716/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8160 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 2717/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8160 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 2718/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8160 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
            "Epoch 2719/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8247 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
            "Epoch 2720/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5538 - val_accuracy: 0.7396\n",
            "Epoch 2721/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5553 - val_accuracy: 0.7344\n",
            "Epoch 2722/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 2723/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8177 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
            "Epoch 2724/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.5552 - val_accuracy: 0.7344\n",
            "Epoch 2725/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8247 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
            "Epoch 2726/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8160 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
            "Epoch 2727/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8212 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
            "Epoch 2728/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8212 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
            "Epoch 2729/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5543 - val_accuracy: 0.7396\n",
            "Epoch 2730/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5539 - val_accuracy: 0.7396\n",
            "Epoch 2731/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
            "Epoch 2732/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8177 - val_loss: 0.5545 - val_accuracy: 0.7396\n",
            "Epoch 2733/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8194 - val_loss: 0.5539 - val_accuracy: 0.7396\n",
            "Epoch 2734/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8212 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 2735/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 2736/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
            "Epoch 2737/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 2738/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8108 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
            "Epoch 2739/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5554 - val_accuracy: 0.7344\n",
            "Epoch 2740/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8247 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
            "Epoch 2741/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.5539 - val_accuracy: 0.7396\n",
            "Epoch 2742/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
            "Epoch 2743/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8125 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 2744/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8160 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 2745/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8160 - val_loss: 0.5536 - val_accuracy: 0.7396\n",
            "Epoch 2746/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8229 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
            "Epoch 2747/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8160 - val_loss: 0.5543 - val_accuracy: 0.7396\n",
            "Epoch 2748/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8125 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
            "Epoch 2749/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
            "Epoch 2750/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8177 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
            "Epoch 2751/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8142 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 2752/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8142 - val_loss: 0.5545 - val_accuracy: 0.7396\n",
            "Epoch 2753/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8160 - val_loss: 0.5556 - val_accuracy: 0.7396\n",
            "Epoch 2754/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8160 - val_loss: 0.5555 - val_accuracy: 0.7396\n",
            "Epoch 2755/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8247 - val_loss: 0.5554 - val_accuracy: 0.7396\n",
            "Epoch 2756/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8212 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
            "Epoch 2757/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8142 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
            "Epoch 2758/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 2759/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8212 - val_loss: 0.5556 - val_accuracy: 0.7344\n",
            "Epoch 2760/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8160 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
            "Epoch 2761/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 2762/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8125 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
            "Epoch 2763/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8194 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 2764/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
            "Epoch 2765/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8194 - val_loss: 0.5551 - val_accuracy: 0.7396\n",
            "Epoch 2766/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8194 - val_loss: 0.5558 - val_accuracy: 0.7344\n",
            "Epoch 2767/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
            "Epoch 2768/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8125 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
            "Epoch 2769/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
            "Epoch 2770/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8194 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
            "Epoch 2771/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8177 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
            "Epoch 2772/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8142 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
            "Epoch 2773/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8194 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
            "Epoch 2774/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8160 - val_loss: 0.5557 - val_accuracy: 0.7396\n",
            "Epoch 2775/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8160 - val_loss: 0.5555 - val_accuracy: 0.7396\n",
            "Epoch 2776/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8194 - val_loss: 0.5556 - val_accuracy: 0.7396\n",
            "Epoch 2777/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5556 - val_accuracy: 0.7396\n",
            "Epoch 2778/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8142 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
            "Epoch 2779/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
            "Epoch 2780/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8160 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
            "Epoch 2781/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5557 - val_accuracy: 0.7396\n",
            "Epoch 2782/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
            "Epoch 2783/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8177 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
            "Epoch 2784/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5562 - val_accuracy: 0.7396\n",
            "Epoch 2785/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8229 - val_loss: 0.5554 - val_accuracy: 0.7396\n",
            "Epoch 2786/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8229 - val_loss: 0.5551 - val_accuracy: 0.7396\n",
            "Epoch 2787/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8090 - val_loss: 0.5559 - val_accuracy: 0.7396\n",
            "Epoch 2788/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8194 - val_loss: 0.5565 - val_accuracy: 0.7396\n",
            "Epoch 2789/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5560 - val_accuracy: 0.7396\n",
            "Epoch 2790/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8142 - val_loss: 0.5561 - val_accuracy: 0.7396\n",
            "Epoch 2791/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8125 - val_loss: 0.5575 - val_accuracy: 0.7396\n",
            "Epoch 2792/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8194 - val_loss: 0.5565 - val_accuracy: 0.7396\n",
            "Epoch 2793/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5569 - val_accuracy: 0.7344\n",
            "Epoch 2794/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8194 - val_loss: 0.5565 - val_accuracy: 0.7396\n",
            "Epoch 2795/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8142 - val_loss: 0.5564 - val_accuracy: 0.7396\n",
            "Epoch 2796/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5572 - val_accuracy: 0.7344\n",
            "Epoch 2797/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8160 - val_loss: 0.5561 - val_accuracy: 0.7396\n",
            "Epoch 2798/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8160 - val_loss: 0.5564 - val_accuracy: 0.7396\n",
            "Epoch 2799/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8160 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
            "Epoch 2800/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5565 - val_accuracy: 0.7396\n",
            "Epoch 2801/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8160 - val_loss: 0.5572 - val_accuracy: 0.7344\n",
            "Epoch 2802/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8108 - val_loss: 0.5575 - val_accuracy: 0.7396\n",
            "Epoch 2803/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 2804/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3959 - accuracy: 0.8160 - val_loss: 0.5560 - val_accuracy: 0.7396\n",
            "Epoch 2805/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8125 - val_loss: 0.5584 - val_accuracy: 0.7396\n",
            "Epoch 2806/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8160 - val_loss: 0.5569 - val_accuracy: 0.7396\n",
            "Epoch 2807/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8212 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
            "Epoch 2808/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8160 - val_loss: 0.5578 - val_accuracy: 0.7344\n",
            "Epoch 2809/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5582 - val_accuracy: 0.7396\n",
            "Epoch 2810/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8212 - val_loss: 0.5560 - val_accuracy: 0.7396\n",
            "Epoch 2811/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8194 - val_loss: 0.5569 - val_accuracy: 0.7344\n",
            "Epoch 2812/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 2813/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8160 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
            "Epoch 2814/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8212 - val_loss: 0.5564 - val_accuracy: 0.7396\n",
            "Epoch 2815/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8194 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
            "Epoch 2816/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5576 - val_accuracy: 0.7344\n",
            "Epoch 2817/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5568 - val_accuracy: 0.7396\n",
            "Epoch 2818/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8125 - val_loss: 0.5582 - val_accuracy: 0.7396\n",
            "Epoch 2819/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5571 - val_accuracy: 0.7396\n",
            "Epoch 2820/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8160 - val_loss: 0.5567 - val_accuracy: 0.7396\n",
            "Epoch 2821/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8142 - val_loss: 0.5571 - val_accuracy: 0.7396\n",
            "Epoch 2822/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
            "Epoch 2823/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3961 - accuracy: 0.8142 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
            "Epoch 2824/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8160 - val_loss: 0.5571 - val_accuracy: 0.7396\n",
            "Epoch 2825/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8212 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
            "Epoch 2826/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.5572 - val_accuracy: 0.7396\n",
            "Epoch 2827/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5576 - val_accuracy: 0.7396\n",
            "Epoch 2828/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8194 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 2829/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8247 - val_loss: 0.5567 - val_accuracy: 0.7396\n",
            "Epoch 2830/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3951 - accuracy: 0.8108 - val_loss: 0.5578 - val_accuracy: 0.7396\n",
            "Epoch 2831/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8160 - val_loss: 0.5577 - val_accuracy: 0.7396\n",
            "Epoch 2832/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8194 - val_loss: 0.5572 - val_accuracy: 0.7396\n",
            "Epoch 2833/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8142 - val_loss: 0.5574 - val_accuracy: 0.7396\n",
            "Epoch 2834/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8142 - val_loss: 0.5576 - val_accuracy: 0.7396\n",
            "Epoch 2835/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8142 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
            "Epoch 2836/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.5579 - val_accuracy: 0.7396\n",
            "Epoch 2837/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5573 - val_accuracy: 0.7396\n",
            "Epoch 2838/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8160 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
            "Epoch 2839/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8212 - val_loss: 0.5575 - val_accuracy: 0.7396\n",
            "Epoch 2840/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8160 - val_loss: 0.5569 - val_accuracy: 0.7396\n",
            "Epoch 2841/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8142 - val_loss: 0.5580 - val_accuracy: 0.7344\n",
            "Epoch 2842/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8194 - val_loss: 0.5572 - val_accuracy: 0.7344\n",
            "Epoch 2843/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8160 - val_loss: 0.5572 - val_accuracy: 0.7344\n",
            "Epoch 2844/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
            "Epoch 2845/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8177 - val_loss: 0.5580 - val_accuracy: 0.7344\n",
            "Epoch 2846/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8142 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 2847/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8125 - val_loss: 0.5590 - val_accuracy: 0.7344\n",
            "Epoch 2848/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8160 - val_loss: 0.5580 - val_accuracy: 0.7344\n",
            "Epoch 2849/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8142 - val_loss: 0.5578 - val_accuracy: 0.7344\n",
            "Epoch 2850/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8160 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
            "Epoch 2851/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
            "Epoch 2852/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5575 - val_accuracy: 0.7344\n",
            "Epoch 2853/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8177 - val_loss: 0.5576 - val_accuracy: 0.7396\n",
            "Epoch 2854/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 2855/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8125 - val_loss: 0.5587 - val_accuracy: 0.7344\n",
            "Epoch 2856/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5576 - val_accuracy: 0.7344\n",
            "Epoch 2857/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
            "Epoch 2858/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8142 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
            "Epoch 2859/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8142 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
            "Epoch 2860/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8142 - val_loss: 0.5587 - val_accuracy: 0.7292\n",
            "Epoch 2861/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8264 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 2862/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8177 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
            "Epoch 2863/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.5580 - val_accuracy: 0.7344\n",
            "Epoch 2864/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8142 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
            "Epoch 2865/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8160 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
            "Epoch 2866/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
            "Epoch 2867/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8142 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
            "Epoch 2868/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8160 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 2869/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8194 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 2870/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8142 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
            "Epoch 2871/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8160 - val_loss: 0.5586 - val_accuracy: 0.7344\n",
            "Epoch 2872/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8160 - val_loss: 0.5581 - val_accuracy: 0.7344\n",
            "Epoch 2873/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
            "Epoch 2874/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8160 - val_loss: 0.5581 - val_accuracy: 0.7344\n",
            "Epoch 2875/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5576 - val_accuracy: 0.7344\n",
            "Epoch 2876/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8160 - val_loss: 0.5587 - val_accuracy: 0.7292\n",
            "Epoch 2877/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8194 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 2878/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8142 - val_loss: 0.5575 - val_accuracy: 0.7344\n",
            "Epoch 2879/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8125 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
            "Epoch 2880/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8160 - val_loss: 0.5580 - val_accuracy: 0.7292\n",
            "Epoch 2881/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8142 - val_loss: 0.5576 - val_accuracy: 0.7344\n",
            "Epoch 2882/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8125 - val_loss: 0.5581 - val_accuracy: 0.7344\n",
            "Epoch 2883/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8142 - val_loss: 0.5576 - val_accuracy: 0.7344\n",
            "Epoch 2884/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8177 - val_loss: 0.5568 - val_accuracy: 0.7344\n",
            "Epoch 2885/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8125 - val_loss: 0.5583 - val_accuracy: 0.7292\n",
            "Epoch 2886/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8177 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
            "Epoch 2887/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5570 - val_accuracy: 0.7344\n",
            "Epoch 2888/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8125 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 2889/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5581 - val_accuracy: 0.7344\n",
            "Epoch 2890/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8212 - val_loss: 0.5572 - val_accuracy: 0.7344\n",
            "Epoch 2891/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8125 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
            "Epoch 2892/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
            "Epoch 2893/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8142 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
            "Epoch 2894/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8229 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 2895/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 2896/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8177 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 2897/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8125 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 2898/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8108 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
            "Epoch 2899/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8142 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
            "Epoch 2900/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8108 - val_loss: 0.5580 - val_accuracy: 0.7344\n",
            "Epoch 2901/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8142 - val_loss: 0.5585 - val_accuracy: 0.7344\n",
            "Epoch 2902/3000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8160 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
            "Epoch 2903/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8142 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 2904/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
            "Epoch 2905/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8160 - val_loss: 0.5585 - val_accuracy: 0.7344\n",
            "Epoch 2906/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
            "Epoch 2907/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8177 - val_loss: 0.5596 - val_accuracy: 0.7292\n",
            "Epoch 2908/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8229 - val_loss: 0.5588 - val_accuracy: 0.7344\n",
            "Epoch 2909/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3960 - accuracy: 0.8160 - val_loss: 0.5591 - val_accuracy: 0.7292\n",
            "Epoch 2910/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5576 - val_accuracy: 0.7344\n",
            "Epoch 2911/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8142 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
            "Epoch 2912/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8142 - val_loss: 0.5581 - val_accuracy: 0.7344\n",
            "Epoch 2913/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8142 - val_loss: 0.5595 - val_accuracy: 0.7292\n",
            "Epoch 2914/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8194 - val_loss: 0.5595 - val_accuracy: 0.7344\n",
            "Epoch 2915/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5589 - val_accuracy: 0.7292\n",
            "Epoch 2916/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8142 - val_loss: 0.5586 - val_accuracy: 0.7344\n",
            "Epoch 2917/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8177 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
            "Epoch 2918/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
            "Epoch 2919/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8194 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 2920/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8229 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
            "Epoch 2921/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8194 - val_loss: 0.5588 - val_accuracy: 0.7344\n",
            "Epoch 2922/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8142 - val_loss: 0.5600 - val_accuracy: 0.7344\n",
            "Epoch 2923/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
            "Epoch 2924/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8142 - val_loss: 0.5596 - val_accuracy: 0.7292\n",
            "Epoch 2925/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8194 - val_loss: 0.5592 - val_accuracy: 0.7292\n",
            "Epoch 2926/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8142 - val_loss: 0.5592 - val_accuracy: 0.7344\n",
            "Epoch 2927/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8229 - val_loss: 0.5590 - val_accuracy: 0.7344\n",
            "Epoch 2928/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8160 - val_loss: 0.5590 - val_accuracy: 0.7344\n",
            "Epoch 2929/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5591 - val_accuracy: 0.7344\n",
            "Epoch 2930/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8177 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 2931/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8160 - val_loss: 0.5590 - val_accuracy: 0.7344\n",
            "Epoch 2932/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8177 - val_loss: 0.5591 - val_accuracy: 0.7344\n",
            "Epoch 2933/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8177 - val_loss: 0.5598 - val_accuracy: 0.7292\n",
            "Epoch 2934/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3950 - accuracy: 0.8160 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
            "Epoch 2935/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3951 - accuracy: 0.8177 - val_loss: 0.5607 - val_accuracy: 0.7344\n",
            "Epoch 2936/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8160 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
            "Epoch 2937/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8194 - val_loss: 0.5600 - val_accuracy: 0.7292\n",
            "Epoch 2938/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8177 - val_loss: 0.5604 - val_accuracy: 0.7292\n",
            "Epoch 2939/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3951 - accuracy: 0.8177 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
            "Epoch 2940/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5594 - val_accuracy: 0.7344\n",
            "Epoch 2941/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3951 - accuracy: 0.8229 - val_loss: 0.5591 - val_accuracy: 0.7344\n",
            "Epoch 2942/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8194 - val_loss: 0.5592 - val_accuracy: 0.7344\n",
            "Epoch 2943/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8177 - val_loss: 0.5594 - val_accuracy: 0.7344\n",
            "Epoch 2944/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5597 - val_accuracy: 0.7344\n",
            "Epoch 2945/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8194 - val_loss: 0.5585 - val_accuracy: 0.7344\n",
            "Epoch 2946/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3945 - accuracy: 0.8177 - val_loss: 0.5595 - val_accuracy: 0.7344\n",
            "Epoch 2947/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8229 - val_loss: 0.5585 - val_accuracy: 0.7344\n",
            "Epoch 2948/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8247 - val_loss: 0.5585 - val_accuracy: 0.7344\n",
            "Epoch 2949/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8177 - val_loss: 0.5587 - val_accuracy: 0.7344\n",
            "Epoch 2950/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8142 - val_loss: 0.5596 - val_accuracy: 0.7344\n",
            "Epoch 2951/3000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3948 - accuracy: 0.8142 - val_loss: 0.5604 - val_accuracy: 0.7292\n",
            "Epoch 2952/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5611 - val_accuracy: 0.7344\n",
            "Epoch 2953/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3950 - accuracy: 0.8229 - val_loss: 0.5604 - val_accuracy: 0.7292\n",
            "Epoch 2954/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3947 - accuracy: 0.8212 - val_loss: 0.5593 - val_accuracy: 0.7344\n",
            "Epoch 2955/3000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3955 - accuracy: 0.8160 - val_loss: 0.5598 - val_accuracy: 0.7292\n",
            "Epoch 2956/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8212 - val_loss: 0.5598 - val_accuracy: 0.7344\n",
            "Epoch 2957/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.8212 - val_loss: 0.5612 - val_accuracy: 0.7344\n",
            "Epoch 2958/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8229 - val_loss: 0.5599 - val_accuracy: 0.7344\n",
            "Epoch 2959/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8229 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
            "Epoch 2960/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8177 - val_loss: 0.5608 - val_accuracy: 0.7344\n",
            "Epoch 2961/3000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3954 - accuracy: 0.8160 - val_loss: 0.5593 - val_accuracy: 0.7344\n",
            "Epoch 2962/3000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3943 - accuracy: 0.8177 - val_loss: 0.5590 - val_accuracy: 0.7344\n",
            "Epoch 2963/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8160 - val_loss: 0.5599 - val_accuracy: 0.7344\n",
            "Epoch 2964/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8212 - val_loss: 0.5599 - val_accuracy: 0.7344\n",
            "Epoch 2965/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8264 - val_loss: 0.5587 - val_accuracy: 0.7344\n",
            "Epoch 2966/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8177 - val_loss: 0.5595 - val_accuracy: 0.7344\n",
            "Epoch 2967/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8177 - val_loss: 0.5598 - val_accuracy: 0.7344\n",
            "Epoch 2968/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8177 - val_loss: 0.5596 - val_accuracy: 0.7344\n",
            "Epoch 2969/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8160 - val_loss: 0.5601 - val_accuracy: 0.7292\n",
            "Epoch 2970/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5595 - val_accuracy: 0.7344\n",
            "Epoch 2971/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8177 - val_loss: 0.5606 - val_accuracy: 0.7292\n",
            "Epoch 2972/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8125 - val_loss: 0.5607 - val_accuracy: 0.7292\n",
            "Epoch 2973/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5606 - val_accuracy: 0.7292\n",
            "Epoch 2974/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8177 - val_loss: 0.5602 - val_accuracy: 0.7344\n",
            "Epoch 2975/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8229 - val_loss: 0.5598 - val_accuracy: 0.7344\n",
            "Epoch 2976/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8160 - val_loss: 0.5593 - val_accuracy: 0.7344\n",
            "Epoch 2977/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8177 - val_loss: 0.5597 - val_accuracy: 0.7344\n",
            "Epoch 2978/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8212 - val_loss: 0.5611 - val_accuracy: 0.7292\n",
            "Epoch 2979/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8212 - val_loss: 0.5611 - val_accuracy: 0.7292\n",
            "Epoch 2980/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8177 - val_loss: 0.5606 - val_accuracy: 0.7344\n",
            "Epoch 2981/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5597 - val_accuracy: 0.7344\n",
            "Epoch 2982/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8125 - val_loss: 0.5613 - val_accuracy: 0.7292\n",
            "Epoch 2983/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8194 - val_loss: 0.5609 - val_accuracy: 0.7292\n",
            "Epoch 2984/3000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8160 - val_loss: 0.5601 - val_accuracy: 0.7344\n",
            "Epoch 2985/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8177 - val_loss: 0.5604 - val_accuracy: 0.7344\n",
            "Epoch 2986/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8160 - val_loss: 0.5600 - val_accuracy: 0.7344\n",
            "Epoch 2987/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8194 - val_loss: 0.5606 - val_accuracy: 0.7344\n",
            "Epoch 2988/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8177 - val_loss: 0.5602 - val_accuracy: 0.7344\n",
            "Epoch 2989/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5607 - val_accuracy: 0.7292\n",
            "Epoch 2990/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8142 - val_loss: 0.5600 - val_accuracy: 0.7344\n",
            "Epoch 2991/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5602 - val_accuracy: 0.7344\n",
            "Epoch 2992/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8229 - val_loss: 0.5608 - val_accuracy: 0.7292\n",
            "Epoch 2993/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8212 - val_loss: 0.5605 - val_accuracy: 0.7292\n",
            "Epoch 2994/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8229 - val_loss: 0.5599 - val_accuracy: 0.7344\n",
            "Epoch 2995/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8160 - val_loss: 0.5610 - val_accuracy: 0.7292\n",
            "Epoch 2996/3000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5606 - val_accuracy: 0.7344\n",
            "Epoch 2997/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8177 - val_loss: 0.5608 - val_accuracy: 0.7292\n",
            "Epoch 2998/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8194 - val_loss: 0.5605 - val_accuracy: 0.7344\n",
            "Epoch 2999/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8177 - val_loss: 0.5606 - val_accuracy: 0.7344\n",
            "Epoch 3000/3000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8177 - val_loss: 0.5603 - val_accuracy: 0.7344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_3.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_3.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "082wzhKuBE1A",
        "outputId": "0a5fbfdc-50dd-450e-9ef3-e52a1c7aff34"
      },
      "id": "082wzhKuBE1A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79ad3aa88e50>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_3 = np.argmax(model2.predict(X_test_norm), axis=-1)\n",
        "y_pred_prob_nn_3 = model2.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRl4uUbLBJZ5",
        "outputId": "4192e5d4-a2f0-4ecc-bf8a-df770d60629d"
      },
      "id": "pRl4uUbLBJZ5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_3)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_3)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_3, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "nNxKprZJBUKT",
        "outputId": "d397c1bd-e5e3-4ef9-c341-9ad5706cc7fb"
      },
      "id": "nNxKprZJBUKT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.641\n",
            "roc-auc is 0.801\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "**Observation**:\n",
        "- Here in this model, I used 2 hidden layers which is made up of 5 and 3 hidden layer nodes respectively. I used the rule of thumb where the hidden layer node should be 2/3 of the input layer node [1]. And that their value should be between the value of input layer node and output layer node. I still used the \"relu\" activation function here but I changed the learning rate to 0.01, the epochs to 3000 and the batch size to 32.\n",
        "\n",
        "- The final training accuracy of this model is 0.8177 with the training loss of 0.3946. The final validation accuracy is 0.7344 with validation loss of 0.5603. This indicates overfitting since there is a large gap between the training accuracy and the validation accuracy.\n",
        "\n",
        "- We can observe in the graph that our validation loss stopped decreasing  around 300th-500th epoch and instead started increasing until the last epoch.\n",
        "\n",
        "- For our ROC curve, we can see that it is still not that smooth and haven't reached the top left corner, and the value even decreased to 0.801. This means that our model is less optimized in balancing the true positive and true negative values. The accuracy stays the same because the validation dataset and test dataset is the same.\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "9GSlJZoeG-ug"
      },
      "id": "9GSlJZoeG-ug"
    },
    {
      "cell_type": "code",
      "source": [
        "model3  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(12, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model3.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_4 = model3.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIzdopg1HBC4",
        "outputId": "4f98010b-de80-4c07-e556-c35120431eb6"
      },
      "id": "FIzdopg1HBC4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 1s 23ms/step - loss: 0.6877 - accuracy: 0.6076 - val_loss: 0.6484 - val_accuracy: 0.6302\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.6354 - val_loss: 0.6378 - val_accuracy: 0.6510\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6580 - val_loss: 0.6284 - val_accuracy: 0.6875\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6736 - val_loss: 0.6200 - val_accuracy: 0.6979\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6858 - val_loss: 0.6124 - val_accuracy: 0.7031\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.6944 - val_loss: 0.6053 - val_accuracy: 0.7240\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.6979 - val_loss: 0.5988 - val_accuracy: 0.7344\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.7014 - val_loss: 0.5927 - val_accuracy: 0.7448\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.7014 - val_loss: 0.5870 - val_accuracy: 0.7448\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6045 - accuracy: 0.7049 - val_loss: 0.5817 - val_accuracy: 0.7552\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.7083 - val_loss: 0.5766 - val_accuracy: 0.7500\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.7101 - val_loss: 0.5718 - val_accuracy: 0.7552\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5881 - accuracy: 0.7153 - val_loss: 0.5674 - val_accuracy: 0.7604\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.7153 - val_loss: 0.5632 - val_accuracy: 0.7604\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.7222 - val_loss: 0.5592 - val_accuracy: 0.7552\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7274 - val_loss: 0.5555 - val_accuracy: 0.7604\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.7292 - val_loss: 0.5520 - val_accuracy: 0.7604\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7309 - val_loss: 0.5486 - val_accuracy: 0.7604\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7361 - val_loss: 0.5454 - val_accuracy: 0.7604\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.7361 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7378 - val_loss: 0.5395 - val_accuracy: 0.7604\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7361 - val_loss: 0.5369 - val_accuracy: 0.7604\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.7378 - val_loss: 0.5344 - val_accuracy: 0.7604\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7396 - val_loss: 0.5319 - val_accuracy: 0.7656\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7431 - val_loss: 0.5296 - val_accuracy: 0.7656\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5386 - accuracy: 0.7483 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5359 - accuracy: 0.7448 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7483 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7500 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7483 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7552 - val_loss: 0.5166 - val_accuracy: 0.7604\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7535 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7587 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5163 - accuracy: 0.7552 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7622 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7622 - val_loss: 0.5099 - val_accuracy: 0.7760\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7604 - val_loss: 0.5088 - val_accuracy: 0.7760\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7622 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.7656 - val_loss: 0.5064 - val_accuracy: 0.7760\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7639 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7656 - val_loss: 0.5042 - val_accuracy: 0.7760\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7639 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7674 - val_loss: 0.5014 - val_accuracy: 0.7760\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7691 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7691 - val_loss: 0.4998 - val_accuracy: 0.7760\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7726 - val_loss: 0.4990 - val_accuracy: 0.7760\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7708 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7743 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7726 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7726 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7760 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7760 - val_loss: 0.4951 - val_accuracy: 0.7812\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7795 - val_loss: 0.4946 - val_accuracy: 0.7812\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7795 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7778 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7795 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7795 - val_loss: 0.4930 - val_accuracy: 0.7812\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7760\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4727 - accuracy: 0.7830 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4715 - accuracy: 0.7830 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4706 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7830 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7830 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7847 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.7847 - val_loss: 0.4899 - val_accuracy: 0.7552\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4630 - accuracy: 0.7865 - val_loss: 0.4897 - val_accuracy: 0.7604\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4604 - accuracy: 0.7917 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4596 - accuracy: 0.7882 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.7882 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4581 - accuracy: 0.7882 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4574 - accuracy: 0.7882 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4567 - accuracy: 0.7882 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4563 - accuracy: 0.7899 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4555 - accuracy: 0.7899 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4548 - accuracy: 0.7899 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4540 - accuracy: 0.7899 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4535 - accuracy: 0.7899 - val_loss: 0.4893 - val_accuracy: 0.7812\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4529 - accuracy: 0.7865 - val_loss: 0.4894 - val_accuracy: 0.7812\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4516 - accuracy: 0.7865 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4510 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.7899 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.7899 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7917 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7899 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.7899 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4431 - accuracy: 0.7934 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4425 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4422 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7917 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4397 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4394 - accuracy: 0.7969 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7917 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4378 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4366 - accuracy: 0.7986 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7656\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.8003 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4334 - accuracy: 0.8021 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.8021 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.8003 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.8003 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8021 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8003 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8021 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8003 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.8021 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.8021 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8003 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.8038 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8021 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7986 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4243 - accuracy: 0.8021 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4242 - accuracy: 0.8038 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4238 - accuracy: 0.8038 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4239 - accuracy: 0.8003 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8038 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.8021 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4231 - accuracy: 0.8021 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8003 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.8003 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4227 - accuracy: 0.8003 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.8021 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8003 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8021 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4217 - accuracy: 0.8021 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8021 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8021 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8021 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7986 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.4991 - val_accuracy: 0.7604\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8003 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.4994 - val_accuracy: 0.7604\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7986 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7986 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7951 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7951 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8003 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8003 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8003 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8003 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8003 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8003 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.7969 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8003 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8003 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8021 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8038 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8021 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8056 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4113 - accuracy: 0.8021 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8021 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8021 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8056 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4100 - accuracy: 0.8003 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4097 - accuracy: 0.8021 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8021 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8021 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.8038 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8038 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.8056 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4083 - accuracy: 0.8056 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8038 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.8056 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4074 - accuracy: 0.8056 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4075 - accuracy: 0.8073 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8056 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4067 - accuracy: 0.8021 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4064 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8090 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8056 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4058 - accuracy: 0.8056 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4058 - accuracy: 0.8090 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4056 - accuracy: 0.8073 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8090 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4052 - accuracy: 0.8090 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4051 - accuracy: 0.8056 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8073 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8090 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8073 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8090 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8125 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.8073 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8056 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8090 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8125 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8108 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8142 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8142 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8125 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8125 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8090 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8142 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8125 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8142 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8177 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8125 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8142 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8142 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4017 - accuracy: 0.8108 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8125 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8142 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4010 - accuracy: 0.8142 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4012 - accuracy: 0.8160 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8142 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8160 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8142 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8142 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8160 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8142 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8160 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4000 - accuracy: 0.8125 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8142 - val_loss: 0.5061 - val_accuracy: 0.7552\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8142 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8142 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3992 - accuracy: 0.8142 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8125 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8108 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8125 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8142 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8142 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8142 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8142 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3986 - accuracy: 0.8142 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.8108 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8160 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8142 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8142 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8125 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8160 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3979 - accuracy: 0.8142 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8142 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3977 - accuracy: 0.8142 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3972 - accuracy: 0.8125 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8108 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8125 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3967 - accuracy: 0.8108 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8108 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8125 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8160 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3964 - accuracy: 0.8108 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3960 - accuracy: 0.8142 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8125 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3961 - accuracy: 0.8160 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8125 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3954 - accuracy: 0.8142 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8160 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3956 - accuracy: 0.8160 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3953 - accuracy: 0.8160 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8125 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8177 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3950 - accuracy: 0.8160 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3948 - accuracy: 0.8160 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.3948 - accuracy: 0.8160 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.3945 - accuracy: 0.8160 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3945 - accuracy: 0.8160 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8160 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8177 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8194 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8125 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8160 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8160 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8177 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8177 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8177 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8160 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3931 - accuracy: 0.8194 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8177 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8160 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8160 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8194 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8160 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8160 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8194 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3923 - accuracy: 0.8194 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8160 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8160 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8212 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3926 - accuracy: 0.8177 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8160 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8177 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8177 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8177 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8194 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3916 - accuracy: 0.8177 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3919 - accuracy: 0.8160 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8160 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8160 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3912 - accuracy: 0.8177 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3916 - accuracy: 0.8177 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3910 - accuracy: 0.8177 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3911 - accuracy: 0.8160 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3916 - accuracy: 0.8177 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8194 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3909 - accuracy: 0.8160 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3905 - accuracy: 0.8177 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3908 - accuracy: 0.8160 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8177 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8177 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3906 - accuracy: 0.8177 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8160 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8194 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3898 - accuracy: 0.8177 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8177 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.8177 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3900 - accuracy: 0.8177 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8194 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8177 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3896 - accuracy: 0.8160 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3890 - accuracy: 0.8160 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3892 - accuracy: 0.8160 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3890 - accuracy: 0.8194 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8177 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8194 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3891 - accuracy: 0.8177 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3886 - accuracy: 0.8177 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8177 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8177 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8177 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8229 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8194 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8177 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8194 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8177 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8177 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8194 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8160 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3876 - accuracy: 0.8177 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.8177 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3874 - accuracy: 0.8194 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3870 - accuracy: 0.8194 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.8194 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.8160 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3868 - accuracy: 0.8194 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8194 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3869 - accuracy: 0.8177 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3868 - accuracy: 0.8212 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8212 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.8177 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3868 - accuracy: 0.8194 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3864 - accuracy: 0.8194 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3864 - accuracy: 0.8212 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.8194 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3859 - accuracy: 0.8212 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3860 - accuracy: 0.8212 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3862 - accuracy: 0.8212 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3858 - accuracy: 0.8212 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3856 - accuracy: 0.8247 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8212 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3859 - accuracy: 0.8229 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8212 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.8194 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8212 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8229 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8229 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8229 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.8229 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8229 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8247 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8229 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3848 - accuracy: 0.8229 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8229 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8229 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8229 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3841 - accuracy: 0.8247 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3841 - accuracy: 0.8247 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8247 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8194 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.8229 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.8229 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8194 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8212 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8247 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3833 - accuracy: 0.8212 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8229 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8247 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3834 - accuracy: 0.8212 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8212 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8229 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8247 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.8212 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3828 - accuracy: 0.8229 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8247 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8247 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3823 - accuracy: 0.8229 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8229 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3824 - accuracy: 0.8247 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8247 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8247 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3818 - accuracy: 0.8247 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8247 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8247 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8247 - val_loss: 0.5173 - val_accuracy: 0.7656\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8247 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8247 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.8247 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3817 - accuracy: 0.8229 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3817 - accuracy: 0.8264 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3808 - accuracy: 0.8281 - val_loss: 0.5163 - val_accuracy: 0.7604\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.3807 - accuracy: 0.8247 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3808 - accuracy: 0.8281 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8264 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.8247 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.8247 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8281 - val_loss: 0.5188 - val_accuracy: 0.7656\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8247 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8264 - val_loss: 0.5174 - val_accuracy: 0.7552\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8264 - val_loss: 0.5186 - val_accuracy: 0.7604\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8264 - val_loss: 0.5185 - val_accuracy: 0.7604\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3801 - accuracy: 0.8299 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8247 - val_loss: 0.5170 - val_accuracy: 0.7552\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8264 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8281 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3795 - accuracy: 0.8281 - val_loss: 0.5192 - val_accuracy: 0.7604\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3794 - accuracy: 0.8247 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8281 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8281 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3792 - accuracy: 0.8281 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.8264 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8281 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8281 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3788 - accuracy: 0.8281 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8281 - val_loss: 0.5204 - val_accuracy: 0.7656\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8281 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8281 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8299 - val_loss: 0.5192 - val_accuracy: 0.7604\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3785 - accuracy: 0.8299 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8299 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8281 - val_loss: 0.5189 - val_accuracy: 0.7552\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8299 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.8299 - val_loss: 0.5212 - val_accuracy: 0.7656\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8299 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3778 - accuracy: 0.8299 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3775 - accuracy: 0.8281 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3780 - accuracy: 0.8299 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3778 - accuracy: 0.8299 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3776 - accuracy: 0.8299 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3778 - accuracy: 0.8299 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.8299 - val_loss: 0.5204 - val_accuracy: 0.7656\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3771 - accuracy: 0.8299 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3771 - accuracy: 0.8299 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.8281 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3769 - accuracy: 0.8299 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3771 - accuracy: 0.8299 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8299 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3772 - accuracy: 0.8333 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3766 - accuracy: 0.8299 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3768 - accuracy: 0.8299 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3762 - accuracy: 0.8351 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.8316 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3764 - accuracy: 0.8299 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3763 - accuracy: 0.8333 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.8316 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.8316 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3761 - accuracy: 0.8333 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8333 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8351 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8333 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3761 - accuracy: 0.8351 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3756 - accuracy: 0.8333 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3757 - accuracy: 0.8333 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3756 - accuracy: 0.8368 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3755 - accuracy: 0.8299 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8351 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3753 - accuracy: 0.8333 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3750 - accuracy: 0.8351 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.8333 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3750 - accuracy: 0.8333 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3748 - accuracy: 0.8351 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3754 - accuracy: 0.8333 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3751 - accuracy: 0.8333 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3749 - accuracy: 0.8333 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3747 - accuracy: 0.8351 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3746 - accuracy: 0.8333 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3746 - accuracy: 0.8351 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3742 - accuracy: 0.8351 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3744 - accuracy: 0.8333 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3743 - accuracy: 0.8351 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3742 - accuracy: 0.8368 - val_loss: 0.5221 - val_accuracy: 0.7708\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8333 - val_loss: 0.5247 - val_accuracy: 0.7708\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3740 - accuracy: 0.8351 - val_loss: 0.5238 - val_accuracy: 0.7708\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3740 - accuracy: 0.8351 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3738 - accuracy: 0.8368 - val_loss: 0.5226 - val_accuracy: 0.7708\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.8368 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8333 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8333 - val_loss: 0.5242 - val_accuracy: 0.7708\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.8368 - val_loss: 0.5232 - val_accuracy: 0.7708\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8385 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8333 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8351 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8368 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8385 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8368 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8368 - val_loss: 0.5240 - val_accuracy: 0.7708\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8351 - val_loss: 0.5251 - val_accuracy: 0.7760\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3729 - accuracy: 0.8368 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.8385 - val_loss: 0.5219 - val_accuracy: 0.7708\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8351 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8368 - val_loss: 0.5244 - val_accuracy: 0.7708\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3726 - accuracy: 0.8333 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8368 - val_loss: 0.5256 - val_accuracy: 0.7708\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8385 - val_loss: 0.5240 - val_accuracy: 0.7708\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3720 - accuracy: 0.8368 - val_loss: 0.5243 - val_accuracy: 0.7708\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8385 - val_loss: 0.5258 - val_accuracy: 0.7708\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3720 - accuracy: 0.8351 - val_loss: 0.5251 - val_accuracy: 0.7760\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8368 - val_loss: 0.5243 - val_accuracy: 0.7708\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8368 - val_loss: 0.5258 - val_accuracy: 0.7708\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3718 - accuracy: 0.8385 - val_loss: 0.5241 - val_accuracy: 0.7760\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8368 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8403 - val_loss: 0.5234 - val_accuracy: 0.7760\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8351 - val_loss: 0.5248 - val_accuracy: 0.7708\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3715 - accuracy: 0.8368 - val_loss: 0.5235 - val_accuracy: 0.7760\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3715 - accuracy: 0.8403 - val_loss: 0.5248 - val_accuracy: 0.7708\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3716 - accuracy: 0.8403 - val_loss: 0.5251 - val_accuracy: 0.7708\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3715 - accuracy: 0.8403 - val_loss: 0.5242 - val_accuracy: 0.7708\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3712 - accuracy: 0.8385 - val_loss: 0.5256 - val_accuracy: 0.7708\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3715 - accuracy: 0.8368 - val_loss: 0.5249 - val_accuracy: 0.7708\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3717 - accuracy: 0.8351 - val_loss: 0.5244 - val_accuracy: 0.7708\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8368 - val_loss: 0.5255 - val_accuracy: 0.7708\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3710 - accuracy: 0.8368 - val_loss: 0.5248 - val_accuracy: 0.7708\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8385 - val_loss: 0.5237 - val_accuracy: 0.7708\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8385 - val_loss: 0.5256 - val_accuracy: 0.7708\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3703 - accuracy: 0.8368 - val_loss: 0.5281 - val_accuracy: 0.7760\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3707 - accuracy: 0.8368 - val_loss: 0.5277 - val_accuracy: 0.7708\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8420 - val_loss: 0.5259 - val_accuracy: 0.7708\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8403 - val_loss: 0.5264 - val_accuracy: 0.7708\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8385 - val_loss: 0.5251 - val_accuracy: 0.7708\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3704 - accuracy: 0.8403 - val_loss: 0.5249 - val_accuracy: 0.7708\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8385 - val_loss: 0.5247 - val_accuracy: 0.7708\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8368 - val_loss: 0.5255 - val_accuracy: 0.7708\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8368 - val_loss: 0.5267 - val_accuracy: 0.7760\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8420 - val_loss: 0.5259 - val_accuracy: 0.7708\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8385 - val_loss: 0.5265 - val_accuracy: 0.7708\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8403 - val_loss: 0.5256 - val_accuracy: 0.7708\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3694 - accuracy: 0.8403 - val_loss: 0.5276 - val_accuracy: 0.7708\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8420 - val_loss: 0.5282 - val_accuracy: 0.7760\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3694 - accuracy: 0.8368 - val_loss: 0.5270 - val_accuracy: 0.7708\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3694 - accuracy: 0.8403 - val_loss: 0.5263 - val_accuracy: 0.7708\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3694 - accuracy: 0.8420 - val_loss: 0.5258 - val_accuracy: 0.7708\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3694 - accuracy: 0.8420 - val_loss: 0.5278 - val_accuracy: 0.7708\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8368 - val_loss: 0.5276 - val_accuracy: 0.7708\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3688 - accuracy: 0.8403 - val_loss: 0.5259 - val_accuracy: 0.7708\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3689 - accuracy: 0.8403 - val_loss: 0.5260 - val_accuracy: 0.7708\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8420 - val_loss: 0.5266 - val_accuracy: 0.7708\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3689 - accuracy: 0.8385 - val_loss: 0.5252 - val_accuracy: 0.7708\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3689 - accuracy: 0.8403 - val_loss: 0.5259 - val_accuracy: 0.7708\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3686 - accuracy: 0.8403 - val_loss: 0.5276 - val_accuracy: 0.7708\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3684 - accuracy: 0.8438 - val_loss: 0.5276 - val_accuracy: 0.7708\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3681 - accuracy: 0.8385 - val_loss: 0.5294 - val_accuracy: 0.7708\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3689 - accuracy: 0.8385 - val_loss: 0.5298 - val_accuracy: 0.7708\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3681 - accuracy: 0.8403 - val_loss: 0.5261 - val_accuracy: 0.7708\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3681 - accuracy: 0.8420 - val_loss: 0.5268 - val_accuracy: 0.7708\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3681 - accuracy: 0.8403 - val_loss: 0.5285 - val_accuracy: 0.7708\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3683 - accuracy: 0.8403 - val_loss: 0.5280 - val_accuracy: 0.7708\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3679 - accuracy: 0.8403 - val_loss: 0.5269 - val_accuracy: 0.7708\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8438 - val_loss: 0.5273 - val_accuracy: 0.7708\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3680 - accuracy: 0.8438 - val_loss: 0.5293 - val_accuracy: 0.7708\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3677 - accuracy: 0.8438 - val_loss: 0.5286 - val_accuracy: 0.7708\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3677 - accuracy: 0.8385 - val_loss: 0.5284 - val_accuracy: 0.7708\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3674 - accuracy: 0.8420 - val_loss: 0.5281 - val_accuracy: 0.7708\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3675 - accuracy: 0.8403 - val_loss: 0.5296 - val_accuracy: 0.7708\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3675 - accuracy: 0.8385 - val_loss: 0.5276 - val_accuracy: 0.7708\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3672 - accuracy: 0.8420 - val_loss: 0.5301 - val_accuracy: 0.7760\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3672 - accuracy: 0.8438 - val_loss: 0.5295 - val_accuracy: 0.7708\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3671 - accuracy: 0.8385 - val_loss: 0.5277 - val_accuracy: 0.7708\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3669 - accuracy: 0.8420 - val_loss: 0.5279 - val_accuracy: 0.7708\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3671 - accuracy: 0.8438 - val_loss: 0.5277 - val_accuracy: 0.7708\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3673 - accuracy: 0.8438 - val_loss: 0.5307 - val_accuracy: 0.7708\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3669 - accuracy: 0.8385 - val_loss: 0.5302 - val_accuracy: 0.7760\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3672 - accuracy: 0.8403 - val_loss: 0.5313 - val_accuracy: 0.7760\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3669 - accuracy: 0.8403 - val_loss: 0.5288 - val_accuracy: 0.7760\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8438 - val_loss: 0.5291 - val_accuracy: 0.7708\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8403 - val_loss: 0.5279 - val_accuracy: 0.7708\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8403 - val_loss: 0.5299 - val_accuracy: 0.7760\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8438 - val_loss: 0.5298 - val_accuracy: 0.7708\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8403 - val_loss: 0.5306 - val_accuracy: 0.7708\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8420 - val_loss: 0.5320 - val_accuracy: 0.7708\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8420 - val_loss: 0.5297 - val_accuracy: 0.7708\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8438 - val_loss: 0.5316 - val_accuracy: 0.7760\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8420 - val_loss: 0.5305 - val_accuracy: 0.7760\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8385 - val_loss: 0.5293 - val_accuracy: 0.7708\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8420 - val_loss: 0.5314 - val_accuracy: 0.7708\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8403 - val_loss: 0.5315 - val_accuracy: 0.7708\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8403 - val_loss: 0.5282 - val_accuracy: 0.7708\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8420 - val_loss: 0.5277 - val_accuracy: 0.7760\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8420 - val_loss: 0.5298 - val_accuracy: 0.7760\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8438 - val_loss: 0.5305 - val_accuracy: 0.7760\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8438 - val_loss: 0.5294 - val_accuracy: 0.7708\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8438 - val_loss: 0.5287 - val_accuracy: 0.7708\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8420 - val_loss: 0.5288 - val_accuracy: 0.7708\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8420 - val_loss: 0.5304 - val_accuracy: 0.7656\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8438 - val_loss: 0.5317 - val_accuracy: 0.7708\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8420 - val_loss: 0.5313 - val_accuracy: 0.7656\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8438 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8420 - val_loss: 0.5292 - val_accuracy: 0.7656\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8403 - val_loss: 0.5297 - val_accuracy: 0.7656\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3645 - accuracy: 0.8385 - val_loss: 0.5311 - val_accuracy: 0.7656\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3645 - accuracy: 0.8438 - val_loss: 0.5301 - val_accuracy: 0.7656\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8403 - val_loss: 0.5325 - val_accuracy: 0.7760\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8403 - val_loss: 0.5315 - val_accuracy: 0.7760\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.8455 - val_loss: 0.5307 - val_accuracy: 0.7708\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8420 - val_loss: 0.5319 - val_accuracy: 0.7760\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8438 - val_loss: 0.5329 - val_accuracy: 0.7760\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3645 - accuracy: 0.8385 - val_loss: 0.5317 - val_accuracy: 0.7708\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8438 - val_loss: 0.5317 - val_accuracy: 0.7760\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8420 - val_loss: 0.5319 - val_accuracy: 0.7708\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8420 - val_loss: 0.5332 - val_accuracy: 0.7760\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3634 - accuracy: 0.8438 - val_loss: 0.5299 - val_accuracy: 0.7708\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8385 - val_loss: 0.5306 - val_accuracy: 0.7760\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8438 - val_loss: 0.5305 - val_accuracy: 0.7760\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3634 - accuracy: 0.8420 - val_loss: 0.5326 - val_accuracy: 0.7760\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8403 - val_loss: 0.5336 - val_accuracy: 0.7760\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3632 - accuracy: 0.8403 - val_loss: 0.5310 - val_accuracy: 0.7760\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3631 - accuracy: 0.8403 - val_loss: 0.5310 - val_accuracy: 0.7760\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.8403 - val_loss: 0.5312 - val_accuracy: 0.7812\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3630 - accuracy: 0.8420 - val_loss: 0.5317 - val_accuracy: 0.7812\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3626 - accuracy: 0.8403 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.8420 - val_loss: 0.5322 - val_accuracy: 0.7760\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3630 - accuracy: 0.8438 - val_loss: 0.5346 - val_accuracy: 0.7708\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.8472 - val_loss: 0.5334 - val_accuracy: 0.7760\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8420 - val_loss: 0.5334 - val_accuracy: 0.7812\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3622 - accuracy: 0.8420 - val_loss: 0.5360 - val_accuracy: 0.7708\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8420 - val_loss: 0.5326 - val_accuracy: 0.7760\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3623 - accuracy: 0.8420 - val_loss: 0.5342 - val_accuracy: 0.7812\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8438 - val_loss: 0.5342 - val_accuracy: 0.7760\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.8420 - val_loss: 0.5333 - val_accuracy: 0.7760\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3619 - accuracy: 0.8403 - val_loss: 0.5316 - val_accuracy: 0.7760\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3619 - accuracy: 0.8403 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3619 - accuracy: 0.8403 - val_loss: 0.5346 - val_accuracy: 0.7812\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8420 - val_loss: 0.5337 - val_accuracy: 0.7812\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8403 - val_loss: 0.5361 - val_accuracy: 0.7760\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8438 - val_loss: 0.5329 - val_accuracy: 0.7812\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3616 - accuracy: 0.8438 - val_loss: 0.5341 - val_accuracy: 0.7812\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8420 - val_loss: 0.5338 - val_accuracy: 0.7812\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8385 - val_loss: 0.5346 - val_accuracy: 0.7865\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3612 - accuracy: 0.8403 - val_loss: 0.5330 - val_accuracy: 0.7812\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3609 - accuracy: 0.8455 - val_loss: 0.5336 - val_accuracy: 0.7812\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.8420 - val_loss: 0.5348 - val_accuracy: 0.7812\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3612 - accuracy: 0.8438 - val_loss: 0.5370 - val_accuracy: 0.7760\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3607 - accuracy: 0.8420 - val_loss: 0.5363 - val_accuracy: 0.7812\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3609 - accuracy: 0.8420 - val_loss: 0.5372 - val_accuracy: 0.7760\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3613 - accuracy: 0.8438 - val_loss: 0.5370 - val_accuracy: 0.7760\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3607 - accuracy: 0.8438 - val_loss: 0.5339 - val_accuracy: 0.7812\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3603 - accuracy: 0.8403 - val_loss: 0.5342 - val_accuracy: 0.7812\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3605 - accuracy: 0.8438 - val_loss: 0.5345 - val_accuracy: 0.7760\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3604 - accuracy: 0.8385 - val_loss: 0.5335 - val_accuracy: 0.7760\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3600 - accuracy: 0.8472 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3601 - accuracy: 0.8385 - val_loss: 0.5335 - val_accuracy: 0.7760\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3603 - accuracy: 0.8455 - val_loss: 0.5368 - val_accuracy: 0.7760\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8438 - val_loss: 0.5354 - val_accuracy: 0.7812\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3602 - accuracy: 0.8438 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3596 - accuracy: 0.8438 - val_loss: 0.5354 - val_accuracy: 0.7760\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.8403 - val_loss: 0.5339 - val_accuracy: 0.7760\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3595 - accuracy: 0.8403 - val_loss: 0.5342 - val_accuracy: 0.7812\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3598 - accuracy: 0.8455 - val_loss: 0.5358 - val_accuracy: 0.7760\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3596 - accuracy: 0.8438 - val_loss: 0.5349 - val_accuracy: 0.7760\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3595 - accuracy: 0.8438 - val_loss: 0.5342 - val_accuracy: 0.7812\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3595 - accuracy: 0.8420 - val_loss: 0.5359 - val_accuracy: 0.7812\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3590 - accuracy: 0.8455 - val_loss: 0.5358 - val_accuracy: 0.7812\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3589 - accuracy: 0.8420 - val_loss: 0.5335 - val_accuracy: 0.7760\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3592 - accuracy: 0.8420 - val_loss: 0.5352 - val_accuracy: 0.7760\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3588 - accuracy: 0.8455 - val_loss: 0.5353 - val_accuracy: 0.7812\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3588 - accuracy: 0.8455 - val_loss: 0.5339 - val_accuracy: 0.7812\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3586 - accuracy: 0.8438 - val_loss: 0.5349 - val_accuracy: 0.7812\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3587 - accuracy: 0.8455 - val_loss: 0.5360 - val_accuracy: 0.7760\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3586 - accuracy: 0.8420 - val_loss: 0.5346 - val_accuracy: 0.7812\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3585 - accuracy: 0.8420 - val_loss: 0.5340 - val_accuracy: 0.7760\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3583 - accuracy: 0.8420 - val_loss: 0.5355 - val_accuracy: 0.7812\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8472 - val_loss: 0.5347 - val_accuracy: 0.7760\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3583 - accuracy: 0.8472 - val_loss: 0.5347 - val_accuracy: 0.7760\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3579 - accuracy: 0.8455 - val_loss: 0.5354 - val_accuracy: 0.7812\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8472 - val_loss: 0.5347 - val_accuracy: 0.7812\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3576 - accuracy: 0.8455 - val_loss: 0.5361 - val_accuracy: 0.7760\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3579 - accuracy: 0.8385 - val_loss: 0.5363 - val_accuracy: 0.7760\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3575 - accuracy: 0.8438 - val_loss: 0.5354 - val_accuracy: 0.7865\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8420 - val_loss: 0.5355 - val_accuracy: 0.7865\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8472 - val_loss: 0.5363 - val_accuracy: 0.7812\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3572 - accuracy: 0.8438 - val_loss: 0.5354 - val_accuracy: 0.7865\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3572 - accuracy: 0.8438 - val_loss: 0.5367 - val_accuracy: 0.7812\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8420 - val_loss: 0.5340 - val_accuracy: 0.7760\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8438 - val_loss: 0.5337 - val_accuracy: 0.7760\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3571 - accuracy: 0.8472 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3568 - accuracy: 0.8403 - val_loss: 0.5374 - val_accuracy: 0.7760\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3576 - accuracy: 0.8420 - val_loss: 0.5374 - val_accuracy: 0.7812\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8438 - val_loss: 0.5345 - val_accuracy: 0.7708\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3571 - accuracy: 0.8385 - val_loss: 0.5360 - val_accuracy: 0.7812\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3567 - accuracy: 0.8490 - val_loss: 0.5362 - val_accuracy: 0.7708\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.8438 - val_loss: 0.5359 - val_accuracy: 0.7708\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8438 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3560 - accuracy: 0.8490 - val_loss: 0.5340 - val_accuracy: 0.7656\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8472 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8472 - val_loss: 0.5349 - val_accuracy: 0.7760\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8472 - val_loss: 0.5352 - val_accuracy: 0.7708\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8438 - val_loss: 0.5350 - val_accuracy: 0.7708\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3558 - accuracy: 0.8490 - val_loss: 0.5358 - val_accuracy: 0.7760\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8490 - val_loss: 0.5393 - val_accuracy: 0.7760\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8490 - val_loss: 0.5395 - val_accuracy: 0.7812\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8472 - val_loss: 0.5385 - val_accuracy: 0.7812\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8507 - val_loss: 0.5359 - val_accuracy: 0.7865\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8420 - val_loss: 0.5381 - val_accuracy: 0.7760\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8438 - val_loss: 0.5379 - val_accuracy: 0.7760\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8472 - val_loss: 0.5375 - val_accuracy: 0.7760\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8455 - val_loss: 0.5382 - val_accuracy: 0.7760\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8438 - val_loss: 0.5408 - val_accuracy: 0.7812\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.8490 - val_loss: 0.5397 - val_accuracy: 0.7812\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3551 - accuracy: 0.8490 - val_loss: 0.5373 - val_accuracy: 0.7760\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8542 - val_loss: 0.5372 - val_accuracy: 0.7708\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8524 - val_loss: 0.5368 - val_accuracy: 0.7760\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8472 - val_loss: 0.5363 - val_accuracy: 0.7760\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8438 - val_loss: 0.5371 - val_accuracy: 0.7812\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3541 - accuracy: 0.8490 - val_loss: 0.5383 - val_accuracy: 0.7656\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8472 - val_loss: 0.5364 - val_accuracy: 0.7760\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8542 - val_loss: 0.5360 - val_accuracy: 0.7760\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.8524 - val_loss: 0.5363 - val_accuracy: 0.7760\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3539 - accuracy: 0.8472 - val_loss: 0.5376 - val_accuracy: 0.7760\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8507 - val_loss: 0.5397 - val_accuracy: 0.7760\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8542 - val_loss: 0.5409 - val_accuracy: 0.7760\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3532 - accuracy: 0.8524 - val_loss: 0.5364 - val_accuracy: 0.7708\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8490 - val_loss: 0.5382 - val_accuracy: 0.7760\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8507 - val_loss: 0.5389 - val_accuracy: 0.7760\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3534 - accuracy: 0.8490 - val_loss: 0.5376 - val_accuracy: 0.7760\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3528 - accuracy: 0.8594 - val_loss: 0.5377 - val_accuracy: 0.7760\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8472 - val_loss: 0.5389 - val_accuracy: 0.7760\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8507 - val_loss: 0.5362 - val_accuracy: 0.7656\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3528 - accuracy: 0.8542 - val_loss: 0.5361 - val_accuracy: 0.7708\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3530 - accuracy: 0.8524 - val_loss: 0.5363 - val_accuracy: 0.7708\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3529 - accuracy: 0.8490 - val_loss: 0.5367 - val_accuracy: 0.7708\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8542 - val_loss: 0.5359 - val_accuracy: 0.7708\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8455 - val_loss: 0.5386 - val_accuracy: 0.7708\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8490 - val_loss: 0.5381 - val_accuracy: 0.7708\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8524 - val_loss: 0.5365 - val_accuracy: 0.7760\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8559 - val_loss: 0.5410 - val_accuracy: 0.7760\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.8542 - val_loss: 0.5397 - val_accuracy: 0.7760\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8507 - val_loss: 0.5375 - val_accuracy: 0.7760\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8542 - val_loss: 0.5389 - val_accuracy: 0.7708\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8559 - val_loss: 0.5370 - val_accuracy: 0.7708\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8594 - val_loss: 0.5397 - val_accuracy: 0.7708\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8507 - val_loss: 0.5384 - val_accuracy: 0.7708\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8559 - val_loss: 0.5409 - val_accuracy: 0.7760\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8576 - val_loss: 0.5387 - val_accuracy: 0.7708\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3518 - accuracy: 0.8542 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8524 - val_loss: 0.5383 - val_accuracy: 0.7708\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8542 - val_loss: 0.5388 - val_accuracy: 0.7760\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3518 - accuracy: 0.8490 - val_loss: 0.5407 - val_accuracy: 0.7760\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8559 - val_loss: 0.5416 - val_accuracy: 0.7760\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8507 - val_loss: 0.5374 - val_accuracy: 0.7760\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8524 - val_loss: 0.5379 - val_accuracy: 0.7760\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8576 - val_loss: 0.5424 - val_accuracy: 0.7760\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8490 - val_loss: 0.5394 - val_accuracy: 0.7708\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8542 - val_loss: 0.5400 - val_accuracy: 0.7708\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3506 - accuracy: 0.8559 - val_loss: 0.5377 - val_accuracy: 0.7760\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3499 - accuracy: 0.8559 - val_loss: 0.5426 - val_accuracy: 0.7760\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8576 - val_loss: 0.5439 - val_accuracy: 0.7708\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8542 - val_loss: 0.5408 - val_accuracy: 0.7760\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3504 - accuracy: 0.8576 - val_loss: 0.5390 - val_accuracy: 0.7760\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8559 - val_loss: 0.5404 - val_accuracy: 0.7812\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3502 - accuracy: 0.8559 - val_loss: 0.5418 - val_accuracy: 0.7760\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8542 - val_loss: 0.5382 - val_accuracy: 0.7760\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8611 - val_loss: 0.5396 - val_accuracy: 0.7812\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8576 - val_loss: 0.5385 - val_accuracy: 0.7760\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3499 - accuracy: 0.8611 - val_loss: 0.5398 - val_accuracy: 0.7812\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8524 - val_loss: 0.5392 - val_accuracy: 0.7760\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3493 - accuracy: 0.8576 - val_loss: 0.5389 - val_accuracy: 0.7760\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8576 - val_loss: 0.5422 - val_accuracy: 0.7812\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8542 - val_loss: 0.5365 - val_accuracy: 0.7760\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8576 - val_loss: 0.5411 - val_accuracy: 0.7812\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3488 - accuracy: 0.8576 - val_loss: 0.5411 - val_accuracy: 0.7760\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8542 - val_loss: 0.5397 - val_accuracy: 0.7865\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3487 - accuracy: 0.8594 - val_loss: 0.5409 - val_accuracy: 0.7812\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.8594 - val_loss: 0.5420 - val_accuracy: 0.7812\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8542 - val_loss: 0.5401 - val_accuracy: 0.7865\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.8559 - val_loss: 0.5392 - val_accuracy: 0.7812\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3484 - accuracy: 0.8594 - val_loss: 0.5366 - val_accuracy: 0.7812\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3488 - accuracy: 0.8576 - val_loss: 0.5383 - val_accuracy: 0.7812\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3479 - accuracy: 0.8611 - val_loss: 0.5419 - val_accuracy: 0.7812\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.8576 - val_loss: 0.5408 - val_accuracy: 0.7760\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3482 - accuracy: 0.8628 - val_loss: 0.5386 - val_accuracy: 0.7760\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3480 - accuracy: 0.8646 - val_loss: 0.5434 - val_accuracy: 0.7865\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3480 - accuracy: 0.8594 - val_loss: 0.5411 - val_accuracy: 0.7812\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3479 - accuracy: 0.8646 - val_loss: 0.5400 - val_accuracy: 0.7812\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3482 - accuracy: 0.8559 - val_loss: 0.5392 - val_accuracy: 0.7812\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3479 - accuracy: 0.8611 - val_loss: 0.5404 - val_accuracy: 0.7865\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3475 - accuracy: 0.8628 - val_loss: 0.5419 - val_accuracy: 0.7917\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3476 - accuracy: 0.8646 - val_loss: 0.5405 - val_accuracy: 0.7917\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3476 - accuracy: 0.8576 - val_loss: 0.5400 - val_accuracy: 0.7812\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3479 - accuracy: 0.8628 - val_loss: 0.5408 - val_accuracy: 0.7812\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3477 - accuracy: 0.8594 - val_loss: 0.5383 - val_accuracy: 0.7812\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3473 - accuracy: 0.8594 - val_loss: 0.5381 - val_accuracy: 0.7812\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3476 - accuracy: 0.8576 - val_loss: 0.5413 - val_accuracy: 0.7865\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3469 - accuracy: 0.8594 - val_loss: 0.5415 - val_accuracy: 0.7865\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3472 - accuracy: 0.8594 - val_loss: 0.5410 - val_accuracy: 0.7917\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3468 - accuracy: 0.8594 - val_loss: 0.5404 - val_accuracy: 0.7812\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3468 - accuracy: 0.8646 - val_loss: 0.5400 - val_accuracy: 0.7917\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3473 - accuracy: 0.8576 - val_loss: 0.5399 - val_accuracy: 0.7865\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3472 - accuracy: 0.8594 - val_loss: 0.5422 - val_accuracy: 0.7865\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3467 - accuracy: 0.8559 - val_loss: 0.5416 - val_accuracy: 0.7917\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.8628 - val_loss: 0.5401 - val_accuracy: 0.7917\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8681 - val_loss: 0.5403 - val_accuracy: 0.7865\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8611 - val_loss: 0.5443 - val_accuracy: 0.7917\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8628 - val_loss: 0.5437 - val_accuracy: 0.7917\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8628 - val_loss: 0.5430 - val_accuracy: 0.7865\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8646 - val_loss: 0.5403 - val_accuracy: 0.7865\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8611 - val_loss: 0.5408 - val_accuracy: 0.7812\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8594 - val_loss: 0.5436 - val_accuracy: 0.7865\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8628 - val_loss: 0.5429 - val_accuracy: 0.7865\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8628 - val_loss: 0.5443 - val_accuracy: 0.7917\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8611 - val_loss: 0.5457 - val_accuracy: 0.7917\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8646 - val_loss: 0.5445 - val_accuracy: 0.7865\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3464 - accuracy: 0.8628 - val_loss: 0.5455 - val_accuracy: 0.7865\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8576 - val_loss: 0.5426 - val_accuracy: 0.7865\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.8611 - val_loss: 0.5408 - val_accuracy: 0.7865\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8594 - val_loss: 0.5424 - val_accuracy: 0.7865\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8646 - val_loss: 0.5411 - val_accuracy: 0.7865\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8663 - val_loss: 0.5427 - val_accuracy: 0.7865\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8594 - val_loss: 0.5406 - val_accuracy: 0.7865\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.8594 - val_loss: 0.5427 - val_accuracy: 0.7865\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3455 - accuracy: 0.8594 - val_loss: 0.5391 - val_accuracy: 0.7760\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3454 - accuracy: 0.8611 - val_loss: 0.5413 - val_accuracy: 0.7812\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8628 - val_loss: 0.5419 - val_accuracy: 0.7760\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8628 - val_loss: 0.5435 - val_accuracy: 0.7865\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3449 - accuracy: 0.8628 - val_loss: 0.5409 - val_accuracy: 0.7812\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8611 - val_loss: 0.5418 - val_accuracy: 0.7865\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8576 - val_loss: 0.5417 - val_accuracy: 0.7760\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8628 - val_loss: 0.5417 - val_accuracy: 0.7812\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8646 - val_loss: 0.5451 - val_accuracy: 0.7865\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8594 - val_loss: 0.5478 - val_accuracy: 0.7917\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8594 - val_loss: 0.5450 - val_accuracy: 0.7865\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8646 - val_loss: 0.5412 - val_accuracy: 0.7812\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8646 - val_loss: 0.5417 - val_accuracy: 0.7865\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8628 - val_loss: 0.5468 - val_accuracy: 0.7917\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8594 - val_loss: 0.5417 - val_accuracy: 0.7760\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8628 - val_loss: 0.5408 - val_accuracy: 0.7812\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8646 - val_loss: 0.5443 - val_accuracy: 0.7812\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8646 - val_loss: 0.5445 - val_accuracy: 0.7865\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8594 - val_loss: 0.5451 - val_accuracy: 0.7865\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8611 - val_loss: 0.5459 - val_accuracy: 0.7865\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8628 - val_loss: 0.5433 - val_accuracy: 0.7865\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8628 - val_loss: 0.5459 - val_accuracy: 0.7865\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8628 - val_loss: 0.5428 - val_accuracy: 0.7812\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8628 - val_loss: 0.5441 - val_accuracy: 0.7865\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8628 - val_loss: 0.5451 - val_accuracy: 0.7865\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8611 - val_loss: 0.5433 - val_accuracy: 0.7760\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8628 - val_loss: 0.5432 - val_accuracy: 0.7865\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8646 - val_loss: 0.5435 - val_accuracy: 0.7865\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8576 - val_loss: 0.5442 - val_accuracy: 0.7865\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3430 - accuracy: 0.8611 - val_loss: 0.5467 - val_accuracy: 0.7865\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3437 - accuracy: 0.8576 - val_loss: 0.5465 - val_accuracy: 0.7865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_4.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_4.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "8PLdp-kAHbyH",
        "outputId": "768b18ce-8e48-465f-c9a1-e8bf8cda7d8e"
      },
      "id": "8PLdp-kAHbyH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79ad378b51e0>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_4 = np.argmax(model3.predict(X_test_norm), axis=-1)\n",
        "y_pred_prob_nn_4 = model3.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eNg92iQHdo9",
        "outputId": "c25ece65-ece6-4f3a-cbec-364a252fd39f"
      },
      "id": "3eNg92iQHdo9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_4)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_4)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_4, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "m5QA84G3HfNd",
        "outputId": "0c7729bc-ef02-4d4a-ebdc-f41e44460554"
      },
      "id": "m5QA84G3HfNd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.641\n",
            "roc-auc is 0.817\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "**Observation**:\n",
        "- Here in this last model that I created, it is basically the same with our first model in this supplementary activity but the number of hidden layer nodes is doubled. In our first model, we have created 2 hidden layers with 6 hidden nodes each while this last model have 12 nodes each in the 2 hidden layers. The activation function is the same which is \"relu\". The learning rate is the same 0.003 but the number of epoch is increased from 200 to 1000.\n",
        "\n",
        "- The final training accuracy is 0.8576 with the loss of 0.3437. The final validation accuracy is 0.7865 with the validation loss of 0.5465. This model also shows overfitting because of the large gap between the training and validation accuracy and loss.\n",
        "\n",
        "- This model proves that the number of hidden layer nodes may not necessarily optimize the model to have a better accuracy, it also shows that the number of epoch may even be detrimental for the model because the loss may increase.\n",
        "\n",
        "- For the ROC curve, it is pretty much the same with the previous ROC curve, it shows that our model balances the true positive and true negative predictions. The accuracy is still the same in 0.641 because of the same validation and testing dataset.\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "1PlHGfqQ_dUN"
      },
      "id": "1PlHGfqQ_dUN"
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "#Summary/Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "### Summary:\n",
        "\n",
        "- In this activity, I trained a neural network with a real world dataset. In this activity there are no feature selection or correlation but there is data normalization which is done with the StandardScaler(). The dataset is split to 75-25, 75 for the training dataset and 25 for the testing dataset. In the first model in the procedure, we created a model with 1 hidden layer and 12 hidden layer nodes. The learning rate is 0.003 for the SGD, we used binary crossentropy for the loss function and we used accuracy as the metric. For the training of the model, we used the testing dataset for the validation dataset and we have set it to 200 epoch. The result can be considered as acceptable and the model is not overfitted.\n",
        "\n",
        "- For the supplementary activity, I created 3 models with different hidden layer nodes, learning rate, and epochs. I explored the different factors that affect the neural network. For the first model in the supplementary activity, I have set 2 hidden layers with 6 nodes each and the learning rate is 0.003, and the epochs is 1500. The result is also acceptable but the increase in terms of accuracy is not obvious and there is also a minimal increase in the ROC curve. The final results of training accuracy and loss also indicates overfitting. For the second model, I used the formula 2/3 of the previous layer for the hidden layer nodes, that's why I created a model with 2 hidden layer nodes with 5 and 3 nodes each. The activation function is still relu. The SGD learning rate is 0.01 and the epoch is 3000. The result is much worse than the previous models and shows that even if it is the rule of thumb, it may not be the best neural architecture. Also it shows that higher number of epochs may result to overfitting. For the last model, I doubled the hidden layer nodes of the first model, from 6 it became 12. The SGD learning rate is the same with the first model and the number of epoch is also the same. The result is not much better than the first model and it can be even considered as much less optimized. Also the model indicates overfitting. This shows that the number of hidden layer nodes may not be directly proportional for this particular dataset. Also the number of epochs may increase overfitting.\n",
        "\n",
        "<hr>\n",
        "\n"
      ],
      "metadata": {
        "id": "mAfxq2CW3gmt"
      },
      "id": "mAfxq2CW3gmt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion:\n",
        "\n",
        "- In this activity, I explored the world of neural networks using a real-world dataset. Without any prior feature selection or correlation analysis, I began by normalizing the data using the StandardScaler method. Splitting the dataset into a 75-25 ratio for training and testing respectively, I proceeded to build my first model with a single hidden layer comprising 12 nodes. Using a learning rate of 0.003 for the Stochastic Gradient Descent (SGD) optimizer, I utilized binary crossentropy as the loss function and accuracy as the evaluation metric. After 200 epochs, the model's performance proved acceptable without signs of overfitting. In the supplementary activity, I experimented with three additional models, each varying in hidden layer nodes, learning rate, and epochs. Despite adjusting parameters, the results differed widely. For instance, the second model, following the rule of thumb with 2/3 of the previous layer's nodes, exhibited poorer performance with increased epochs and a higher learning rate. Similarly, doubling the hidden layer nodes in the third model did not significantly improve results and suggested signs of overfitting. These outcomes highlights relationship between hidden layer nodes, epochs, and model performance, emphasizing the importance of careful parameter selection tailored to specific datasets to avoid overfitting and achieve optimal performance. Overall, this activity helped me widen my view regarding the neural networks and it made me understand that creating your own neural network is a very complicated task. I will certainly recommend this activity to the future data science students as it highlighted the important factors in creating a neural network. It also showcased the power of neural network using a real-world datset.\n",
        "\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "I0FNVaky7Vf6"
      },
      "id": "I0FNVaky7Vf6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###References:\n",
        "\n",
        "[1]S. Karsoliya, “Approximating Number of Hidden layer neurons in Multiple Hidden Layer BPNN Architecture,” 2012. Accessed: Mar. 24, 2024. [Online]. Available: https://ijettjournal.org/volume-3/issue-6/IJETT-V3I6P206.pdf"
      ],
      "metadata": {
        "id": "lJsUJqPw9P_y"
      },
      "id": "lJsUJqPw9P_y"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}